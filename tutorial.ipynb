{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DINN Tutorial --- COVID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will show the entire process of training a neural network to learn a disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the following system of differential equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dS/dt = - (alpha / N) * S * I\n",
    "\n",
    "dI/dt = (alpha / N) * S * I - beta * I - gamma * I \n",
    "\n",
    "dD/dt = gamma * I\n",
    "\n",
    "dR/dt = beta * I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where \n",
    "\n",
    "beta = “effective/apparent” per day recovery rates\n",
    "\n",
    "gamma = “effective/apparent” per day fatality rates\n",
    "\n",
    "alpha = infection rate\n",
    "\n",
    "N = population size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This system represents a COVID model and has 4 compartments: susceptible, infected, dead, and recovered. \n",
    "\n",
    "## Since we don't have actual data from the environment to work with, we will generate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries for generating & visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We start by setting some information that we got from the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions (from the literature)\n",
    "N = 59e6 #population size\n",
    "\n",
    "S0 = N - 1 #everyone starts out as susceptible, except for 1 person that is infected\n",
    "I0 = 1 #1 infected person\n",
    "D0 = 0\n",
    "R0 = 0\n",
    "\n",
    "# A grid of time points (in days)\n",
    "t = np.linspace(0, 500, 100) #from day 0 to day 500, generate 100 points\n",
    "\n",
    "#parameters (from the literature)\n",
    "alpha = 0.191\n",
    "beta = 0.05\n",
    "gamma = 0.0294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We then write out the system of equations in a function that will calculate the value of each compartment at each time step (e.g day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SIR model differential equations.\n",
    "def deriv(y, t, alpha, betta, gamma):\n",
    "    S, I, D, R = y\n",
    "    dSdt = - (alpha / N) * S * I\n",
    "    dIdt = (alpha / N) * S * I - beta * I - gamma * I \n",
    "    dDdt = gamma * I\n",
    "    dRdt = beta * I\n",
    "\n",
    "    return dSdt, dIdt, dDdt, dRdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And then we pass the initial conditions to the function to get the values of each compartment for the length we chose before (500 days, 100 data points per compartment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial conditions vector\n",
    "y0 = S0, I0, D0, R0\n",
    "# Integrate the SIR equations over the time grid, t.\n",
    "ret = odeint(deriv, y0, t, args=(alpha, beta, gamma))\n",
    "S, I, D, R = ret.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can now plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Susceptible', linestyle='dashed')\n",
    "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Infected', linestyle='dashed')\n",
    "ax.plot(t, D, 'blue', alpha=0.5, lw=2, label='Dead', linestyle='dashed')\n",
    "ax.plot(t, R, 'red', alpha=0.5, lw=2, label='Recovered', linestyle='dashed')\n",
    "\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Number')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And to save the results as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv file\n",
    "COVID_Data = np.asarray([t, S, I, D, R]) \n",
    "\n",
    "np.savetxt(\"COVID_Tutorial.csv\", COVID_Data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great! Now we have data to work with. On to training a neural network.\n",
    "I will break down the entire training process into parts. These parts might NOT be runnable on their own (meaning, you can't run the code -- which is why I will comment them out). The point is, I think that it will be easier to understand the process by first understanding what each part is doing, and then seeing how they all work together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x151a937ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import grad\n",
    "import torch.nn as nn\n",
    "from numpy import genfromtxt\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1234) #set seed (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = genfromtxt('COVID_Tutorial.csv', delimiter=',') #in the form of [t,S,I,D,R]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): # remember that the data was saved as [t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        # here all the \"loading the data\" and training is happening\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Now we need to define some initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. There are two options for this part. Either you know the values of the parameters (alpha, beta, gamma) or you don't. \n",
    "If you're wondering how can we not know their values if we just generated the data using them, remember that we can also get the data from the environment, and so we might not have the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we don't know their values, we let the neural network learn it\n",
    "Note that the reason for the \"tilda\" part will be clear soon. It's basically to bound the variables around a certain range (imagine telling the neural network to learn alpha, but not from negative infinity to infinity, but from -100 to 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "# self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "# self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we do know their values, we just set it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.alpha_tilda = torch.tensor(0.191)\n",
    "# self.beta_tilda = torch.tensor(0.05)\n",
    "# self.gamma_tilda = torch.tensor(0.0294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's assume we don't know them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Normalize the data\n",
    "Remember that our population size was 59 mil? Remember that there was only 1 infected person and almost 59 mil susceptible people? These drastic variation in values is quite challenging for the network to learn. So we normalize each compartment to be between 0 and 1 for the sake of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find values for normalization\n",
    "\n",
    "# max values\n",
    "# self.S_max = max(self.S)\n",
    "# self.I_max = max(self.I)\n",
    "# self.D_max = max(self.D)\n",
    "# self.R_max = max(self.R)\n",
    "\n",
    "# min values\n",
    "# self.S_min = min(self.S)\n",
    "# self.I_min = min(self.I)\n",
    "# self.D_min = min(self.D)\n",
    "# self.R_min = min(self.R)\n",
    "\n",
    "# create new normalized parameters (which is why the \"hat\" parts)\n",
    "# self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "# self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "# self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "# self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. A bit \"hacky\" way to calculate the gradients later\n",
    "It doesn't seem like PyTorch has an easy way to calculate gradients. The issue is that \"grad\" only knows how to propagate gradients from a scalar tensor (which our network's output is not), which is why I had to calculate the Jacobian.\n",
    "So instead of calculating the entire jacobian, I'm using this \"hacky\" way\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrices (x4 for S,I,D,R) for the gradients\n",
    "# What's important here:\n",
    "# We have 4 compartments, hence the value 4 in \"torch.zeros((len(self.t), 4))\". If we had 20 compartments we would write torch.zeros((len(self.t), 20))\n",
    "# Also, we're setting each specific column in the formed matrices to 1\n",
    "\n",
    "# self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "# self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "# self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "# self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "# See (https://stackoverflow.com/questions/67472361/using-pytorchs-autograd-efficiently-with-tensors-by-calculating-the-jacobian) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Let's initialize the network and learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initializing the neural network\n",
    "# self.net_sidr = self.Net_sidr()\n",
    "\n",
    "# # adding the parameters (alpha, beta, gamma) to the list of learnable parameters (basically, without this part only the neural network's weights will be updated, so we're telling the model to learn alpha, beta, and gamma as well)\n",
    "# self.params = list(self.net_sidr.parameters())\n",
    "# self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Forcing the parameters to be in a certain range\n",
    "As I mentioned before, we could let the model learn the parameters from negative infinity to infinity, but why should we? These parameters usually have some plausible range. Here we force these ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force parameters to be in the range of (-1, 1)\n",
    "@property\n",
    "def alpha(self):\n",
    "    return torch.tanh(self.alpha_tilda) \n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return torch.tanh(self.beta_tilda) \n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return torch.tanh(self.gamma_tilda) \n",
    "\n",
    "\n",
    "#note that you can easily play with that:\n",
    "\n",
    "#force parameters to be in various ranges\n",
    "@property\n",
    "def alpha(self):\n",
    "    return torch.tanh(self.alpha_tilda) * 0.5 # range of (-0.5, 0.5)\n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return torch.tanh(self.beta_tilda) * 0.01 + 1 # range of (-0.99, 1.01)\n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return torch.tanh(self.gamma_tilda) * 100 # range of (-100, 100)\n",
    "\n",
    "\n",
    "# Also note that we call these alpha, beta, and gamma (in comparison to \"alpha_tilda\", etc. from before)\n",
    "\n",
    "# If you know the values of the parameters you just need to change this to:\n",
    "@property\n",
    "def alpha(self):\n",
    "    return self.alpha_tilda\n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return self.beta_tilda\n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return self.gamma_tilda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) \n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) \n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Creating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "    def __init__(self):\n",
    "        super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "        self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "        self.fc2=nn.Linear(20, 20)\n",
    "        self.fc3=nn.Linear(20, 20)\n",
    "        self.fc4=nn.Linear(20, 20)\n",
    "        self.fc5=nn.Linear(20, 20)\n",
    "        self.fc6=nn.Linear(20, 20)\n",
    "        self.fc7=nn.Linear(20, 20)\n",
    "        self.fc8=nn.Linear(20, 20)\n",
    "        self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "    def forward(self, t_batch):\n",
    "        sidr=F.relu(self.fc1(t_batch))\n",
    "        sidr=F.relu(self.fc2(sidr))\n",
    "        sidr=F.relu(self.fc3(sidr))\n",
    "        sidr=F.relu(self.fc4(sidr))\n",
    "        sidr=F.relu(self.fc5(sidr))\n",
    "        sidr=F.relu(self.fc6(sidr))\n",
    "        sidr=F.relu(self.fc7(sidr))\n",
    "        sidr=F.relu(self.fc8(sidr))\n",
    "        sidr=self.out(sidr)\n",
    "        return sidr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Now the somewhat complicated part, we create another function that takes the timesteps batch, and pass it to the neural network \n",
    "We basically want to optimize the neural network and also this function that has the system of equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_f(self, t_batch):\n",
    "        \n",
    "        #pass the timesteps batch to the neural network\n",
    "        sidr_hat = self.net_sidr(t_batch)\n",
    "        \n",
    "        #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "        S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. we now want to get the derivative of each compartment with respect to time (this is why we had to do the \"hacky\" jacobian part)\n",
    "We do this to plug in the systems of equations (you'll see in the next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #S_t\n",
    "# sidr_hat.backward(self.m1, retain_graph=True)\n",
    "# S_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #I_t\n",
    "# sidr_hat.backward(self.m2, retain_graph=True)\n",
    "# I_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #D_t\n",
    "# sidr_hat.backward(self.m3, retain_graph=True)\n",
    "# D_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #R_t\n",
    "# sidr_hat.backward(self.m4, retain_graph=True)\n",
    "# R_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. We now unnormalize the compartments because we don't actually want the equations to change, we just wanted the network to learn quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #unnormalize\n",
    "# S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "# I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "# D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "# R = self.R_min + (self.R_max - self.R_min) * R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Lastly (almost), we write out the systems of equations we want to learn\n",
    "These are almost the same as the initial system of equations, except that we have another normalization component here (e.g \"/ (self.S_max - self.S_min)\"), and also that we use the partial derivates (e.g \"S\" with respect to time) here. We basically moved the right side of each compartment to the left (hence the negative signs after the derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "# f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "# f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "# f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Lastly, we return the values we learned and want to optimize --- S, I, D, R, and each system's compartment (e.g f1_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        \n",
    "\n",
    "            return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. The training process:\n",
    "Here we just create a function called \"train\", that will take a number of epochs to train for, and will train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, n_epochs):\n",
    "      # train\n",
    "      print('\\nstarting training...\\n')\n",
    "      \n",
    "      for epoch in range(n_epochs):\n",
    "        # lists to hold the output (maintain only the final epoch)\n",
    "        S_pred_list = []\n",
    "        I_pred_list = []\n",
    "        D_pred_list = []\n",
    "        R_pred_list = []\n",
    "\n",
    "        # we pass the timesteps batch into net_f\n",
    "        f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch) # net_f outputs f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "        \n",
    "        self.optimizer.zero_grad() #zero grad\n",
    "        \n",
    "        #append the values to plot later (note that we unnormalize them here for plotting)\n",
    "        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred)\n",
    "        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
    "        D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
    "        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
    "\n",
    "        #calculate the loss --- MSE of the neural networks output and each compartment\n",
    "        loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
    "                torch.mean(torch.square(self.I_hat - I_pred))+\n",
    "                torch.mean(torch.square(self.D_hat - D_pred))+\n",
    "                torch.mean(torch.square(self.R_hat - R_pred))+\n",
    "                torch.mean(torch.square(f1))+\n",
    "                torch.mean(torch.square(f2))+\n",
    "                torch.mean(torch.square(f3))+\n",
    "                torch.mean(torch.square(f4))\n",
    "                ) \n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step() \n",
    "\n",
    "        # append the loss value (we call \"loss.item()\" because we just want the value of the loss and not the entire computational graph)\n",
    "        self.losses.append(loss.item())\n",
    "\n",
    "        if epoch % 1000 == 0:          \n",
    "          print('\\nEpoch ', epoch)\n",
    "\n",
    "          print('alpha: (goal 0.191 ', self.alpha)\n",
    "          print('beta: (goal 0.05 ', self.beta)\n",
    "          print('gamma: (goal 0.0294 ', self.gamma)\n",
    "\n",
    "          print('#################################')                \n",
    "\n",
    "      return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        \n",
    "\n",
    "            return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        # train\n",
    "        print('\\nstarting training...\\n')\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # lists to hold the output (maintain only the final epoch)\n",
    "            S_pred_list = []\n",
    "            I_pred_list = []\n",
    "            D_pred_list = []\n",
    "            R_pred_list = []\n",
    "\n",
    "            # we pass the timesteps batch into net_f\n",
    "            f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch) # net_f outputs f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "            \n",
    "            self.optimizer.zero_grad() #zero grad\n",
    "            \n",
    "            #append the values to plot later (note that we unnormalize them here for plotting)\n",
    "            S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred)\n",
    "            I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
    "            D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
    "            R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
    "\n",
    "            #calculate the loss --- MSE of the neural networks output and each compartment\n",
    "            loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
    "                    torch.mean(torch.square(self.I_hat - I_pred))+\n",
    "                    torch.mean(torch.square(self.D_hat - D_pred))+\n",
    "                    torch.mean(torch.square(self.R_hat - R_pred))+\n",
    "                    torch.mean(torch.square(f1))+\n",
    "                    torch.mean(torch.square(f2))+\n",
    "                    torch.mean(torch.square(f3))+\n",
    "                    torch.mean(torch.square(f4))\n",
    "                    ) \n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step() \n",
    "\n",
    "            # append the loss value (we call \"loss.item()\" because we just want the value of the loss and not the entire computational graph)\n",
    "            self.losses.append(loss.item())\n",
    "\n",
    "            if epoch % 1000 == 0:          \n",
    "                print('\\nEpoch ', epoch)\n",
    "\n",
    "                print('alpha: (goal 0.191 ', self.alpha)\n",
    "                print('beta: (goal 0.05 ', self.beta)\n",
    "                print('gamma: (goal 0.0294 ', self.gamma)\n",
    "\n",
    "                print('#################################')                \n",
    "\n",
    "        return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting training...\n",
      "\n",
      "\n",
      "Epoch  0\n",
      "alpha: (goal 0.191  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3816], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2541], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  1000\n",
      "alpha: (goal 0.191  tensor([0.0450], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3683], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2397], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  2000\n",
      "alpha: (goal 0.191  tensor([0.0532], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3603], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2310], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  3000\n",
      "alpha: (goal 0.191  tensor([0.0619], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3508], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2208], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  4000\n",
      "alpha: (goal 0.191  tensor([0.0737], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3402], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2093], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  5000\n",
      "alpha: (goal 0.191  tensor([0.0869], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3289], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1972], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  6000\n",
      "alpha: (goal 0.191  tensor([0.0995], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3182], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1857], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  7000\n",
      "alpha: (goal 0.191  tensor([0.1115], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3080], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1748], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  8000\n",
      "alpha: (goal 0.191  tensor([0.1233], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2981], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1642], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  9000\n",
      "alpha: (goal 0.191  tensor([0.1333], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2892], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1548], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  10000\n",
      "alpha: (goal 0.191  tensor([0.1432], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2799], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1449], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  11000\n",
      "alpha: (goal 0.191  tensor([0.1539], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2695], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1340], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  12000\n",
      "alpha: (goal 0.191  tensor([0.1653], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2579], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1218], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  13000\n",
      "alpha: (goal 0.191  tensor([0.1759], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2468], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1101], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  14000\n",
      "alpha: (goal 0.191  tensor([0.1854], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2366], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0995], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  15000\n",
      "alpha: (goal 0.191  tensor([0.1949], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2271], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0897], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  16000\n",
      "alpha: (goal 0.191  tensor([0.2047], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2176], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0799], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  17000\n",
      "alpha: (goal 0.191  tensor([0.2144], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2081], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0701], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  18000\n",
      "alpha: (goal 0.191  tensor([0.2239], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1985], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0604], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  19000\n",
      "alpha: (goal 0.191  tensor([0.2328], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1891], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0509], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  20000\n",
      "alpha: (goal 0.191  tensor([0.2413], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1800], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0419], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  21000\n",
      "alpha: (goal 0.191  tensor([0.2493], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1714], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0333], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  22000\n",
      "alpha: (goal 0.191  tensor([0.2568], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1630], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0253], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  23000\n",
      "alpha: (goal 0.191  tensor([0.2637], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1550], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0178], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  24000\n",
      "alpha: (goal 0.191  tensor([0.2699], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1473], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0111], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  25000\n",
      "alpha: (goal 0.191  tensor([0.2752], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1401], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0057], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  26000\n",
      "alpha: (goal 0.191  tensor([0.2790], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1333], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0021], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  27000\n",
      "alpha: (goal 0.191  tensor([0.2806], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1268], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0014], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  28000\n",
      "alpha: (goal 0.191  tensor([0.2796], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1202], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0039], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  29000\n",
      "alpha: (goal 0.191  tensor([0.2760], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1130], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0084], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  30000\n",
      "alpha: (goal 0.191  tensor([0.2700], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1052], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0130], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  31000\n",
      "alpha: (goal 0.191  tensor([0.2620], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0972], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0169], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  32000\n",
      "alpha: (goal 0.191  tensor([0.2531], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0892], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0202], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  33000\n",
      "alpha: (goal 0.191  tensor([0.2438], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0816], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0230], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  34000\n",
      "alpha: (goal 0.191  tensor([0.2347], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0744], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0249], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  35000\n",
      "alpha: (goal 0.191  tensor([0.2266], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0672], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0266], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  36000\n",
      "alpha: (goal 0.191  tensor([0.2182], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0614], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0284], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  37000\n",
      "alpha: (goal 0.191  tensor([0.2099], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0568], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0293], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  38000\n",
      "alpha: (goal 0.191  tensor([0.2029], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0535], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0296], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  39000\n",
      "alpha: (goal 0.191  tensor([0.1968], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0513], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0294], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  40000\n",
      "alpha: (goal 0.191  tensor([0.1934], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0501], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0293], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  41000\n",
      "alpha: (goal 0.191  tensor([0.1918], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0497], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0291], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  42000\n",
      "alpha: (goal 0.191  tensor([0.1911], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0495], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0291], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  43000\n",
      "alpha: (goal 0.191  tensor([0.1912], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0496], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  44000\n",
      "alpha: (goal 0.191  tensor([0.1911], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0496], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  45000\n",
      "alpha: (goal 0.191  tensor([0.1912], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0497], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  46000\n",
      "alpha: (goal 0.191  tensor([0.1937], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0493], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0289], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  47000\n",
      "alpha: (goal 0.191  tensor([0.1934], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0492], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0289], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  48000\n",
      "alpha: (goal 0.191  tensor([0.1938], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0494], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0289], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  49000\n",
      "alpha: (goal 0.191  tensor([0.1938], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0494], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0289], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "CPU times: user 3min 3s, sys: 525 ms, total: 3min 4s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dinn = DINN(covid_data[0], covid_data[1], covid_data[2], covid_data[3], \n",
    "            covid_data[4]) #in the form of [t,S,I,D,R]\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
    "dinn.optimizer = optimizer\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=1000, mode=\"exp_range\", gamma=0.85, cycle_momentum=False)\n",
    "\n",
    "dinn.scheduler = scheduler\n",
    "\n",
    "S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(50000) #train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Plotting the losses and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0, 0.5, 'Loss'),)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgX0lEQVR4nO3de5hV9X3v8fdn7hcYBmEEAgJaMUSjgsVbNI02N7SpmsRYaZpbzaGa2DTpc9KYp32S0/Y85yRNT07rpRKSEE9O4qUeoyFeota0GrWJDAIKRAERDKIyyv0mc/meP/Ya3LPZe2ZzWbOG2Z/X8+xnr/1ba+39/aEzn/n91tprKSIwMzMrpirrAszMbOhySJiZWUkOCTMzK8khYWZmJTkkzMyspJqsCziSxo4dG1OnTs26DDOzo8bixYtfj4i2UuuHVUhMnTqV9vb2rMswMztqSFrf33pPN5mZWUkOCTMzK8khYWZmJTkkzMysJIeEmZmV5JAwM7OSUjsFVtIC4EPApoh4Z5H1XwY+nlfHO4C2iNgsaR2wA+gGuiJiVlp1mplZaWmOJG4BZpdaGRHfiogZETED+CrwaERsztvkwmR9qgEREfz9o4/y4Jo1aX6MmdlRKbWQiIjHgM0DbpgzB7gtrVr6I4l//M//5AGHhJnZATI/JiGpidyI46685gAekrRY0twB9p8rqV1Se0dHxyHVMLapiY7duw9pXzOz4SzzkAD+EHiiYKrpvIg4A7gI+Lyk3yu1c0TMj4hZETGrra3k5Uf61dbUxOsOCTOzAwyFkLiSgqmmiNiYPG8C7gbOSrOAsU1NdOzaleZHmJkdlTINCUmjgPcAP81ra5Y0sncZ+ACwPM062pqbPZIwMysizVNgbwMuAMZK2gB8HagFiIh5yWYfBh6KiPw/48cBd0vqre/WiPh5WnVCbrqpY/duIoLkc83MjBRDIiLmlLHNLeROlc1vWwucnk5VxY1tamJvVxe7OztprqsbzI82MxvShsIxicy1NTUB+AwnM7MCDglyIwnAxyXMzAo4JHgrJHyGk5lZXw4JYEwSEpv37Mm4EjOzocUhAYxpbATgDYeEmVkfDgmgtaEB4ZGEmVkhhwRQXVVFa0MDb/jAtZlZHw6JxJimJk83mZkVcEgkjmls9HSTmVkBh0RiTGOjRxJmZgUcEokxTU0+JmFmVsAhkTimocHTTWZmBRwSiTFNTWx78026enqyLsXMbMhwSCR6v1C3xaMJM7P9HBKJY/ytazOzAzgkEr3Xb/LBazOztzgkEr0jCR+8NjN7i0Mi4Yv8mZkdyCGR8HSTmdmBUgsJSQskbZK0vMT6CyRtk7Q0eXwtb91sSc9LWiPpurRqzDeyro6aqipPN5mZ5UlzJHELMHuAbX4ZETOSx98BSKoGbgIuAk4G5kg6OcU6ST6XY3xpDjOzPlILiYh4DNh8CLueBayJiLURsQ+4Hbj0iBZXgq/fZGbWV9bHJM6VtEzSA5JOSdomAr/N22ZD0laUpLmS2iW1d3R0HFYxvhKsmVlfWYbE08CUiDgduAG4J2lXkW2j1JtExPyImBURs9ra2g6rIF/kz8ysr8xCIiK2R8TOZPl+oFbSWHIjh+PyNp0EbByMmjzdZGbWV2YhIWm8JCXLZyW1vAEsAqZJOl5SHXAlsHAwavJ0k5lZXzVpvbGk24ALgLGSNgBfB2oBImIecDlwjaQuYA9wZUQE0CXpWuBBoBpYEBEr0qoz35jGRnZ3drK3q4uGmtT+aczMjhqp/SaMiDkDrL8RuLHEuvuB+9Ooqz/7L/K3ezcTW1oG++PNzIacrM9uGlJ6v3XtKSczsxyHRB5fv8nMrC+HRJ786SYzM3NI9OHpJjOzvhwSeTzdZGbWl0MiT2NtLQ01NZ5uMjNLOCQKjPEX6szM9nNIFBjT1OTpJjOzhEOigO8pYWb2FodEAU83mZm9xSFRYHRDg0PCzCzhkCjQUl/PjjffzLoMM7MhwSFRYGR9Pbs6O+mJkvc5MjOrGA6JAi319QDs3Lcv40rMzLLnkCgwsq4OgO2ecjIzc0gUGpmMJHxcwszMIXGA3ummHZ5uMjNzSBTydJOZ2VscEgU83WRm9pbUQkLSAkmbJC0vsf7jkp5JHk9KOj1v3TpJz0paKqk9rRqL6Z1u8kjCzCzdkcQtwOx+1r8IvCciTgP+HphfsP7CiJgREbNSqq+o3ukmH5MwM4OatN44Ih6TNLWf9U/mvfwVMCmtWg5Gi6ebzMz2GyrHJK4CHsh7HcBDkhZLmtvfjpLmSmqX1N7R0XHYhdTX1FBbVeXpJjMzUhxJlEvSheRC4vy85vMiYqOkY4GHJT0XEY8V2z8i5pNMVc2aNeuIXEtjZH29p5vMzMh4JCHpNOB7wKUR8UZve0RsTJ43AXcDZw1mXS0OCTMzIMOQkDQZ+AnwiYhYldfeLGlk7zLwAaDoGVJpGVlX5+kmMzNSnG6SdBtwATBW0gbg60AtQETMA74GjAH+RRJAV3Im0zjg7qStBrg1In6eVp3F+HLhZmY5aZ7dNGeA9Z8FPlukfS1w+oF7DJ6R9fW8sXt3liWYmQ0JQ+XspiFlZF2dj0mYmeGQKGpkXZ2nm8zMcEgU1VxXx67OzqzLMDPLnEOiiObaWnZ5usnMzCFRTHNdHZ09PXR2d2ddiplZphwSRYxILvLnKSczq3QOiSKaa2sB2OkpJzOrcA6JIpp7RxIOCTOrcA6JInpHEp5uMrNK55AowiMJM7Mch0QRHkmYmeU4JIrwSMLMLMchUUTvKbA+u8nMKp1DoghPN5mZ5TgkivB0k5lZjkOiiCaPJMzMAIdEUVUSjTU1HkmYWcVzSJTgy4WbmTkkSmqurfXZTWZW8VILCUkLJG2StLzEekm6XtIaSc9IOiNv3WxJzyfrrkurxv6M8EjCzCzVkcQtwOx+1l8ETEsec4GbASRVAzcl608G5kg6OcU6i2quq/MxCTOreKmFREQ8BmzuZ5NLgR9Gzq+AVkkTgLOANRGxNiL2Abcn2w6q5tpajyTMrOJleUxiIvDbvNcbkrZS7YPKIwkzs2xDQkXaop/24m8izZXULqm9o6PjiBXnkYSZWbYhsQE4Lu/1JGBjP+1FRcT8iJgVEbPa2tqOWHE+u8nMLNuQWAh8MjnL6RxgW0S8AiwCpkk6XlIdcGWy7aDydJOZGdSk9caSbgMuAMZK2gB8HagFiIh5wP3AxcAaYDfwmWRdl6RrgQeBamBBRKxIq85SPN1kZpZiSETEnAHWB/D5EuvuJxcimRlRV0dXTw/7urupq67OshQzs8yUNd0kqVlSVbJ8kqRLJNWmW1q2fCVYM7Pyj0k8BjRImgg8Qm5q6Ja0ihoKeu8p4YPXZlbJyg0JRcRu4CPADRHxYXLfhh629o8kfFzCzCpY2SEh6Vzg48B9SVtqxzOGgv13p/NIwswqWLkh8UXgq8DdEbFC0gnAv6dW1RDgkYSZWZmjgYh4FHgUIDmA/XpEfCHNwrI2wgeuzczKPrvpVkktkpqBlcDzkr6cbmnZavYtTM3Myp5uOjkitgOXkfv+wmTgE2kVNRT4FFgzs/JDojb5XsRlwE8jopN+Lro3HPgUWDOz8kPiO8A6oBl4TNIUYHtaRQ0FPnBtZlb+gevrgevzmtZLujCdkoaGJp8Ca2ZW9oHrUZK+3XvfBkn/i9yoYtiqkmjyRf7MrMKVO920ANgBXJE8tgM/SKuooaK5ttYjCTOraOV+a/p3IuKjea//VtLSFOoZUprr6tjpkYSZVbByRxJ7JJ3f+0LSecCedEoaOjySMLNKV+5I4mrgh5JGJa+3AJ9Kp6ShY0RdnY9JmFlFK/fspmXA6ZJaktfbJX0ReCbF2jLnW5iaWaU7qHtcR8T25JvXAH+ZQj1Dim9hamaV7qBCooCOWBVDlEcSZlbpDickBrwsh6TZkp6XtEbSdUXWf1nS0uSxXFK3pGOSdeskPZusaz+MOg9Zc22tL8thZhWt32MSknZQPAwENA6wbzVwE/B+YAOwSNLCiFjZu01EfAv4VrL9HwJfiojNeW9zYUS8Xk5H0uAD12ZW6foNiYgYeRjvfRawJiLWAki6HbiU3KXGi5kD3HYYn3fE9Z4CGxFIw352zczsAIcz3TSQicBv815vSNoOIKkJmA3cldccwEOSFkuam1qV/Wiuq6M7gn3d3Vl8vJlZ5tK8T3WxP71LHcf4Q+CJgqmm8yJio6RjgYclPRcRjx3wIbkAmQswefLkw625j/wbD9XXDOtbepuZFZXmSGIDcFze60nAxhLbXknBVFNEbEyeNwF3k5u+OkBEzI+IWRExq62t7bCLzucbD5lZpUszJBYB0yQdL6mOXBAsLNwo+Rb3e4Cf5rU1SxrZuwx8AFieYq1F9d7n2mc4mVmlSm0OJSK6JF0LPAhUAwsiYoWkq5P185JNPww8FBG78nYfB9ydHCyuAW6NiJ+nVWspvs+1mVW6VCfaI+J+cvfEzm+bV/D6FuCWgra1wOlp1lYOTzeZWaVLc7rpqOeRhJlVOodEPzySMLNK55DoR++Ba48kzKxSOST60Tvd5LObzKxSOST64ekmM6t0Dol+NNbUIDzdZGaVyyHRD0k0+T7XZlbBHBIDaPblws2sgjkkBuB7SphZJXNIDMB3pzOzSuaQGMCIujqHhJlVLIfEAEY1NLBt796syzAzy4RDYgCtDQ1sdUiYWYVySAxgVH092958M+syzMwy4ZAYQO9IIqLUnVfNzIYvh8QAWhsa2Nfdzd6urqxLMTMbdA6JAYyqrwfwlJOZVSSHxABaGxoAfPDazCqSQ2IADgkzq2QOiQGMSkLC35Uws0qUakhImi3peUlrJF1XZP0FkrZJWpo8vlbuvoPFIwkzq2Q1ab2xpGrgJuD9wAZgkaSFEbGyYNNfRsSHDnHf1PnAtZlVsjRHEmcBayJibUTsA24HLh2EfY+o3pHElj17svh4M7NMpRkSE4Hf5r3ekLQVOlfSMkkPSDrlIPdF0lxJ7ZLaOzo6jkTdfTTV1tJYU0PH7t1H/L3NzIa6NENCRdoKv7b8NDAlIk4HbgDuOYh9c40R8yNiVkTMamtrO9RaS5LEuBEjeG3XriP+3mZmQ12aIbEBOC7v9SRgY/4GEbE9InYmy/cDtZLGlrPvYDq2uZlNDgkzq0BphsQiYJqk4yXVAVcCC/M3kDRekpLls5J63ihn38E0rrmZ13buzOrjzcwyk9rZTRHRJela4EGgGlgQESskXZ2snwdcDlwjqQvYA1wZuSvpFd03rVoHcmxzM+0bMxvImJllJrWQgP1TSPcXtM3LW74RuLHcfbMyLplu6omgSsUOl5iZDU/+xnUZjm1upjvCp8GaWcVxSJThbSNHArBh+/aMKzEzG1wOiTKcMHo0AC9u3ZptIWZmg8whUYbekFi7ZUvGlZiZDS6HRBlGNzbS2tDgkDCziuOQKNMJo0ezevPmrMswMxtUDokynTZuHEteeYXc1zjMzCqDQ6JMZ77tbXTs3s1L27ZlXYqZ2aBxSJTp7Im5i9A+tn59xpWYmQ0eh0SZZk6YwKSWFu5cOej3PTIzy4xDokxVEn9y6qnct3o1S199NetyzMwGhUPiIHz5vPNoa2riD269lbtWrqSrpyfrkszMUuWQOAjHNDby0Cc+QUt9PZffeScTv/1tPn3PPdyxfDmbfV0nMxuGNJxO6Zw1a1a0t7en/jldPT3ct2oVty1fzkMvvMCWvXupknjPlClcccop/NEppzC6sTH1OszMDpekxRExq+R6h8Th6e7p4amXX+a+1av5fytX8vwbb1AlcfbEicw+8UQ+dNJJzBw/HvkS42Y2BDkkBlFE0L5xIz9btYoHX3iBRS+/TJC7iuwfTJvGh046ifedcAJNtbWZ1Whmls8hkaFNu3bxwOrV3Lt6NQ+uWcOOfftoqKnhS+ecw/9473uzLs/MbMCQSPXOdJXu2OZmPjVjBp+aMYN93d38cv165i1ezP98/HFe3LqVL7/rXZwxYULWZZqZleSQGCR11dW894QTePeUKZw4ejQ3PPUUty9fzu9NmcIXzz6bS97+dqqrfLKZmQ0tqU43SZoN/DNQDXwvIr5RsP7jwFeSlzuBayJiWbJuHbAD6Aa6+hsO9Rpq00392bp3L99/+mlueOop1m/bxnEtLVw1cyZ/OnMmx40alXV5ZlYhMjsmIakaWAW8H9gALALmRMTKvG3eBfwmIrZIugj4bxFxdrJuHTArIl4v9zOPppDo1dXTw8Lnn2f+4sU89MILSOLiadP4L2ecwcXTplHj0YWZpSjLYxJnAWsiYm1SyO3ApcD+kIiIJ/O2/xUwKcV6hqSaqio+8o538JF3vIMXt2zh+0uWsGDJEu5dtYq3jRzJVTNnctXMmUxpbc26VDOrQGmOJC4HZkfEZ5PXnwDOjohrS2z/X4Hpedu/CGwBAvhORMwvsd9cYC7A5MmTf3f9MLhKa2d3N/etXs13n36aB1avBuCDJ57I3DPO4EMnnURtdXXGFZrZcJHlSKLYt8eKJpKkC4GrgPPzms+LiI2SjgUelvRcRDx2wBvmwmM+5KabDr/s7NVWV3PZ9OlcNn0667duZcGSJXx/yRI+8q//yvgRI/jMjBn81Xnn0drQkHWpZjbMpTnhvQE4Lu/1JGBj4UaSTgO+B1waEW/0tkfExuR5E3A3uemrijOltZW/vfBC1n3xi/xszhzOfNvb+Mbjj3PazTfzzccfZ9OuXVmXaGbDWJrTTTXkDly/F3iZ3IHrP46IFXnbTAZ+AXwy//iEpGagKiJ2JMsPA38XET/v7zOPxgPXh+Lxl17ib37xCx5dv57a5JjG5888k/MnT/blP8zsoGQ23RQRXZKuBR4kdwrsgohYIenqZP084GvAGOBfkl9uvae6jgPuTtpqgFsHCohKcv7kyfzHpz/Nbzo6mL94MbcsW8YdK1Ywc/x4vnTOOVxxyinU1/grMGZ2+HxZjmFgd2cnP3rmGf75179mZUcHxzY389mZM/mzWbOY7O9cmFk/fO2mChIRPPTCC9y0aBH3rlqFJC55+9v5ynnncc6kiju72MzK4Gs3VRBJfPDEE/ngiSeybutWvtPezvynn+ae557jw9On8833vY9pY8ZkXaaZHUU8khjmdu7bxz/96ld884kn2NvVxWXTp/O5WbO4YOpUH+Q2M083Wc5rO3fyrSef5AdLl7J5zx5Obmvj82eeySdOO42R9fVZl2dmGXFIWB97Oju5fflybly0iKdfeYUpo0bx7Q9+kEt9FVqziuSQsKIign9bu5Y/u/deXty6lamtrfzNu9/NZ2bOpMrTUGYVY6CQ8J+OFUoS7/+d32HVn/85d11xBeNHjOCzP/sZp958M7cvX053T0/WJZrZEOCQqHC9V6F94k//lNs++lEA5tx1F++8+WZue/ZZh4VZhXNIGABVEle+8508e8013HH55VRL/PFPfuKwMKtwDgnro0riilNO4ZlrruHOj32Mmqqq/WHx0+eeYzgdwzKzgTkkrKgqictPPpllV1/NnR/7GACX3XEH7/3hD1n66qsZV2dmg8UhYf3qDYtnrr6amy6+mGdee40zvvMdPrtwoS9TblYBHBJWltrqaj535pms+cIX+Mtzz+X/LFvGSTfcwLz2dno8BWU2bDkk7KC0NjTwjx/4AM9ecw1nTJjANffdx3tuuYVVb7wx8M5mdtRxSNghmT52LI988pMsuOQSlm/axGk338w/PPEEXT4LymxYcUjYIZPEZ2bOZOXnPsfF06bxlX/7N8767nd5/KWXsi7NzI4Qh4QdtgkjR3LXFVdw58c+xqZdu3j3D37ART/+MU+89JJPmTU7yvnaTXZE7dq3j5sWLeJbTz7J67t3846xY/n4qafyx6eeyvGjR2ddnpkV8AX+LBO79u3jx88+y4+eeYZfJtNPk1pamDF+PDPGjWPG+PHMnDCB41tbfV8LswxlGhKSZgP/DFQD34uIbxSsV7L+YmA38OmIeLqcfYtxSAxN67du5Se/+Q2LX3mFpa++ynOvv0538v9dS309pyehcXJbG1NGjWJSSwsTW1oY3dDgADFLWWa3L5VUDdwEvB/YACyStDAiVuZtdhEwLXmcDdwMnF3mvnaUmNLaypfOPXf/6z2dnSzftImlr76ae7z2GguWLGFXZ2ef/Rpqahjb1MQxjY2Mbmjo83xMYyOje58bGmiqraW+pob66mrqqqv3L/c+11ZXUyVRJSFw+BxFdnd28tK2bUwfO/aIvN++7m6qpUG/f0pndzev7drFpJaWI/q+L27ZwtQUR+Rp3uP6LGBNRKwFkHQ7cCmQ/4v+UuCHkRvO/EpSq6QJwNQy9rWjVGNtLWdOnMiZEyfub+uJYOOOHazfupWXd+zg5e3beXnHDt7Ys4cte/awec8eVm/ezObk9Z6ursOqQUB1VdX+4Cj1qJb2//D1hkvhj2LhD2exH9WBtin2A97bEsC6rVtpqq3d/wumdwagdx4gf0agsG2g10dyn5379rG3q4um2lomjxrVpz/FZi2KzWMUbrd682YAjm9tpaGm9K+sIPf/UXdPD90RfZbz27bu3QvASWPG0JO05T+6e3oOaOvs6WHnvn2MbmhgwsiRRWuOfpYjghe2bAFgwogRtDY0lPw3KOx/f+t7/20A4utfL/lvczjSDImJwG/zXm8gN1oYaJuJZe4LgKS5wFyAyZMnH17FlpkqiUktLWX/lbW3q2t/eGzZu5c9nZ282d3Nm11dRZ87u7v3/xIp9YvggF8WyXbA/h/0g/2BLtZW1j4Fv4zXbd3Kicccw8ltbfvbe0MkP8Qo0TbQ64PZNj/QCtv2dXfz/SVLOH/y5D6/CAu379PWT0BCbkpy8SuvMHPCBKoH+Gu5Khkh9I4UqqDva4l57e1Mamlh5vjxB/6hkLxHVd72VRI9Edy0aBFnTJjA6MbGop+dP0Ittjy1tZVHXnyRsydNorZgFHOwf0T0vpoxfjx3rlzJZdOn9/vvcjjSDIli/zULfx5KbVPOvrnGiPnAfMgdkziYAu3o1VBTw4SRI4v+VTcc/d8PfzjrEsr2vUsuybqEfl1/0UWHtN+NF198hCs5OqQZEhuA4/JeTwI2lrlNXRn7mplZytI8crMImCbpeEl1wJXAwoJtFgKfVM45wLaIeKXMfc3MLGWpjSQiokvStcCD5E5jXRARKyRdnayfB9xP7vTXNeROgf1Mf/umVauZmRXnL9OZmVWwgb4n4Ws3mZlZSQ4JMzMrySFhZmYlOSTMzKykYXXgWlIHsP4Qdx8LvH4EyzkauM/DX6X1F9zngzUlItpKrRxWIXE4JLX3d4R/OHKfh79K6y+4z0eap5vMzKwkh4SZmZXkkHjL/KwLyID7PPxVWn/BfT6ifEzCzMxK8kjCzMxKckiYmVlJFR8SkmZLel7SGknXZV3PwZK0QNImScvz2o6R9LCk1cnz6Lx1X036+rykD+a1/66kZ5N11yu5FZakekl3JO2/ljR1UDtYQNJxkv5d0m8krZD0F0n7cO5zg6SnJC1L+vy3Sfuw7XMvSdWSlki6N3k9rPssaV1S61JJ7Ulbtn2OiIp9kLsM+QvACeRudLQMODnrug6yD78HnAEsz2v7B+C6ZPk64JvJ8slJH+uB45O+VyfrngLOJXdXwAeAi5L2zwHzkuUrgTsy7u8E4IxkeSSwKunXcO6zgBHJci3wa+Cc4dznvL7/JXArcO9w/387qWMdMLagLdM+Z/4/Qcb/Qc4FHsx7/VXgq1nXdQj9mErfkHgemJAsTwCeL9Y/cvfrODfZ5rm89jnAd/K3SZZryH2rU1n3Oa/WnwLvr5Q+A03A0+Tu+T6s+0zujpSPAL/PWyEx3Pu8jgNDItM+V/p000Tgt3mvNyRtR7txkbvDH8nzsUl7qf5OTJYL2/vsExFdwDZgTGqVH4RkqDyT3F/Ww7rPybTLUmAT8HBEDPs+A/8E/BXQk9c23PscwEOSFkuam7Rl2uc073F9NFCRtuF8TnCp/vb37zAk/40kjQDuAr4YEduTKdeimxZpO+r6HBHdwAxJrcDdkt7Zz+ZHfZ8lfQjYFBGLJV1Qzi5F2o6qPifOi4iNko4FHpb0XD/bDkqfK30ksQE4Lu/1JGBjRrUcSa9JmgCQPG9K2kv1d0OyXNjeZx9JNcAoYHNqlZdBUi25gPhxRPwkaR7Wfe4VEVuB/wBmM7z7fB5wiaR1wO3A70v6EcO7z0TExuR5E3A3cBYZ97nSQ2IRME3S8ZLqyB3IWZhxTUfCQuBTyfKnyM3b97ZfmZzhcDwwDXgqGcLukHROchbEJwv26X2vy4FfRDKhmYWkvu8Dv4mIb+etGs59bktGEEhqBN4HPMcw7nNEfDUiJkXEVHI/l7+IiD9hGPdZUrOkkb3LwAeA5WTd5ywP0gyFB3AxuTNkXgD+Out6DqH+24BXgE5yfyVcRW6O8RFgdfJ8TN72f5309XmSMx6S9lnJ/5AvADfy1rfxG4A7gTXkzpg4IeP+nk9uePwMsDR5XDzM+3wasCTp83Lga0n7sO1zQf8v4K0D18O2z+TOslyWPFb0/j7Kus++LIeZmZVU6dNNZmbWD4eEmZmV5JAwM7OSHBJmZlaSQ8LMzEpySJgNQFJ3clXO3scRu1qwpKnKu4Kv2VBT6ZflMCvHnoiYkXURZlnwSMLsECXX/v+mcvd6eErSiUn7FEmPSHomeZ6ctI+TdLdy94VYJuldyVtVS/qucveKeCj5VjWSviBpZfI+t2fUTatwDgmzgTUWTDf9Ud667RFxFrlvtf5T0nYj8MOIOA34MXB90n498GhEnE7uHiArkvZpwE0RcQqwFfho0n4dMDN5n6vT6ZpZ//yNa7MBSNoZESOKtK8Dfj8i1iYXHXw1IsZIep3c9f87k/ZXImKspA5gUkS8mfceU8ld+nta8vorQG1E/HdJPwd2AvcA90TEzpS7anYAjyTMDk+UWC61TTFv5i1389axwj8AbgJ+F1icXLXTbFA5JMwOzx/lPf9nsvwkuSuXAnwceDxZfgS4BvbfRKil1JtKqgKOi4h/J3fjnVbggNGMWdr8l4nZwBqTu8L1+nlE9J4GWy/p1+T+4JqTtH0BWCDpy0AH8Jmk/S+A+ZKuIjdiuIbcFXyLqQZ+JGkUuRvF/O/I3UvCbFD5mITZIUqOScyKiNezrsUsLZ5uMjOzkjySMDOzkjySMDOzkhwSZmZWkkPCzMxKckiYmVlJDgkzMyvp/wP5dMgxSSJ/sgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dinn.losses[0:], color = 'teal')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[1], 'pink', alpha=0.5, lw=2, label='Susceptible')\n",
    "ax.plot(covid_data[0], S_pred_list[0].detach().numpy(), 'red', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[2], 'violet', alpha=0.5, lw=2, label='Infected')\n",
    "ax.plot(covid_data[0], I_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[3], 'darkgreen', alpha=0.5, lw=2, label='Dead')\n",
    "ax.plot(covid_data[0], D_pred_list[0].detach().numpy(), 'green', alpha=0.9, lw=2, label='Dead Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[4], 'blue', alpha=0.5, lw=2, label='Recovered')\n",
    "ax.plot(covid_data[0], R_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='Recovered Prediction', linestyle='dashed')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Number')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
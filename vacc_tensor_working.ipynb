{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "vacc_tensor_test2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JoPs1QTPZtrO",
        "outputId": "2ebbf067-fc2c-4ebe-9266-a9b6221080c8"
      },
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n",
        "os.getcwd() "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/dinn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhy95XbZqOS",
        "outputId": "ea7ab247-38d9-4ffb-b094-7ac55cab97e0"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tSI_vaccination_data = genfromtxt('tSI_vaccination_data.csv', delimiter=',') #in the form of [t, S, I]\n",
        "\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe0da439d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6iFgYfZqOa",
        "outputId": "1e9f3a1d-f02b-4e8c-e236-5d6dead620e4"
      },
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'vacc_tensor_test2.pt' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data): #t, S_data, I_data\n",
        "        super(DINN, self).__init__()\n",
        "        self.t = torch.tensor(t, requires_grad = True).float()\n",
        "        self.t = torch.reshape(self.t, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data) \n",
        "        self.I = torch.tensor(I_data) \n",
        "\n",
        "        self.losses = [] #keep the losses\n",
        "        self.SI_vals = [] #keep the intermediate SI values\n",
        " \n",
        "        #learnable parameters\n",
        "        self.alpha1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.alpha2_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.mu_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.u_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.tao_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "\n",
        "        #NN\n",
        "        self.net_si = self.Net_si()\n",
        "        self.params = list(self.net_si.parameters())\n",
        "        self.params.extend(list([self.mu_tilda, self.beta_tilda, self.alpha1_tilda, self.alpha2_tilda, self.u_tilda, self.tao_tilda]))\n",
        "\n",
        "        \n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha1(self):\n",
        "        return torch.tanh(self.alpha1_tilda) * 2 \n",
        "\n",
        "    @property\n",
        "    def alpha2(self):\n",
        "        return torch.tanh(self.alpha2_tilda) * 0.1\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda) * 0.01\n",
        "\n",
        "    @property\n",
        "    def mu(self):\n",
        "        return torch.tanh(self.mu_tilda) * 6\n",
        "\n",
        "    @property\n",
        "    def u(self):\n",
        "        return torch.tanh(self.u_tilda) \n",
        "\n",
        "    @property\n",
        "    def tao(self):\n",
        "        return torch.tanh(self.tao_tilda) \n",
        "\n",
        "    #nets\n",
        "    class Net_si(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_si, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 32) #takes 100 t's\n",
        "            self.fc2=nn.Linear(32, 32)\n",
        "            self.fc3=nn.Linear(32, 64)\n",
        "            self.fc4=nn.Linear(64, 128)\n",
        "            self.fc5=nn.Linear(128, 128)\n",
        "            self.fc6=nn.Linear(128, 64)\n",
        "            self.fc7=nn.Linear(64, 32)\n",
        "            self.fc8=nn.Linear(32, 32)\n",
        "            self.out=nn.Linear(32, 2) #outputs S, I\n",
        "\n",
        "\n",
        "        def forward(self, t):\n",
        "            si=F.relu(self.fc1(t))\n",
        "            si=F.relu(self.fc2(si))\n",
        "            si=F.relu(self.fc3(si))\n",
        "            si=F.relu(self.fc4(si))\n",
        "            si=F.relu(self.fc5(si))\n",
        "            si=F.relu(self.fc6(si))\n",
        "            si=F.relu(self.fc7(si))\n",
        "            si=F.relu(self.fc8(si))\n",
        "            si=self.out(si)\n",
        "            return si    \n",
        "\n",
        "    def get_SI(self, t_):\n",
        "      net_vals = self.net_si(t_)\n",
        "      self.SI_vals.append(net_vals)\n",
        "      return net_vals\n",
        "\n",
        "    def net_f(self, t):       \n",
        "        self.SI_vals = [] #reset values list\n",
        "\n",
        "        d_SI = torch.autograd.functional.jacobian(self.get_SI, t) #calculate Jacobian\n",
        "\n",
        "        S = (self.SI_vals[0][:,0] - 46.7866) / (2000 - 46.7866)\n",
        "        I = (self.SI_vals[0][:,1] - 0.0807) / (545.5998 - 0.0807)\n",
        "    \n",
        "        S_t = torch.diagonal(torch.diagonal(d_SI, 0, -1), 0)[0] \n",
        "        I_t = torch.diagonal(torch.diagonal(d_SI, 1, -1), 0)[0] \n",
        "\n",
        "        # need to see if this works. if not check S_t -- its the derivative of the unnormalized S, so maybe I need to change this\n",
        "        f1 = (S_t  + self.beta * (S*(2000 - 46.7866) + 46.7866) * (I*(545.5998 - 0.0807) + 0.0807) - self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t)),(1,100)) * (-self.alpha1) * ((S*(2000 - 46.7866) + 46.7866))) / (2000 - 46.7866)\n",
        "        f2 = (I_t  - self.beta * (S*(2000 - 46.7866) + 46.7866) * (I*(545.5998 - 0.0807) + 0.0807) + self.mu * (I*(545.5998 - 0.0807) + 0.0807) - self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t)),(1,100)) * (-self.alpha2) * ((I*(545.5998 - 0.0807) + 0.0807))) / (545.5998 - 0.0807)\n",
        "        return f1, f2, S*(2000 - 46.7866) + 46.7866, I*(545.5998 - 0.0807) + 0.0807\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        print('trying to load...')\n",
        "        checkpoint = torch.load(PATH) \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        self.losses = checkpoint['losses']\n",
        "        print('loaded previous loss: ', loss)\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list= []\n",
        "        I_pred_list= []\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        f1, f2, S_pred, I_pred = self.net_f(self.t)\n",
        "\n",
        "        S_pred_list.append(S_pred)\n",
        "        I_pred_list.append(I_pred)\n",
        "\n",
        "        loss = (torch.mean(torch.square(self.S - S_pred))+torch.mean(torch.square(self.I - I_pred)) \\\n",
        "        +torch.mean(torch.square(f1)) + torch.mean(torch.square(f2))) #/100\n",
        "\n",
        "        #loss.backward(retain_graph=True)\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() #scheduler\n",
        "\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 100 == 0:\n",
        "          #checkpoint save every 1000 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH)\n",
        "\n",
        "          #old_loss = loss #change old loss to current loss\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print('epoch: ', epoch)\n",
        "          print('loss: ' ,loss)\n",
        "          print('alpha1: (goal 1)', self.alpha1)\n",
        "          print('\\nalpha2: (goal 0)', self.alpha2)\n",
        "          print('\\nbeta: (goal 0.0075): ', self.beta)\n",
        "          print('\\nmu (goal 5): ', self.mu)\n",
        "          print('\\nu: (goal 0.515151515): ', self.u)\n",
        "          print('\\ntao (goal 0.58): ', self.tao)\n",
        "          print('#################################')                \n",
        "\n",
        "        \n",
        "      #plot\n",
        "      plt.plot(self.losses, color = 'teal')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      return S_pred_list, I_pred_list"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 53 µs, sys: 0 ns, total: 53 µs\n",
            "Wall time: 57.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1obOwWZqOc",
        "outputId": "8cbad736-b42f-402f-847e-88dddd70e08a"
      },
      "source": [
        "%%time\n",
        "\n",
        "#this worked best\n",
        "\n",
        "dinn = DINN(tSI_vaccination_data[0], tSI_vaccination_data[1], tSI_vaccination_data[2]) #t, S_data, I_data\n",
        "\n",
        "learning_rate = 0.02\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=3000, mode=\"triangular2\", cycle_momentum=False)\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "S_pred_list, I_pred_list = dinn.train(20000) #train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trying to load...\n",
            "\n",
            "loading pre-trained model...\n",
            "loaded previous loss:  tensor(0.0930, dtype=torch.float64, requires_grad=True)\n",
            "\n",
            "starting training...\n",
            "\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  0\n",
            "loss:  tensor(0.0919, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8769], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9465], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6078], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  100\n",
            "loss:  tensor(0.0966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8766], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9468], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6078], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5764], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  200\n",
            "loss:  tensor(0.0920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8765], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9468], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6079], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  300\n",
            "loss:  tensor(0.0941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9464], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6080], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  400\n",
            "loss:  tensor(0.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8765], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9466], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6081], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  500\n",
            "loss:  tensor(0.1144, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8771], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9461], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6084], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  600\n",
            "loss:  tensor(0.0903, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0852], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9466], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6084], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  700\n",
            "loss:  tensor(0.0908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8764], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9466], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6083], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  800\n",
            "loss:  tensor(0.1076, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8769], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9464], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6087], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  900\n",
            "loss:  tensor(0.0897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8766], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9463], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6086], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1000\n",
            "loss:  tensor(0.0938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9459], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6086], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1100\n",
            "loss:  tensor(0.0891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8769], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9462], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6088], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1200\n",
            "loss:  tensor(0.0897, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8765], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9459], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6087], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1300\n",
            "loss:  tensor(0.0894, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8768], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9461], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6090], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1400\n",
            "loss:  tensor(0.0957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8770], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9455], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6090], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5765], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1500\n",
            "loss:  tensor(0.0883, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9460], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6091], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1600\n",
            "loss:  tensor(0.0889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8773], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9457], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6094], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1700\n",
            "loss:  tensor(0.0879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8764], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9459], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6092], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1800\n",
            "loss:  tensor(0.0876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.8767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0853], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([4.9460], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6094], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5766], grad_fn=<TanhBackward>)\n",
            "#################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrvoRWQZqOd"
      },
      "source": [
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Susceptible')\n",
        "ax.plot(tSI_vaccination_data[0], S_pred_list[0].detach().numpy(), 'violet', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Infected')\n",
        "ax.plot(tSI_vaccination_data[0], I_pred_list[0].detach().numpy(), 'darkgreen', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.set_ylabel('Number')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcowlQFZqOe"
      },
      "source": [
        "print('alpha1: (goal 1)', round(dinn.alpha1.item(),2))\n",
        "print('\\nalpha2: (goal 0)', round(dinn.alpha2.item(),2))\n",
        "print('\\nbeta: (goal 0.0075): ', round(dinn.beta.item(),4))\n",
        "print('\\nmu (goal 5): ', round(dinn.mu.item(),2))\n",
        "print('\\nu: (goal 0.515151515): ', round(dinn.u.item(),2))\n",
        "print('\\ntao (goal 0.58): ', round(dinn.tao.item(),2))\n",
        "\n",
        "\n",
        "print('\\nerror:')\n",
        "print('alpha1: ', round((1-round(dinn.alpha1.item(),2))/1,2)*100,'%')\n",
        "print('alpha2: ', round((0-round(dinn.alpha2.item(),2))/1e-20,2)*100,'%')\n",
        "print('beta: ', round((0.0075-round(dinn.beta.item(),4))/0.0075,2)*100,'%')\n",
        "print('mu: ', round((5-round(dinn.mu.item(),2))/5,2)*100,'%')\n",
        "print('u: ', round((0.515151515-round(dinn.u.item(),2))/0.515151515,2)*100,'%')\n",
        "print('tao: ', round((0.58-round(dinn.tao.item(),2))/0.58,2)*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzZI6VMZqOe"
      },
      "source": [
        "#vaccination! \n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initial number of infected individuals, I0\n",
        "I0 = 1\n",
        "# Everyone else, S0, is susceptible to infection initially.\n",
        "S0 = 2000\n",
        "# Contact rate, beta, and mean recovery rate, mu.\n",
        "beta, mu = dinn.beta, dinn.mu\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 3, 100) \n",
        "#parameters\n",
        "u = dinn.u\n",
        "tao = dinn.tao\n",
        "alpha1 = dinn.alpha1\n",
        "alpha2 = dinn.alpha2\n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t, beta, mu, u, tao, alpha1, alpha2):\n",
        "    S, I = y\n",
        "    dSdt = -beta * S * I + u * (t > tao) * alpha1 * (-S)\n",
        "    dIdt = beta * S * I - mu * I + u * (t > tao) * alpha2 * (-I)\n",
        "    return dSdt, dIdt\n",
        "\n",
        "#add u = 0.5, get the corresponding tao, generate the SI data\n",
        "# learn u (self.u), the corresponding tao (self.tao)\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = S0, I0\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t, args=(beta, mu, u, tao, alpha1, alpha2))\n",
        "S, I = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Actual Susceptible')\n",
        "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Learnable Param Susceptible', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Actual Infected')\n",
        "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Learnable Param Infected', linestyle='dashed')\n",
        "ax.set_xlabel('Time /days')\n",
        "#ax.set_ylabel('Number (1000s)')\n",
        "#ax.set_ylim(0,1.2)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICWNogFjn27j"
      },
      "source": [
        "#calculate relative MSE loss\n",
        "import math\n",
        "\n",
        "S_total_loss = 0\n",
        "S_den = 0\n",
        "I_total_loss = 0\n",
        "I_den = 0\n",
        "for timestep in range(len(t)):\n",
        "  S_value = tSI_vaccination_data[1][timestep] - S[timestep]\n",
        "  S_total_loss += S_value**2\n",
        "  S_den += (tSI_vaccination_data[1][timestep])**2\n",
        "  I_value = tSI_vaccination_data[2][timestep] - I[timestep]\n",
        "  I_total_loss += I_value**2\n",
        "  I_den += (tSI_vaccination_data[2][timestep])**2\n",
        "\n",
        "S_total_loss = math.sqrt(S_total_loss/S_den)\n",
        "\n",
        "I_total_loss = math.sqrt(I_total_loss/I_den)\n",
        "print('S_total_loss: ', S_total_loss)\n",
        "print('I_total_loss: ', I_total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfH8jZ8u93OF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
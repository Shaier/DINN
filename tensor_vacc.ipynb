{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "tensor_vacc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoPs1QTPZtrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "787d6035-c73b-4541-b7a2-713ab99685c2"
      },
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n",
        "os.getcwd() "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/dinn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFhy95XbZqOS"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tSI_vaccination_data = genfromtxt('tSI_vaccination_data.csv', delimiter=',') #in the form of [t, S, I]\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "import gc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AD6iFgYfZqOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7aab6d1-62d5-4709-8131-2fc2d6d29feb"
      },
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'tensor_vacc' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data): #t, S_data, I_data\n",
        "        super(DINN, self).__init__()\n",
        "        self.t = torch.tensor(t, requires_grad = True).float()\n",
        "        self.t = torch.reshape(self.t, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data)\n",
        "        self.I = torch.tensor(I_data)\n",
        "\n",
        "        self.losses = [] #keep the losses\n",
        "        self.SI_vals = [] #keep the intermediate SI values\n",
        "        self.save = 2 #which file to save to\n",
        "\n",
        "        #learnable parameters\n",
        "        self.alpha1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.alpha2_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.mu_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.u_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.tao_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "\n",
        "        #NN\n",
        "        self.net_si = self.Net_si()\n",
        "        self.params = list(self.net_si.parameters())\n",
        "        self.params.extend(list([self.mu_tilda, self.beta_tilda, self.alpha1_tilda, self.alpha2_tilda, self.u_tilda, self.tao_tilda]))\n",
        "        \n",
        "        #get values for normalization\n",
        "        self.t_min = torch.min(self.t)\n",
        "        self.t_max = torch.max(self.t)\n",
        "        self.S_min = torch.min(self.S)\n",
        "        self.S_max = torch.max(self.S)\n",
        "        self.I_min = torch.min(self.I)\n",
        "        self.I_max = torch.max(self.I)\n",
        "\n",
        "        #normalize \n",
        "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
        "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
        "        self.t_hat = (self.t - self.t_min) / (self.t_max - self.t_min)        \n",
        "        \n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha1(self):\n",
        "        return torch.tanh(self.alpha1_tilda) * 1.5 \n",
        "\n",
        "    @property\n",
        "    def alpha2(self):\n",
        "        return torch.tanh(self.alpha2_tilda) * 0.2\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda) * 0.03\n",
        "\n",
        "    @property\n",
        "    def mu(self):\n",
        "        return torch.tanh(self.mu_tilda) * 6 + 6\n",
        "\n",
        "    @property\n",
        "    def u(self):\n",
        "        return torch.tanh(self.u_tilda) * 0.8 + 0.8\n",
        "\n",
        "    @property\n",
        "    def tao(self):\n",
        "        return torch.tanh(self.tao_tilda) * 0.8 + 0.8\n",
        "\n",
        "    #nets\n",
        "    class Net_si(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_si, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 32) #takes 100 t's\n",
        "            self.fc2=nn.Linear(32, 32)\n",
        "            self.fc3=nn.Linear(32, 64)\n",
        "            self.fc4=nn.Linear(64, 128)\n",
        "            self.fc5=nn.Linear(128, 128)\n",
        "            self.fc6=nn.Linear(128, 64)\n",
        "            self.fc7=nn.Linear(64, 32)\n",
        "            self.fc8=nn.Linear(32, 32)\n",
        "            self.out=nn.Linear(32, 2) #outputs S, I\n",
        "\n",
        "\n",
        "        def forward(self, t):\n",
        "            si=F.relu(self.fc1(t))\n",
        "            si=F.relu(self.fc2(si))\n",
        "            si=F.relu(self.fc3(si))\n",
        "            si=F.relu(self.fc4(si))\n",
        "            si=F.relu(self.fc5(si))\n",
        "            si=F.relu(self.fc6(si))\n",
        "            si=F.relu(self.fc7(si))\n",
        "            si=F.relu(self.fc8(si))\n",
        "            si=self.out(si)\n",
        "            return si    \n",
        "\n",
        "    def get_SI(self, t_):\n",
        "      net_vals = self.net_si(t_) #NN\n",
        "      self.SI_vals.append(net_vals) #save values\n",
        "      return net_vals\n",
        "\n",
        "    def net_f(self, t_hat):       \n",
        "        # our NN take as input normalized data and outputs normalized data \n",
        "      \n",
        "        #reset values list\n",
        "        self.SI_vals = [] \n",
        "\n",
        "        #calculate Jacobian and place the network values (SI) inside self.SI_vals\n",
        "        #d_SI = torch.autograd.functional.jacobian(self.get_SI, (t_normed)) \n",
        "        d_SI = torch.autograd.functional.jacobian(self.get_SI, t_hat) \n",
        "\n",
        "        S_hat = self.SI_vals[0][:,0] #normalized S (since the input to the NN was a normalized t)\n",
        "        I_hat = self.SI_vals[0][:,1] #normalized I (since the input to the NN was a normalized t)\n",
        "    \n",
        "        S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
        "        I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
        "        t = self.t_min + (self.t_max - self.t_min) * t_hat\n",
        "\n",
        "        S_hat_t_hat = torch.diagonal(torch.diagonal(d_SI, 0, -1), 0)[0] #get the S_t vector from the diagonal of the Jacobian\n",
        "        I_hat_t_hat = torch.diagonal(torch.diagonal(d_SI, 1, -1), 0)[0] #get the I_t vector from the other diagonal of the Jacobian        \n",
        "\n",
        "        #f1_hat =  S_t - ((t_max - t_min)/S_max) * (-self.beta * (S * (S_max - S_min) + S_min) * (I * (I_max - I_min) + I_min) + self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - (t_normed * (t_max - t_min) + t_min) )),(1,100)) * (-self.alpha1) * (S * (S_max - S_min) + S_min)) \n",
        "        #f2_hat = I_t - ((t_max - t_min)/I_max) * (-self.beta * (S * (S_max - S_min) + S_min)  * (I * (I_max - I_min) + I_min) - self.mu * (I * (I_max - I_min) + I_min) + self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - (t_normed * (t_max - t_min) + t_min) )),(1,100)) * (-self.alpha2) * (I * (I_max - I_min) + I_min)) \n",
        "        f1_hat = S_hat_t_hat  - (- self.beta * S * I  + self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t)),(1,100)) * (- self.alpha1) * S) * ((self.t_max - self.t_min)/(self.S_max - self.S_min))\n",
        "        f2_hat = I_hat_t_hat  - (self.beta * S * I  - self.mu * I + self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t)),(1,100)) * (-self.alpha2) * I)* ((self.t_max - self.t_min)/(self.I_max - self.I_min))\n",
        "        return f1_hat, f2_hat, S_hat, I_hat\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        print('trying to load...')\n",
        "        checkpoint = torch.load(PATH) \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        self.losses = checkpoint['losses']\n",
        "        print('loaded previous loss: ', loss)\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list= []\n",
        "        I_pred_list= []\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        f1_hat, f2_hat, S_pred, I_pred = self.net_f(self.t)\n",
        "\n",
        "        #un-normalize\n",
        "        #S_pred = S_pred * torch.max(self.S) + torch.min(self.S)\n",
        "        #I_pred = I_pred * torch.max(self.I) + torch.min(self.I)\n",
        "        #print('s_pred', S_pred)\n",
        "\n",
        "        S_pred_list.append(S_pred)\n",
        "        I_pred_list.append(I_pred)\n",
        "\n",
        "        loss = torch.mean(torch.square(self.S_hat - S_pred))+torch.mean(torch.square(self.I_hat - I_pred)) \\\n",
        "        + torch.mean(torch.square(f1_hat)) + torch.mean(torch.square(f2_hat)) \n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() #scheduler\n",
        "\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 100 == 0:\n",
        "          #checkpoint save every 1000 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH + str(self.save)+'.pt')\n",
        "          if self.save % 2 > 0: #its on 3\n",
        "            self.save = 2 #change to 2\n",
        "          else: #its on 2\n",
        "            self.save = 3 #change to 3\n",
        "\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print('epoch: ', epoch)\n",
        "          print('loss: ' ,loss)\n",
        "          print('alpha1: (goal 1)', self.alpha1)\n",
        "          print('\\nalpha2: (goal 0)', self.alpha2)\n",
        "          print('\\nbeta: (goal 0.0075): ', self.beta)\n",
        "          print('\\nmu (goal 5): ', self.mu)\n",
        "          print('\\nu: (goal 0.515151515): ', self.u)\n",
        "          print('\\ntao (goal 0.58): ', self.tao)\n",
        "          print('#################################')                \n",
        "\n",
        "        \n",
        "      #plot\n",
        "      plt.plot(self.losses, color = 'teal')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      return S_pred_list, I_pred_list"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 47 µs, sys: 9 µs, total: 56 µs\n",
            "Wall time: 58.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_P1obOwWZqOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc211040-506a-4cd8-cbac-e98156262892"
      },
      "source": [
        "%%time\n",
        "\n",
        "#this worked best\n",
        "\n",
        "dinn = DINN(tSI_vaccination_data[0], tSI_vaccination_data[1], tSI_vaccination_data[2]) #t, S_data, I_data\n",
        "\n",
        "learning_rate = 0.02\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=1000, mode=\"triangular2\", cycle_momentum=False)\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "S_pred_list, I_pred_list = dinn.train(70000) #train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trying to load...\n",
            "\n",
            "starting training...\n",
            "\n",
            "\n",
            "Saving model... Loss is:  tensor(4.1143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  0\n",
            "loss:  tensor(4.1143, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.0435], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0763], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.1062], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8466], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2838], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(1.3527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  100\n",
            "loss:  tensor(1.3527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.0518], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0755], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0806], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8428], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2854], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  200\n",
            "loss:  tensor(0.2929, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.0503], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0753], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0748], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8418], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2855], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  300\n",
            "loss:  tensor(0.2809, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.0405], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0753], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0748], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8412], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2856], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  400\n",
            "loss:  tensor(0.1880, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.0855], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0753], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0742], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8452], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2833], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  500\n",
            "loss:  tensor(0.1810, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.1634], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0752], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0745], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8636], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2635], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1635, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  600\n",
            "loss:  tensor(0.1635, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2265], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0751], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0077], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0753], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.8892], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2637], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  700\n",
            "loss:  tensor(0.1563, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2655], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0750], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0077], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0742], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9089], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2670], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  800\n",
            "loss:  tensor(0.1721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2658], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0746], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0673], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9076], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2718], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  900\n",
            "loss:  tensor(0.1597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3145], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0744], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0652], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9361], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2676], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1000\n",
            "loss:  tensor(0.1491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3720], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0742], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0077], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0640], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9749], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2627], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1100\n",
            "loss:  tensor(0.1795, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3669], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0740], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0077], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0617], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9709], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2631], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1200\n",
            "loss:  tensor(0.1715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3410], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0738], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0664], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9529], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2632], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1300\n",
            "loss:  tensor(0.1721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3326], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0736], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0669], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9469], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2634], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1400\n",
            "loss:  tensor(0.1708, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3319], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0734], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0671], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9458], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2637], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1500\n",
            "loss:  tensor(0.1703, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3379], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0732], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0074], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0680], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9491], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2639], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1600\n",
            "loss:  tensor(0.1692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3449], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0731], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0074], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0689], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9533], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2643], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1700\n",
            "loss:  tensor(0.1679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3503], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0730], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0698], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9565], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2647], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1800\n",
            "loss:  tensor(0.1675, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3509], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0729], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0700], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9566], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2653], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1900\n",
            "loss:  tensor(0.1667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3501], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0728], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0700], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9559], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2660], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2000\n",
            "loss:  tensor(0.1665, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3501], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0728], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0700], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9558], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2666], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2100\n",
            "loss:  tensor(0.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3500], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0728], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0700], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9557], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2672], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2200\n",
            "loss:  tensor(0.1655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3509], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0727], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0699], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9562], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2721], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2300\n",
            "loss:  tensor(0.1649, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3551], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0727], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0698], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9587], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2720], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2400\n",
            "loss:  tensor(0.1661, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3583], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0726], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0697], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9606], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2720], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2500\n",
            "loss:  tensor(0.1640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3599], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0724], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0690], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9612], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2721], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2600\n",
            "loss:  tensor(0.1621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3601], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0722], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0676], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9607], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2720], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2700\n",
            "loss:  tensor(0.1621, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3614], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0719], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0653], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9607], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2721], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2800\n",
            "loss:  tensor(0.1592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3617], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0715], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0616], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9599], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2720], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2900\n",
            "loss:  tensor(0.1540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3651], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0710], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0073], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0560], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9608], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2719], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3000\n",
            "loss:  tensor(0.1512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3729], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0704], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0074], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0486], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9646], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3100\n",
            "loss:  tensor(0.1491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3735], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0697], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0074], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0399], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9633], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2717], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3200\n",
            "loss:  tensor(0.1509, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3723], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0691], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0312], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9609], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2716], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3300\n",
            "loss:  tensor(0.1471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3743], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0686], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0242], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9611], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2718], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3400\n",
            "loss:  tensor(0.1455, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3825], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0682], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0189], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9656], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3500\n",
            "loss:  tensor(0.1440, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3845], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0678], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0135], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9662], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3600\n",
            "loss:  tensor(0.1435, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3890], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0674], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0089], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9685], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3700\n",
            "loss:  tensor(0.1429, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3882], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0671], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0049], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9674], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3800\n",
            "loss:  tensor(0.1420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3885], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0669], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([8.0018], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9671], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3900\n",
            "loss:  tensor(0.1412, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3892], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0668], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9998], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9673], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4000\n",
            "loss:  tensor(0.1405, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3893], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0667], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9990], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9672], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4100\n",
            "loss:  tensor(0.1407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3890], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0667], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9983], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9670], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4200\n",
            "loss:  tensor(0.1399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3884], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0666], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9969], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9664], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2721], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4300\n",
            "loss:  tensor(0.1394, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3878], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0664], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9946], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9656], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2721], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4400\n",
            "loss:  tensor(0.1393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3864], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0662], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9912], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9642], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2722], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4500\n",
            "loss:  tensor(0.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3863], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0659], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9867], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9635], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2717], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4600\n",
            "loss:  tensor(0.1397, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3922], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0657], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9830], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9670], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2717], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4700\n",
            "loss:  tensor(0.1386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4006], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0653], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9788], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9721], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2716], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4800\n",
            "loss:  tensor(0.1400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4034], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0649], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9729], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9733], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2715], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4900\n",
            "loss:  tensor(0.1392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4004], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0644], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9663], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9705], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2736], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5000\n",
            "loss:  tensor(0.1380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4049], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0637], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9587], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9725], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2734], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5100\n",
            "loss:  tensor(0.1353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3850], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0630], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0075], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9469], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9588], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2736], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5200\n",
            "loss:  tensor(0.1354, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3735], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0622], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9350], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9509], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2736], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5300\n",
            "loss:  tensor(0.1335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3735], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0616], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0076], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9248], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9501], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2729], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5400\n",
            "loss:  tensor(0.1344, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3523], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0608], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0077], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.9093], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9368], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2736], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5500\n",
            "loss:  tensor(0.1336, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3452], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0600], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0078], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8934], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9319], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2730], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5600\n",
            "loss:  tensor(0.1335, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3361], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0592], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0079], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8764], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9261], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2729], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5700\n",
            "loss:  tensor(0.1349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3308], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0585], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0080], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8621], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9226], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2714], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5800\n",
            "loss:  tensor(0.1358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3346], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0580], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0081], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8515], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9241], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2708], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5900\n",
            "loss:  tensor(0.1367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3359], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0576], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0081], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8435], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9244], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2715], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6000\n",
            "loss:  tensor(0.1366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3347], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0574], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8391], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9235], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2711], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6100\n",
            "loss:  tensor(0.1365, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3354], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0573], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8360], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9238], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2710], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6200\n",
            "loss:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3361], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0570], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8299], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9239], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2711], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6300\n",
            "loss:  tensor(0.1371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3405], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0566], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0083], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8218], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9259], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2709], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6400\n",
            "loss:  tensor(0.1374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3478], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0561], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0084], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.8108], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9295], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2698], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6500\n",
            "loss:  tensor(0.1399, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3537], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0555], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7977], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9323], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2701], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6600\n",
            "loss:  tensor(0.1419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3626], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0548], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0086], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7826], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9369], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2703], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6700\n",
            "loss:  tensor(0.1414, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3817], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0541], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0086], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7689], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9477], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2709], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6800\n",
            "loss:  tensor(0.1436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3970], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0535], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0087], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7557], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9566], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2714], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6900\n",
            "loss:  tensor(0.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4145], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0528], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0087], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7430], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9670], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2715], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7000\n",
            "loss:  tensor(0.1421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4364], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0521], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0087], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7325], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9806], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2715], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7100\n",
            "loss:  tensor(0.1424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4432], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0513], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0087], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7182], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9846], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2716], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7200\n",
            "loss:  tensor(0.1426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4436], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0505], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0087], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.7031], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9845], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2716], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7300\n",
            "loss:  tensor(0.1433, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4526], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0499], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0086], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6922], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9900], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2708], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7400\n",
            "loss:  tensor(0.1404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4667], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0493], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0086], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6822], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9989], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2710], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7500\n",
            "loss:  tensor(0.1390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4724], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0487], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0086], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6713], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0024], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2713], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7600\n",
            "loss:  tensor(0.1398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4813], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0482], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6645], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0080], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2704], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7700\n",
            "loss:  tensor(0.1410, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4854], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0479], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6589], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0105], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2712], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7800\n",
            "loss:  tensor(0.1385, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4876], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0476], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6543], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0119], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2710], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7900\n",
            "loss:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4882], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0474], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6507], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0122], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2713], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8000\n",
            "loss:  tensor(0.1379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4886], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0473], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6487], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0124], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2714], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8100\n",
            "loss:  tensor(0.1377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4894], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0472], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0084], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6470], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0129], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2714], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8200\n",
            "loss:  tensor(0.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4892], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0470], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0084], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6443], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0127], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2720], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8300\n",
            "loss:  tensor(0.1372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4877], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0468], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0084], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6403], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0117], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2718], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8400\n",
            "loss:  tensor(0.1372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4861], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0465], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0084], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6357], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0106], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2714], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8500\n",
            "loss:  tensor(0.1362, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4878], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0462], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0083], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6305], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0117], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2716], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8600\n",
            "loss:  tensor(0.1343, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4891], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0459], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0083], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6241], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0124], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2715], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8700\n",
            "loss:  tensor(0.1356, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4842], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0453], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6142], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0092], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2711], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8800\n",
            "loss:  tensor(0.1338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4792], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0447], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.6023], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0061], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2709], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8900\n",
            "loss:  tensor(0.1331, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4750], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0440], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0082], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.5884], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([1.0035], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2708], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9000\n",
            "loss:  tensor(0.1329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4694], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0432], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0081], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.5721], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9999], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2708], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9100\n",
            "loss:  tensor(0.1314, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4664], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0423], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0081], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.5542], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9980], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2711], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9200\n",
            "loss:  tensor(0.1309, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4656], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0414], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0081], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.5358], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9974], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2717], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9300\n",
            "loss:  tensor(0.1307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4633], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0405], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0080], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.5168], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9959], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2718], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9400\n",
            "loss:  tensor(0.1305, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4628], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0397], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0080], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.4995], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9955], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2719], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9500\n",
            "loss:  tensor(0.1312, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4631], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0390], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0080], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.4838], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9955], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2707], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9600\n",
            "loss:  tensor(0.1303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4620], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0384], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0080], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([7.4699], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.9947], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([1.2719], grad_fn=<AddBackward0>)\n",
            "#################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrvoRWQZqOd"
      },
      "source": [
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Susceptible')\n",
        "ax.plot(tSI_vaccination_data[0], S_pred_list[0].detach().numpy(), 'violet', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Infected')\n",
        "ax.plot(tSI_vaccination_data[0], I_pred_list[0].detach().numpy(), 'darkgreen', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.set_ylabel('Number')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysSEosjd8Bhu"
      },
      "source": [
        "[1]*10**10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcowlQFZqOe"
      },
      "source": [
        "print('alpha1: (goal 1)', round(dinn.alpha1.item(),2))\n",
        "print('\\nalpha2: (goal 0)', round(dinn.alpha2.item(),2))\n",
        "print('\\nbeta: (goal 0.0075): ', round(dinn.beta.item(),4))\n",
        "print('\\nmu (goal 5): ', round(dinn.mu.item(),2))\n",
        "print('\\nu: (goal 0.515151515): ', round(dinn.u.item(),2))\n",
        "print('\\ntao (goal 0.58): ', round(dinn.tao.item(),2))\n",
        "\n",
        "\n",
        "print('\\nerror:')\n",
        "print('alpha1: ', round((1-round(dinn.alpha1.item(),2))/1,2)*100,'%')\n",
        "print('alpha2: ', round((0-round(dinn.alpha2.item(),2))/1e-20,2)*100,'%')\n",
        "print('beta: ', round((0.0075-round(dinn.beta.item(),4))/0.0075,2)*100,'%')\n",
        "print('mu: ', round((5-round(dinn.mu.item(),2))/5,2)*100,'%')\n",
        "print('u: ', round((0.515151515-round(dinn.u.item(),2))/0.515151515,2)*100,'%')\n",
        "print('tao: ', round((0.58-round(dinn.tao.item(),2))/0.58,2)*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzZI6VMZqOe"
      },
      "source": [
        "#vaccination! \n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initial number of infected individuals, I0\n",
        "I0 = 1\n",
        "# Everyone else, S0, is susceptible to infection initially.\n",
        "S0 = 2000\n",
        "# Contact rate, beta, and mean recovery rate, mu.\n",
        "beta, mu = dinn.beta, dinn.mu\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 3, 100) \n",
        "#parameters\n",
        "u = dinn.u\n",
        "tao = dinn.tao\n",
        "alpha1 = dinn.alpha1\n",
        "alpha2 = dinn.alpha2\n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t, beta, mu, u, tao, alpha1, alpha2):\n",
        "    S, I = y\n",
        "    dSdt = -beta * S * I + u * (t > tao) * alpha1 * (-S)\n",
        "    dIdt = beta * S * I - mu * I + u * (t > tao) * alpha2 * (-I)\n",
        "    return dSdt, dIdt\n",
        "\n",
        "#add u = 0.5, get the corresponding tao, generate the SI data\n",
        "# learn u (self.u), the corresponding tao (self.tao)\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = S0, I0\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t, args=(beta, mu, u, tao, alpha1, alpha2))\n",
        "S, I = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Actual Susceptible')\n",
        "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Learnable Param Susceptible', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Actual Infected')\n",
        "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Learnable Param Infected', linestyle='dashed')\n",
        "ax.set_xlabel('Time /days')\n",
        "#ax.set_ylabel('Number (1000s)')\n",
        "#ax.set_ylim(0,1.2)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICWNogFjn27j"
      },
      "source": [
        "#calculate relative MSE loss\n",
        "import math\n",
        "\n",
        "S_total_loss = 0\n",
        "S_den = 0\n",
        "I_total_loss = 0\n",
        "I_den = 0\n",
        "for timestep in range(len(t)):\n",
        "  S_value = tSI_vaccination_data[1][timestep] - S[timestep]\n",
        "  S_total_loss += S_value**2\n",
        "  S_den += (tSI_vaccination_data[1][timestep])**2\n",
        "  I_value = tSI_vaccination_data[2][timestep] - I[timestep]\n",
        "  I_total_loss += I_value**2\n",
        "  I_den += (tSI_vaccination_data[2][timestep])**2\n",
        "\n",
        "S_total_loss = math.sqrt(S_total_loss/S_den)\n",
        "\n",
        "I_total_loss = math.sqrt(I_total_loss/I_den)\n",
        "print('S_total_loss: ', S_total_loss)\n",
        "print('I_total_loss: ', I_total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfH8jZ8u93OF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
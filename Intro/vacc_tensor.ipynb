{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vacc_tensor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoPs1QTPZtrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "def5fb5b-2ae9-49f3-9154-cde9071f593f"
      },
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n",
        "os.getcwd() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/dinn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFhy95XbZqOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5a5192-1408-41de-c5ca-8164bdd566b0"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tSI_vaccination_data = genfromtxt('tSI_vaccination_data.csv', delimiter=',') #in the form of [t, S, I]\n",
        "\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f26aa580430>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD6iFgYfZqOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e248d6b9-ab76-4476-e1bb-10b397e40586"
      },
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'vacc_tensor' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data): #t, S_data, I_data\n",
        "        super(DINN, self).__init__()\n",
        "        self.t = torch.tensor(t, requires_grad=True)\n",
        "        self.t_float = self.t.float()\n",
        "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data) \n",
        "        self.I = torch.tensor(I_data) \n",
        "\n",
        "        self.losses = [] #keep the losses\n",
        "        self.save = 3 #which file to save to\n",
        " \n",
        "        #learnable parameters\n",
        "        self.alpha1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.alpha2_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.mu_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.u_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.tao_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "\n",
        "        #matrices (x2 for S,I) for the gradients\n",
        "        self.m1 = torch.zeros((len(self.t), 2)); self.m1[:, 0] = 1\n",
        "        self.m2 = torch.zeros((len(self.t), 2)); self.m2[:, 1] = 1\n",
        "\n",
        "        #NN\n",
        "        self.net_si = self.Net_si()\n",
        "        self.params = list(self.net_si.parameters())\n",
        "        self.params.extend(list([self.mu_tilda, self.beta_tilda, self.alpha1_tilda, self.alpha2_tilda, self.u_tilda, self.tao_tilda]))\n",
        "\n",
        "        \n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha1(self):\n",
        "        return torch.tanh(self.alpha1_tilda) * 0.1 + 1 \n",
        "\n",
        "    @property\n",
        "    def alpha2(self):\n",
        "        return torch.tanh(self.alpha2_tilda) * 0.1\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda) * 0.01\n",
        "\n",
        "    @property\n",
        "    def mu(self):\n",
        "        return torch.tanh(self.mu_tilda) * 6 + 6\n",
        "\n",
        "    @property\n",
        "    def u(self):\n",
        "        return torch.tanh(self.u_tilda) * 0.1 + 0.5\n",
        "\n",
        "    @property\n",
        "    def tao(self):\n",
        "        return torch.tanh(self.tao_tilda) * 0.1 + 0.5\n",
        "\n",
        "    #nets\n",
        "    class Net_si(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_si, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
        "            self.fc2=nn.Linear(20, 20)\n",
        "            self.fc3=nn.Linear(20, 20)\n",
        "            self.fc4=nn.Linear(20, 20)\n",
        "            self.fc5=nn.Linear(20, 20)\n",
        "            self.fc6=nn.Linear(20, 20)\n",
        "            self.fc7=nn.Linear(20, 20)\n",
        "            self.fc8=nn.Linear(20, 20)\n",
        "            self.out=nn.Linear(20, 2) #outputs S, I\n",
        "\n",
        "        def forward(self, t):\n",
        "            si=F.relu(self.fc1(t))\n",
        "            si=F.relu(self.fc2(si))\n",
        "            si=F.relu(self.fc3(si))\n",
        "            si=F.relu(self.fc4(si))\n",
        "            si=F.relu(self.fc5(si))\n",
        "            si=F.relu(self.fc6(si))\n",
        "            si=F.relu(self.fc7(si))\n",
        "            si=F.relu(self.fc8(si))\n",
        "            si=self.out(si)\n",
        "            return si    \n",
        "\n",
        "    def net_f(self, t_batch):       \n",
        "        si = self.net_si(t_batch)\n",
        "\n",
        "        S,I = si[:,0], si[:,1]\n",
        "\n",
        "        #S_t\n",
        "        si.backward(self.m1, retain_graph=True)\n",
        "        S_t = self.t.grad\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #I_t\n",
        "        si.backward(self.m2, retain_graph=True)\n",
        "        I_t = self.t.grad\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        f1 = S_t + self.beta * S * I - self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t_batch)),(1,100)) * (-self.alpha1) * S \n",
        "        f2 = I_t  - self.beta * S * I + self.mu * I - self.u * torch.reshape(torch.nn.Sigmoid()(-1e3*(self.tao - t_batch)),(1,100)) * (-self.alpha2) * I \n",
        "        return f1, f2, S, I\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        print('trying to load...')\n",
        "        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        self.losses = checkpoint['losses']\n",
        "        print('loaded previous loss: ', loss)\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list= []\n",
        "        I_pred_list= []\n",
        "\n",
        "\n",
        "        f1, f2, S_pred, I_pred = self.net_f(self.t_batch)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        S_pred_list.append(S_pred)\n",
        "        I_pred_list.append(I_pred)\n",
        "\n",
        "        loss =  (torch.mean(torch.square(self.S - S_pred)) + torch.mean(torch.square(self.I - I_pred))+\n",
        "                torch.mean(torch.square(f1)) + torch.mean(torch.square(f2)))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() #scheduler\n",
        "\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 1000 == 0:\n",
        "          #checkpoint save every 1000 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH + str(self.save)+'.pt')\n",
        "          if self.save % 2 > 0: #its on 3\n",
        "            self.save = 2 #change to 2\n",
        "          else: #its on 2\n",
        "            self.save = 3 #change to 3\n",
        "\n",
        "          print('epoch: ', epoch)\n",
        "          print('alpha1: (goal 1)', self.alpha1)\n",
        "          print('\\nalpha2: (goal 0)', self.alpha2)\n",
        "          print('\\nbeta: (goal 0.0075): ', self.beta)\n",
        "          print('\\nmu (goal 5): ', self.mu)\n",
        "          print('\\nu: (goal 0.515151515): ', self.u)\n",
        "          print('\\ntao (goal 0.58): ', self.tao)\n",
        "          print('#################################')\n",
        "        \n",
        "      #plot\n",
        "      plt.plot(self.losses, color = 'teal')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      return S_pred_list, I_pred_list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 63 µs, sys: 0 ns, total: 63 µs\n",
            "Wall time: 67.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1obOwWZqOc",
        "outputId": "cdde059f-6b64-4167-b6ba-65b98b724a70"
      },
      "source": [
        "%%time\n",
        "\n",
        "#this worked best\n",
        "\n",
        "dinn = DINN(tSI_vaccination_data[0], tSI_vaccination_data[1], tSI_vaccination_data[2]) #t, S_data, I_data\n",
        "\n",
        "learning_rate = 0.02\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-6, max_lr=5e-4, step_size_up=3000, mode=\"triangular2\", cycle_momentum=False)\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "S_pred_list, I_pred_list = dinn.train(100000) #train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trying to load...\n",
            "\n",
            "loading pre-trained model...\n",
            "loaded previous loss:  tensor(44636.1911, dtype=torch.float64, requires_grad=True)\n",
            "\n",
            "starting training...\n",
            "\n",
            "\n",
            "Saving model... Loss is:  tensor(44636.1912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  0\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0791], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4339], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5910], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44636.0564, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  1000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0791], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4340], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5910], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.9225, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  2000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0790], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4342], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5910], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.7879, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  3000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0790], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4344], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5910], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.6543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  4000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0790], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4346], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5910], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.5214, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  5000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0789], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4348], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.3877, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  6000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0789], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4350], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.2552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  7000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0788], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4352], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44635.1233, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  8000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0788], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4354], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.9912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  9000\n",
            "alpha1: (goal 1) tensor([0.9018], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0788], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4356], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.8589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  10000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0787], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4358], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5911], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.7275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  11000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0787], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4361], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.5966, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  12000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0787], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4363], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  13000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0786], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4365], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.3349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  14000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0786], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4367], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.2046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  15000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0786], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4370], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44634.0749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  16000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0785], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4372], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5912], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.9445, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  17000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0785], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4373], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.8151, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  18000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0784], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4376], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.6865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  19000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0784], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4378], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.5569, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  20000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0784], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4380], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.4283, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  21000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0783], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4382], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.3001, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  22000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0783], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4384], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.1716, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  23000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0783], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4386], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5913], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44633.0436, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  24000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0782], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4389], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5914], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44632.9155, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  25000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0782], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4391], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5914], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44632.7882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  26000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0781], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4393], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5914], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44632.6613, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  27000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0781], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4395], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5914], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44632.5345, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "epoch:  28000\n",
            "alpha1: (goal 1) tensor([0.9017], grad_fn=<AddBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([0.0781], grad_fn=<MulBackward0>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0099], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([11.4397], grad_fn=<AddBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.4018], grad_fn=<AddBackward0>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.5914], grad_fn=<AddBackward0>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(44632.4073, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY71fo4_Ic_N"
      },
      "source": [
        "plt.plot(dinn.losses[90000:], color = 'teal')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrvoRWQZqOd"
      },
      "source": [
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Susceptible')\n",
        "ax.plot(tSI_vaccination_data[0], S_pred_list[0].detach().numpy(), 'violet', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Infected')\n",
        "ax.plot(tSI_vaccination_data[0], I_pred_list[0].detach().numpy(), 'darkgreen', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.set_ylabel('Number')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcowlQFZqOe"
      },
      "source": [
        "print('alpha1: (goal 1)', round(dinn.alpha1.item(),2))\n",
        "print('\\nalpha2: (goal 0)', round(dinn.alpha2.item(),2))\n",
        "print('\\nbeta: (goal 0.0075): ', round(dinn.beta.item(),4))\n",
        "print('\\nmu (goal 5): ', round(dinn.mu.item(),2))\n",
        "print('\\nu: (goal 0.515151515): ', round(dinn.u.item(),2))\n",
        "print('\\ntao (goal 0.58): ', round(dinn.tao.item(),2))\n",
        "\n",
        "\n",
        "print('\\nerror:')\n",
        "print('alpha1: ', round((1-round(dinn.alpha1.item(),2))/1,2)*100,'%')\n",
        "print('alpha2: ', round((0-round(dinn.alpha2.item(),2))/1e-20,2)*100,'%')\n",
        "print('beta: ', round((0.0075-round(dinn.beta.item(),4))/0.0075,2)*100,'%')\n",
        "print('mu: ', round((5-round(dinn.mu.item(),2))/5,2)*100,'%')\n",
        "print('u: ', round((0.515151515-round(dinn.u.item(),2))/0.515151515,2)*100,'%')\n",
        "print('tao: ', round((0.58-round(dinn.tao.item(),2))/0.58,2)*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzZI6VMZqOe"
      },
      "source": [
        "#vaccination! \n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initial number of infected individuals, I0\n",
        "I0 = 1\n",
        "# Everyone else, S0, is susceptible to infection initially.\n",
        "S0 = 2000\n",
        "# Contact rate, beta, and mean recovery rate, mu.\n",
        "beta, mu = dinn.beta, dinn.mu\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 3, 100) \n",
        "#parameters\n",
        "u = dinn.u\n",
        "tao = dinn.tao\n",
        "alpha1 = dinn.alpha1\n",
        "alpha2 = dinn.alpha2\n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t, beta, mu, u, tao, alpha1, alpha2):\n",
        "    S, I = y\n",
        "    dSdt = -beta * S * I + u * (t > tao) * alpha1 * (-S)\n",
        "    dIdt = beta * S * I - mu * I + u * (t > tao) * alpha2 * (-I)\n",
        "    return dSdt, dIdt\n",
        "\n",
        "#add u = 0.5, get the corresponding tao, generate the SI data\n",
        "# learn u (self.u), the corresponding tao (self.tao)\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = S0, I0\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t, args=(beta, mu, u, tao, alpha1, alpha2))\n",
        "S, I = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Actual Susceptible')\n",
        "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Learnable Param Susceptible', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Actual Infected')\n",
        "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Learnable Param Infected', linestyle='dashed')\n",
        "ax.set_xlabel('Time /days')\n",
        "#ax.set_ylabel('Number (1000s)')\n",
        "#ax.set_ylim(0,1.2)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICWNogFjn27j"
      },
      "source": [
        "#calculate relative MSE loss\n",
        "import math\n",
        "\n",
        "S_total_loss = 0\n",
        "S_den = 0\n",
        "I_total_loss = 0\n",
        "I_den = 0\n",
        "for timestep in range(len(t)):\n",
        "  S_value = tSI_vaccination_data[1][timestep] - S[timestep]\n",
        "  S_total_loss += S_value**2\n",
        "  S_den += (tSI_vaccination_data[1][timestep])**2\n",
        "  I_value = tSI_vaccination_data[2][timestep] - I[timestep]\n",
        "  I_total_loss += I_value**2\n",
        "  I_den += (tSI_vaccination_data[2][timestep])**2\n",
        "\n",
        "S_total_loss = math.sqrt(S_total_loss/S_den)\n",
        "\n",
        "I_total_loss = math.sqrt(I_total_loss/I_den)\n",
        "print('S_total_loss: ', S_total_loss)\n",
        "print('I_total_loss: ', I_total_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfH8jZ8u93OF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
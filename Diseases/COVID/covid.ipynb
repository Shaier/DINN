{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhy95XbZqOS",
        "outputId": "559d6a4a-382c-4eec-feaf-70762574023f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "sidr_data = genfromtxt('sidr.csv', delimiter=',') #in the form of [t,S,I,D,R]\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6iFgYfZqOa",
        "outputId": "fb78a6fd-55e2-4445-8a04-a5407375b77b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'sidr_norm_simple' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
        "        super(DINN, self).__init__()\n",
        "        self.N = 59e6 #population size\n",
        "        self.t = torch.tensor(t, requires_grad=True)\n",
        "        self.t_float = self.t.float()\n",
        "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data)\n",
        "        self.I = torch.tensor(I_data)\n",
        "        self.D = torch.tensor(D_data)\n",
        "        self.R = torch.tensor(R_data)\n",
        "\n",
        "        self.losses = []\n",
        "        self.save = 2 #which file to save to\n",
        "\n",
        "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        \n",
        "        #find values for normalization\n",
        "        self.S_max = max(self.S)\n",
        "        self.I_max = max(self.I)\n",
        "        self.D_max = max(self.D)\n",
        "        self.R_max = max(self.R)\n",
        "        self.S_min = min(self.S)\n",
        "        self.I_min = min(self.I)\n",
        "        self.D_min = min(self.D)\n",
        "        self.R_min = min(self.R)\n",
        "\n",
        "        #normalize\n",
        "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
        "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
        "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
        "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n",
        "\n",
        "        #matrices (x4 for S,I,D,R) for the gradients\n",
        "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
        "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
        "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
        "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
        "\n",
        "        #NN\n",
        "        self.net_sidr = self.Net_sidr()\n",
        "        self.params = list(self.net_sidr.parameters())\n",
        "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
        "\n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
        "    \n",
        "    @property\n",
        "    def gamma(self):\n",
        "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
        "\n",
        "\n",
        "    #nets\n",
        "    class Net_sidr(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_sidr, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
        "            self.fc2=nn.Linear(20, 20)\n",
        "            self.fc3=nn.Linear(20, 20)\n",
        "            self.fc4=nn.Linear(20, 20)\n",
        "            self.fc5=nn.Linear(20, 20)\n",
        "            self.fc6=nn.Linear(20, 20)\n",
        "            self.fc7=nn.Linear(20, 20)\n",
        "            self.fc8=nn.Linear(20, 20)\n",
        "            self.out=nn.Linear(20, 4) #outputs S, I, D, R\n",
        "\n",
        "        def forward(self, t_batch):\n",
        "            sidr=F.relu(self.fc1(t_batch))\n",
        "            sidr=F.relu(self.fc2(sidr))\n",
        "            sidr=F.relu(self.fc3(sidr))\n",
        "            sidr=F.relu(self.fc4(sidr))\n",
        "            sidr=F.relu(self.fc5(sidr))\n",
        "            sidr=F.relu(self.fc6(sidr))\n",
        "            sidr=F.relu(self.fc7(sidr))\n",
        "            sidr=F.relu(self.fc8(sidr))\n",
        "            sidr=self.out(sidr)\n",
        "            return sidr\n",
        "            \n",
        "    def net_f(self, t_batch):\n",
        "        sidr_hat = self.net_sidr(t_batch)\n",
        "\n",
        "        S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
        "\n",
        "        #S_t\n",
        "        sidr_hat.backward(self.m1, retain_graph=True)\n",
        "        S_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #I_t\n",
        "        sidr_hat.backward(self.m2, retain_graph=True)\n",
        "        I_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #D_t\n",
        "        sidr_hat.backward(self.m3, retain_graph=True)\n",
        "        D_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #R_t\n",
        "        sidr_hat.backward(self.m4, retain_graph=True)\n",
        "        R_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #unnormalize\n",
        "        S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
        "        I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
        "        D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
        "        R = self.R_min + (self.R_max - self.R_min) * R_hat\n",
        "\n",
        "        f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
        "        f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
        "        f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
        "        f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)\n",
        "\n",
        "        return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        self.losses = checkpoint['losses']\n",
        "\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list = []\n",
        "        I_pred_list = []\n",
        "        D_pred_list = []\n",
        "        R_pred_list = []\n",
        "\n",
        "        f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred) \n",
        "        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
        "        D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
        "        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
        "\n",
        "        loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
        "                torch.mean(torch.square(self.I_hat - I_pred))+\n",
        "                torch.mean(torch.square(self.D_hat - D_pred))+\n",
        "                torch.mean(torch.square(self.R_hat - R_pred))+\n",
        "                torch.mean(torch.square(f1))+\n",
        "                torch.mean(torch.square(f2))+\n",
        "                torch.mean(torch.square(f3))+\n",
        "                torch.mean(torch.square(f4))\n",
        "                ) \n",
        "\n",
        "        #loss.backward(retain_graph=True)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() \n",
        "        self.losses.append(loss.item())\n",
        "\n",
        "        if epoch % 1000 == 0:          \n",
        "          print('\\nEpoch ', epoch)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 4000 == 9999:\n",
        "          #checkpoint save\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              #'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH + str(self.save)+'.pt')\n",
        "          if self.save % 2 > 0: #its on 3\n",
        "            self.save = 2 #change to 2\n",
        "          else: #its on 2\n",
        "            self.save = 3 #change to 3\n",
        "\n",
        "      return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1obOwWZqOc",
        "outputId": "e98ea3f5-43e8-47d5-d9db-fed80b2734bc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "dinn = DINN(sidr_data[0], sidr_data[1], sidr_data[2], sidr_data[3], \n",
        "            sidr_data[4]) #in the form of [t,S,I,D,R]\n",
        "\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=1000, mode=\"exp_range\", gamma=0.85, cycle_momentum=False)\n",
        "\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "try: \n",
        "  S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(1000) #train\n",
        "except EOFError:\n",
        "  if dinn.save == 2:\n",
        "    dinn.save = 3\n",
        "    S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(1000) #train\n",
        "  elif dinn.save == 3:\n",
        "    dinn.save = 2\n",
        "    S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(1000) #train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "WwqBVtEM9FYG",
        "outputId": "7a66fb24-30fd-4d28-fb23-4086414b8c6a"
      },
      "outputs": [],
      "source": [
        "plt.plot(dinn.losses[0:], color = 'teal')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss'),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "pJrvoRWQZqOd",
        "outputId": "683eddcd-5771-4e6b-ed7b-83111cbd3ce9"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12,12))\n",
        "\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.set_facecolor('xkcd:white')\n",
        "\n",
        "\n",
        "# ax.scatter(sidr_data[0], sidr_data[1], 'pink', alpha=0.5, lw=2, label='Susceptible', s=15)\n",
        "ax.scatter(sidr_data[0], sidr_data[1], color = 'red', label='Susceptible Data', s=15)\n",
        "ax.plot(sidr_data[0], S_pred_list[0].detach().numpy(), 'pink', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.scatter(sidr_data[0], sidr_data[2], 'violet', alpha=0.5, lw=2, label='Infected', s=15)\n",
        "ax.scatter(sidr_data[0], sidr_data[2], color = 'violet', label='Infected Data', s=15)\n",
        "ax.plot(sidr_data[0], I_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.scatter(sidr_data[0], sidr_data[3], 'darkgreen', alpha=0.5, lw=2, label='Dead', s=15)\n",
        "ax.scatter(sidr_data[0], sidr_data[3], color = 'black', label='Dead Data', s=15)\n",
        "ax.plot(sidr_data[0], D_pred_list[0].detach().numpy(), 'green', alpha=0.9, lw=2, label='Dead Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.scatter(sidr_data[0], sidr_data[4], 'blue', alpha=0.5, lw=2, label='Recovered', s=15)\n",
        "ax.scatter(sidr_data[0], sidr_data[4], color = 'darkorchid', label='Recovered Data', s=15)\n",
        "ax.plot(sidr_data[0], R_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='Recovered Prediction', linestyle='dashed')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Time /days',size = 20)\n",
        "ax.set_ylabel('Number',size = 20)\n",
        "#ax.set_ylim([-1,50])\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "plt.xticks(size = 20)\n",
        "plt.yticks(size = 20)\n",
        "# ax.grid(b=True, which='major', c='black', lw=2.2, ls=15-')\n",
        "legend = ax.legend(prop={'size':20})\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.savefig('covid_missing_I.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "iUzZI6VMZqOe",
        "outputId": "2807c298-d442-4240-99f9-2393cec110d2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initial conditions\n",
        "N = 59e6\n",
        "\n",
        "S0 = N - 1\n",
        "I0 = 1\n",
        "D0 = 0\n",
        "R0 = 0\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 500, 100) \n",
        "\n",
        "#parameters\n",
        "alpha = dinn.alpha\n",
        "beta = dinn.beta\n",
        "gamma = dinn.gamma\n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t, alpha, betta, gamma):\n",
        "    S, I, D, R = y\n",
        "    dSdt = - (alpha / N) * S * I\n",
        "    dIdt = (alpha / N) * S * I - beta * I - gamma * I \n",
        "    dDdt = gamma * I\n",
        "    dRdt = beta * I\n",
        "\n",
        "    return dSdt, dIdt, dDdt, dRdt\n",
        "\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = S0, I0, D0, R0\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t, args=(alpha, beta, gamma))\n",
        "S, I, D, R = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w', figsize=(12,12))\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "\n",
        "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Learnable Param Susceptible', linestyle='dashed')\n",
        "ax.plot(t, sidr_data[1], 'dodgerblue', alpha=0.5, lw=2, label='Susceptible')\n",
        "\n",
        "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Learnable Param Infected', linestyle='dashed')\n",
        "ax.plot(t, sidr_data[2], 'gold', alpha=0.5, lw=2, label='Susceptible')\n",
        "\n",
        "ax.plot(t, D, 'red', alpha=0.5, lw=2, label='Learnable Param Dead', linestyle='dashed')\n",
        "ax.plot(t, sidr_data[3], 'salmon', alpha=0.5, lw=2, label='Dead')\n",
        "\n",
        "ax.plot(t, R, 'blue', alpha=0.5, lw=2, label='Learnable Param Recovered', linestyle='dashed')\n",
        "ax.plot(t, sidr_data[4], 'wheat', alpha=0.5, lw=2, label='Recovered')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-zofRIm2RNz",
        "outputId": "f8d80220-0217-41c8-8349-afb0a1ab9970"
      },
      "outputs": [],
      "source": [
        "#calculate relative MSE loss\n",
        "import math\n",
        "\n",
        "S_total_loss = 0\n",
        "S_den = 0\n",
        "I_total_loss = 0\n",
        "I_den = 0\n",
        "D_total_loss = 0\n",
        "D_den = 0\n",
        "R_total_loss = 0\n",
        "R_den = 0\n",
        "\n",
        "for timestep in range(len(t)):\n",
        "  S_value = sidr_data[1][timestep] - S[timestep]\n",
        "  S_total_loss += S_value**2\n",
        "  S_den += (sidr_data[1][timestep])**2\n",
        "  I_value = sidr_data[2][timestep] - I[timestep]\n",
        "  I_total_loss += I_value**2\n",
        "  I_den += (sidr_data[2][timestep])**2\n",
        "  D_value = sidr_data[3][timestep] - D[timestep]\n",
        "  D_total_loss += D_value**2\n",
        "  D_den += (sidr_data[3][timestep])**2\n",
        "  R_value = sidr_data[4][timestep] - R[timestep]\n",
        "  R_total_loss += R_value**2\n",
        "  R_den += (sidr_data[4][timestep])**2\n",
        "\n",
        "S_total_loss = math.sqrt(S_total_loss/S_den)\n",
        "I_total_loss = math.sqrt(I_total_loss/I_den)\n",
        "D_total_loss = math.sqrt(D_total_loss/D_den)\n",
        "R_total_loss = math.sqrt(R_total_loss/R_den)\n",
        "\n",
        "print('S_total_loss: ', S_total_loss)\n",
        "print('I_total_loss: ', I_total_loss)\n",
        "print('D_total_loss: ', D_total_loss)\n",
        "print('R_total_loss: ', R_total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lFJLEj4LFVw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "covid.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ebola.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3.7.3 64-bit ('base': conda)","name":"python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"JoPs1QTPZtrO","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1623155668901,"user_tz":360,"elapsed":33749,"user":{"displayName":"Sagi Shaier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXQKL7UiRoL28-GMShElFe0PuFh4NWnMP9hbDD=s64","userId":"12455150063240177220"}},"outputId":"c9f8e7ce-49e1-4e82-e70a-b30e6cb564b1"},"source":["#Mount my drive- run the code, go to the link, accept.\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","#Change working directory to make it easier to access the files\n","import os\n","os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n","os.getcwd() "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/My Drive/Colab Notebooks/dinn'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"pFhy95XbZqOS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623155672441,"user_tz":360,"elapsed":3544,"user":{"displayName":"Sagi Shaier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXQKL7UiRoL28-GMShElFe0PuFh4NWnMP9hbDD=s64","userId":"12455150063240177220"}},"outputId":"11bdaf02-b562-4f19-bde0-457d780eea94"},"source":["import torch\n","from torch.autograd import grad\n","import torch.nn as nn\n","from numpy import genfromtxt\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","\n","ebola_data = genfromtxt('ebola.csv', delimiter=',') #in the form of [t, S, E, I, H, F, R]\n","\n","torch.manual_seed(1234)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7eddf71d90>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"AD6iFgYfZqOa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623155673428,"user_tz":360,"elapsed":989,"user":{"displayName":"Sagi Shaier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXQKL7UiRoL28-GMShElFe0PuFh4NWnMP9hbDD=s64","userId":"12455150063240177220"}},"outputId":"3898e563-0d2a-483a-83e8-eca4e983d5ec"},"source":["%%time\n","\n","PATH = 'ebola' \n","\n","class DINN(nn.Module):\n","    def __init__(self, t, S_data, E_data, I_data, H_data, F_data, R_data): \n","        super(DINN, self).__init__()\n","        self.t = torch.tensor(t, requires_grad=True)\n","        self.t_float = self.t.float()\n","        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n","        self.S = torch.tensor(S_data) \n","        self.E = torch.tensor(E_data) \n","        self.I = torch.tensor(I_data) \n","        self.H = torch.tensor(H_data) \n","        self.F = torch.tensor(F_data) \n","        self.R = torch.tensor(R_data)         \n","\n","        self.N = torch.tensor(470000, requires_grad=False)\n","        self.losses = [] #keep the losses\n","        self.save = 3 #which file to save to\n","  \n","        #learnable parameters\n","        self.beta1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.beta_h_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.beta_f_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_h_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.theta1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_i_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.delta1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_d_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.delta2_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_f_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_ih_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.gamma_dh_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        \n","\n","        #matrices (x6 for T,I,V) for the gradients\n","        self.m1 = torch.zeros((len(self.t), 6)); self.m1[:, 0] = 1\n","        self.m2 = torch.zeros((len(self.t), 6)); self.m2[:, 1] = 1\n","        self.m3 = torch.zeros((len(self.t), 6)); self.m3[:, 2] = 1\n","        self.m4 = torch.zeros((len(self.t), 6)); self.m1[:, 3] = 1\n","        self.m5 = torch.zeros((len(self.t), 6)); self.m2[:, 4] = 1\n","        self.m6 = torch.zeros((len(self.t), 6)); self.m3[:, 5] = 1\n","\n","        #values for norm\n","        self.S_max = max(self.S)\n","        self.E_max = max(self.E)\n","        self.I_max = max(self.I)\n","        self.H_max = max(self.H)\n","        self.F_max = max(self.F)\n","        self.R_max = max(self.R)\n","\n","        self.S_min = min(self.S)\n","        self.E_min = min(self.E)\n","        self.I_min = min(self.I)\n","        self.H_min = min(self.H)\n","        self.F_min = min(self.F)\n","        self.R_min = min(self.R)\n","\n","        #normalize \n","        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n","        self.E_hat = (self.E - self.E_min) / (self.E_max - self.E_min)\n","        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n","        self.H_hat = (self.H - self.H_min) / (self.H_max - self.H_min)\n","        self.F_hat = (self.F - self.F_min) / (self.F_max - self.F_min)\n","        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n","\n","        #NN\n","        self.net_ebola = self.Net_ebola()\n","        self.params = list(self.net_ebola.parameters())\n","        self.params.extend(list([self.beta1_tilda, self.beta_h_tilda, self.beta_f_tilda, self.alpha_tilda, self.gamma_h_tilda, self.theta1_tilda, self.gamma_i_tilda, self.delta1_tilda, self.gamma_d_tilda, self.delta2_tilda, self.gamma_f_tilda, self.gamma_ih_tilda, self.gamma_dh_tilda]))\n","\n","        \n","    #force parameters to be in a range\n","    @property\n","    def beta1(self):\n","        return torch.tanh(self.beta1_tilda) * 0.03 + 3.53\n","\n","    @property\n","    def beta_h(self):\n","        return torch.tanh(self.beta_h_tilda) * 0.001 + 0.012\n","\n","    @property\n","    def beta_f(self):\n","        return torch.tanh(self.beta_f_tilda) * 0.005 + 0.46\n","\n","    @property\n","    def alpha(self):\n","        return torch.tanh(self.alpha_tilda) * 0.008 + 0.08\n","\n","    @property\n","    def gamma_h(self):\n","        return torch.tanh(self.gamma_h_tilda) * 0.003 + 0.25\n","\n","    @property\n","    def theta1(self):\n","        return torch.tanh(self.theta1_tilda) * 0.007 + 0.65\n","\n","    @property\n","    def gamma_i(self):\n","        return torch.tanh(self.gamma_i_tilda) * 0.01 + 0.1\n","\n","    @property\n","    def delta1(self):\n","        return torch.tanh(self.delta1_tilda) * 0.005 + 0.47\n","\n","    @property\n","    def gamma_d(self):\n","        return torch.tanh(self.gamma_d_tilda) * 0.002 + 0.12\n","\n","    @property\n","    def delta2(self):\n","        return torch.tanh(self.delta2_tilda) * 0.005 + 0.42\n","\n","    @property\n","    def gamma_f(self):\n","        return torch.tanh(self.gamma_f_tilda) * 0.05 + 0.5\n","\n","    @property\n","    def gamma_ih(self):\n","        return torch.tanh(self.gamma_ih_tilda) * 0.001 + 0.082\n","\n","    @property\n","    def gamma_dh(self):\n","        return torch.tanh(self.gamma_dh_tilda) * 0.001 + 0.07\n","    \n","\n","    #nets\n","    class Net_ebola(nn.Module): # input = [t]\n","        def __init__(self):\n","            super(DINN.Net_ebola, self).__init__()\n","            self.fc1=nn.Linear(1, 20) #takes t's\n","            self.fc2=nn.Linear(20, 20)\n","            self.fc3=nn.Linear(20, 20)\n","            self.fc4=nn.Linear(20, 20)\n","            self.fc5=nn.Linear(20, 20)\n","            self.fc6=nn.Linear(20, 20)\n","            self.fc7=nn.Linear(20, 20)\n","            self.fc8=nn.Linear(20, 20)\n","            self.out=nn.Linear(20, 6) #outputs S, E, I, H, F, R\n","\n","        def forward(self, t):\n","            ebola=F.relu(self.fc1(t))\n","            ebola=F.relu(self.fc2(ebola))\n","            ebola=F.relu(self.fc3(ebola))\n","            ebola=F.relu(self.fc4(ebola))\n","            ebola=F.relu(self.fc5(ebola))\n","            ebola=F.relu(self.fc6(ebola))\n","            ebola=F.relu(self.fc7(ebola))\n","            ebola=F.relu(self.fc8(ebola))\n","            ebola=self.out(ebola)\n","            return ebola    \n","\n","    def net_f(self, t_batch):      \n","\n","        ebola_hat = self.net_ebola(t_batch)\n","\n","        S_hat, E_hat, I_hat, H_hat, F_hat, R_hat = ebola_hat[:,0], ebola_hat[:,1], ebola_hat[:,2], ebola_hat[:,3], ebola_hat[:,4], ebola_hat[:,5]\n","\n","        #S_t\n","        ebola_hat.backward(self.m1, retain_graph=True)\n","        S_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","\n","        #E_t\n","        ebola_hat.backward(self.m2, retain_graph=True)\n","        E_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","\n","        #I_t\n","        ebola_hat.backward(self.m3, retain_graph=True)\n","        I_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","\n","        #H_t\n","        ebola_hat.backward(self.m4, retain_graph=True)\n","        H_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","\n","        #F_t\n","        ebola_hat.backward(self.m5, retain_graph=True)\n","        F_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","        \n","        #R_t\n","        ebola_hat.backward(self.m6, retain_graph=True)\n","        R_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","        \n","        #unnormalize\n","        S = self.S_min + (self.S_max - self.S_min) * S_hat\n","        E = self.E_min + (self.E_max - self.E_min) * E_hat\n","        I = self.I_min + (self.I_max - self.I_min) * I_hat\n","        H = self.H_min + (self.H_max - self.H_min) * H_hat\n","        F = self.F_min + (self.F_max - self.F_min) * F_hat\n","        R = self.R_min + (self.R_max - self.R_min) * R_hat\n","\n","        f1_hat = S_hat_t - (-1/self.N * (self.beta1 * S * I + self.beta_h * S * H + self.beta_f * S * F)) / (self.S_max - self.S_min) \n","        f2_hat = E_hat_t - (1/self.N * (self.beta1 * S * I + self.beta_h * S * H + self.beta_f * S * F) - self.alpha * E) / (self.E_max - self.E_min) \n","        f3_hat = I_hat_t - (self.alpha * E - (self.gamma_h * self.theta1 + self.gamma_i * (1-self.theta1)*(1-self.delta1) + self.gamma_d * (1-self.theta1) * self.delta1) * I) / (self.I_max - self.I_min) \n","        f4_hat = H_hat_t - (self.gamma_h * self.theta1 * I - (self.gamma_dh * self.delta2 + self.gamma_ih * (1-self.delta2)) * H) / (self.H_max - self.H_min)  \n","        f5_hat = F_hat_t - (self.gamma_d * (1-self.theta1) * self.delta1 * I + self.gamma_dh * self.delta2 * H - self.gamma_f * F) / (self.F_max - self.F_min) \n","        f6_hat = R_hat_t - (self.gamma_i * (1-self.theta1) * (1-self.delta1) * I + self.gamma_ih * (1-self.delta2) * H + self.gamma_f * F) / (self.R_max - self.R_min) \n","\n","        return f1_hat, f2_hat, f3_hat, f4_hat, f5_hat, f6_hat, S_hat, E_hat, I_hat, H_hat, F_hat, R_hat\n","    \n","    def load(self):\n","      # Load checkpoint\n","      try:\n","        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n","        print('\\nloading pre-trained model...')\n","        self.load_state_dict(checkpoint['model'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        self.scheduler.load_state_dict(checkpoint['scheduler'])\n","        epoch = checkpoint['epoch']\n","        loss = checkpoint['loss']\n","        self.losses = checkpoint['losses']\n","        print('loaded previous loss: ', loss)\n","      except RuntimeError :\n","          print('changed the architecture, ignore')\n","          pass\n","      except FileNotFoundError:\n","          pass\n","\n","    def train(self, n_epochs):\n","      #try loading\n","      self.load()\n","\n","      #train\n","      print('\\nstarting training...\\n')\n","      \n","      for epoch in range(n_epochs):\n","        #lists to hold the output (maintain only the final epoch)\n","        S_pred_list= []\n","        E_pred_list= []\n","        I_pred_list= []\n","        H_pred_list= []\n","        F_pred_list= []\n","        R_pred_list= []\n","        \n","        f1, f2, f3, f4, f5, f6, S_pred, E_pred, I_pred, H_pred, F_pred, R_pred = self.net_f(self.t_batch)\n","        self.optimizer.zero_grad()\n","\n","        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred)\n","        E_pred_list.append(self.E_min + (self.E_max - self.E_min) * E_pred)\n","        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n","        H_pred_list.append(self.H_min + (self.H_max - self.H_min) * H_pred)\n","        F_pred_list.append(self.F_min + (self.F_max - self.F_min) * F_pred)\n","        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n","\n","        loss = (\n","              torch.mean(torch.square(self.S_hat - S_pred)) + torch.mean(torch.square(self.I_hat - I_pred)) + torch.mean(torch.square(self.E_hat - E_pred)) + \n","              torch.mean(torch.square(self.H_hat - H_pred)) + torch.mean(torch.square(self.F_hat - F_pred)) + torch.mean(torch.square(self.R_hat - R_pred)) + \n","              torch.mean(torch.square(f1)) + torch.mean(torch.square(f2)) + torch.mean(torch.square(f3)) +\n","              torch.mean(torch.square(f4)) + torch.mean(torch.square(f5)) + torch.mean(torch.square(f6)) \n","               )\n","        loss.backward()\n","\n","        self.optimizer.step()\n","        self.scheduler.step() \n","        #self.scheduler.step(loss) \n","\n","        self.losses.append(loss.item())\n","\n","        if epoch % 1000 == 0:          \n","          print('\\nEpoch ', epoch)\n","\n","        #loss + model parameters update\n","        if epoch % 4000 == 0:\n","          #checkpoint save every 1000 epochs if the loss is lower\n","          print('\\nSaving model... Loss is: ', loss)\n","          torch.save({\n","              'epoch': epoch,\n","              'model': self.state_dict(),\n","              'optimizer_state_dict': self.optimizer.state_dict(),\n","              'scheduler': self.scheduler.state_dict(),\n","              'loss': loss,\n","              'losses': self.losses,\n","              }, PATH + str(self.save)+'.pt')\n","          if self.save % 2 > 0: #its on 3\n","            self.save = 2 #change to 2\n","          else: #its on 2\n","            self.save = 3 #change to 3\n","\n","          print('epoch: ', epoch)\n","          print('beta1: (goal 3.532)', self.beta1)\n","          print('\\nbeta_h: (goal 0.012)', self.beta_h)\n","          print('\\nbeta_f: (goal 0.462): ', self.beta_f)\n","          print('\\ntheta1: (goal 0.65): ', self.theta1)\n","          print('\\ndelta2 (goal 0.42): ', self.delta2)\n","          print('\\ngamma_f (goal 0.5): ', self.gamma_f)\n","          print('#################################')\n","        \n","      #plot\n","      plt.plot(self.losses, color = 'teal')\n","      plt.xlabel('Epochs')\n","      plt.ylabel('Loss')\n","      return S_pred_list, E_pred_list, I_pred_list, H_pred_list, F_pred_list, R_pred_list\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["CPU times: user 51 µs, sys: 11 µs, total: 62 µs\n","Wall time: 67.5 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_P1obOwWZqOc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c4d7400-77fb-44d0-deba-5717c5ec789e"},"source":["%%time\n","\n","#this worked best\n","dinn = DINN(ebola_data[0], ebola_data[1], ebola_data[2], ebola_data[3], ebola_data[4], ebola_data[5], ebola_data[6]) #t,S, E, I, H, F, R\n","\n","learning_rate = 1e-5\n","optimizer = optim.Adam(dinn.params, lr = learning_rate)\n","dinn.optimizer = optimizer\n","\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(dinn.optimizer, factor=0.99, patience = 5000, verbose=True)\n","#scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-7, max_lr=1e-5, step_size_up=20000, mode=\"triangular2\", cycle_momentum=False)\n","scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-7, max_lr=1e-3, step_size_up=1000, mode=\"exp_range\", gamma=0.85, cycle_momentum=False)\n","\n","dinn.scheduler = scheduler\n","\n","try: \n","  S_pred_list, E_pred_list, I_pred_list, H_pred_list, F_pred_list, R_pred_list = dinn.train(10000000) #train\n","except EOFError:\n","  if dinn.save == 2:\n","    dinn.save = 3\n","    S_pred_list, E_pred_list, I_pred_list, H_pred_list, F_pred_list, R_pred_list = dinn.train(10000000) #train\n","  elif dinn.save == 3:\n","    dinn.save = 2\n","    S_pred_list, E_pred_list, I_pred_list, H_pred_list, F_pred_list, R_pred_list = dinn.train(10000000) #train"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","loading pre-trained model...\n","loaded previous loss:  tensor(0.0032, dtype=torch.float64, requires_grad=True)\n","\n","starting training...\n","\n","\n","Epoch  0\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  0\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6523], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5196], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  1000\n","\n","Epoch  2000\n","\n","Epoch  3000\n","\n","Epoch  4000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  4000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6523], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5196], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  5000\n","\n","Epoch  6000\n","\n","Epoch  7000\n","\n","Epoch  8000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  8000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6523], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5196], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  9000\n","\n","Epoch  10000\n","\n","Epoch  11000\n","\n","Epoch  12000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  12000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6523], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5196], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  13000\n","\n","Epoch  14000\n","\n","Epoch  15000\n","\n","Epoch  16000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  16000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6523], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5196], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  17000\n","\n","Epoch  18000\n","\n","Epoch  19000\n","\n","Epoch  20000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  20000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  21000\n","\n","Epoch  22000\n","\n","Epoch  23000\n","\n","Epoch  24000\n","\n","Saving model... Loss is:  tensor(0.0033, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  24000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  25000\n","\n","Epoch  26000\n","\n","Epoch  27000\n","\n","Epoch  28000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  28000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  29000\n","\n","Epoch  30000\n","\n","Epoch  31000\n","\n","Epoch  32000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  32000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  33000\n","\n","Epoch  34000\n","\n","Epoch  35000\n","\n","Epoch  36000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  36000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  37000\n","\n","Epoch  38000\n","\n","Epoch  39000\n","\n","Epoch  40000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  40000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  41000\n","\n","Epoch  42000\n","\n","Epoch  43000\n","\n","Epoch  44000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n","epoch:  44000\n","beta1: (goal 3.532) tensor([3.5589], grad_fn=<AddBackward0>)\n","\n","beta_h: (goal 0.012) tensor([0.0129], grad_fn=<AddBackward0>)\n","\n","beta_f: (goal 0.462):  tensor([0.4638], grad_fn=<AddBackward0>)\n","\n","theta1: (goal 0.65):  tensor([0.6522], grad_fn=<AddBackward0>)\n","\n","delta2 (goal 0.42):  tensor([0.4247], grad_fn=<AddBackward0>)\n","\n","gamma_f (goal 0.5):  tensor([0.5195], grad_fn=<AddBackward0>)\n","#################################\n","\n","Epoch  45000\n","\n","Epoch  46000\n","\n","Epoch  47000\n","\n","Epoch  48000\n","\n","Saving model... Loss is:  tensor(0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RY71fo4_Ic_N"},"source":["plt.plot(dinn.losses[14000000:], color = 'teal')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJrvoRWQZqOd"},"source":["fig = plt.figure(facecolor='w', figsize=(10,10))\n","ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n","\n","ax.plot(ebola_data[0], ebola_data[1], 'pink', alpha=0.5, lw=2, label='S')\n","ax.plot(ebola_data[0], S_pred_list[0].detach().numpy(), 'navy', alpha=0.9, lw=2, label='S Prediction', linestyle='dashed')\n","\n","ax.plot(ebola_data[0], ebola_data[2], 'violet', alpha=0.5, lw=2, label='E')\n","ax.plot(ebola_data[0], E_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='E Prediction', linestyle='dashed')\n","\n","ax.plot(ebola_data[0], ebola_data[3], 'darkgreen', alpha=0.5, lw=2, label='I')\n","ax.plot(ebola_data[0], I_pred_list[0].detach().numpy(), 'gold', alpha=0.9, lw=2, label='I Prediction', linestyle='dashed')\n","\n","ax.plot(ebola_data[0], ebola_data[4], 'red', alpha=0.5, lw=2, label='H')\n","ax.plot(ebola_data[0], H_pred_list[0].detach().numpy(), 'black', alpha=0.9, lw=2, label='H Prediction', linestyle='dashed')\n","\n","ax.plot(ebola_data[0], ebola_data[5], 'blue', alpha=0.5, lw=2, label='F')\n","ax.plot(ebola_data[0], F_pred_list[0].detach().numpy(), 'wheat', alpha=0.9, lw=2, label='F Prediction', linestyle='dashed')\n","\n","ax.plot(ebola_data[0], ebola_data[6], 'purple', alpha=0.5, lw=2, label='R')\n","ax.plot(ebola_data[0], R_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='R Prediction', linestyle='dashed')\n","\n","\n","ax.set_xlabel('Time /days')\n","ax.set_ylabel('Number')\n","ax.yaxis.set_tick_params(length=0)\n","ax.xaxis.set_tick_params(length=0)\n","ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n","legend = ax.legend()\n","legend.get_frame().set_alpha(0.5)\n","for spine in ('top', 'right', 'bottom', 'left'):\n","    ax.spines[spine].set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUzZI6VMZqOe"},"source":["import numpy as np\n","from scipy.integrate import odeint\n","import matplotlib.pyplot as plt\n","\n","# Initial conditions\n","E0 = 0\n","I0 = 425\n","H0 = 0\n","F0 = 0\n","R0 = 0\n","N = 470000\n","S0 = N - I0\n","\n","# A grid of time points (in days)\n","t = np.linspace(0, 100, 100) \n","\n","#parameters\n","beta1 = dinn.beta1\n","beta_h = dinn.beta_h\n","beta_f = dinn.beta_f\n","alpha = dinn.alpha\n","gamma_h = dinn.gamma_h\n","theta1 = dinn.theta1\n","gamma_i = dinn.gamma_i\n","delta1 = dinn.delta1\n","gamma_d = dinn.gamma_d\n","delta2 = dinn.delta2\n","gamma_f = dinn.gamma_f\n","gamma_ih  = 1 / ( (1/dinn.gamma_d) + (1/dinn.gamma_h))\n","gamma_dh = 1 / ( (1/dinn.gamma_i) + (1/dinn.gamma_h))\n","\n","# The SIR model differential equations.\n","def deriv(y, t, N, beta1, beta_h, beta_f, alpha, gamma_h, theta1, gamma_i, delta1, gamma_d, delta2, gamma_f, gamma_ih , gamma_dh):\n","    S, E, I, H, F, R  = y\n","    dSdt = -1/N * (beta1 * S * I + beta_h * S * H + beta_f * S * F)\n","    dEdt = 1/N * (beta1 * S * I + beta_h * S * H + beta_f * S * F) - alpha * E\n","    dIdt = alpha * E - (gamma_h * theta1 + gamma_i * (1-theta1)*(1-delta1) + gamma_d * (1-theta1) * delta1) * I\n","    dHdt = gamma_h * theta1 * I - (gamma_dh * delta2 + gamma_ih * (1-delta2)) * H\n","    dFdt = gamma_d * (1-theta1) * delta1 * I + gamma_dh * delta2 * H - gamma_f * F\n","    dRdt = gamma_i * (1-theta1) * (1-delta1) * I + gamma_ih * (1-delta2) * H + gamma_f * F\n","\n","    return dSdt, dEdt, dIdt, dHdt, dFdt, dRdt\n","\n","\n","# Initial conditions vector\n","y0 = S0, E0, I0, H0, F0, R0\n","# Integrate the SIR equations over the time grid, t.\n","ret = odeint(deriv, y0, t, args=(N, beta1, beta_h, beta_f, alpha, gamma_h, theta1, gamma_i, delta1, gamma_d, delta2, gamma_f, gamma_ih , gamma_dh))\n","S, E, I, H, F, R = ret.T\n","\n","\n","# Plot the data on two separate curves for S(t), I(t)\n","fig = plt.figure(facecolor='w', figsize=(10,10))\n","ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n","\n","ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='S_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[1], 'purple', alpha=0.5, lw=2, label='S')\n","\n","ax.plot(t, E, 'darkgreen', alpha=0.5, lw=2, label='E_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[2], 'teal', alpha=0.5, lw=2, label='E')\n","\n","ax.plot(t, I, 'blue', alpha=0.5, lw=2, label='I_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[3], 'red', alpha=0.5, lw=2, label='I')\n","\n","ax.plot(t, H, 'yellow', alpha=0.5, lw=2, label='H_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[4], 'black', alpha=0.5, lw=2, label='H')\n","\n","ax.plot(t, F, 'orange', alpha=0.5, lw=2, label='F_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[5], 'green', alpha=0.5, lw=2, label='F')\n","\n","ax.plot(t, R, 'silver', alpha=0.5, lw=2, label='R_pred', linestyle='dashed')\n","ax.plot(ebola_data[0], ebola_data[6], 'darkred', alpha=0.5, lw=2, label='R')\n","\n","ax.set_xlabel('Time /days')\n","ax.yaxis.set_tick_params(length=0)\n","ax.xaxis.set_tick_params(length=0)\n","ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n","legend = ax.legend()\n","legend.get_frame().set_alpha(0.5)\n","for spine in ('top', 'right', 'bottom', 'left'):\n","    ax.spines[spine].set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICWNogFjn27j"},"source":["#calculate relative MSE loss\n","import math\n","\n","#SEIHFR\n","\n","S_total_loss = 0\n","S_den = 0\n","E_total_loss = 0\n","E_den = 0\n","I_total_loss = 0\n","I_den = 0\n","H_total_loss = 0\n","H_den = 0\n","F_total_loss = 0\n","F_den = 0\n","R_total_loss = 0\n","R_den = 0\n","\n","for timestep in range(len(t)):\n","  S_value = ebola_data[1][timestep] - S[timestep]\n","  S_total_loss += S_value**2\n","  S_den += (ebola_data[1][timestep])**2\n","\n","  E_value = ebola_data[2][timestep] - E[timestep]\n","  E_total_loss += E_value**2\n","  E_den += (ebola_data[2][timestep])**2\n","  \n","  I_value = ebola_data[3][timestep] - I[timestep]\n","  I_total_loss += I_value**2\n","  I_den += (ebola_data[3][timestep])**2\n","\n","  H_value = ebola_data[4][timestep] - H[timestep]\n","  H_total_loss += H_value**2\n","  H_den += (ebola_data[4][timestep])**2\n","\n","  F_value = ebola_data[5][timestep] - F[timestep]\n","  F_total_loss += F_value**2\n","  F_den += (ebola_data[5][timestep])**2\n","\n","  R_value = ebola_data[6][timestep] - R[timestep]\n","  R_total_loss += R_value**2\n","  R_den += (ebola_data[6][timestep])**2\n","  \n","S_total_loss = math.sqrt(S_total_loss/S_den)\n","E_total_loss = math.sqrt(E_total_loss/E_den)\n","I_total_loss = math.sqrt(I_total_loss/I_den)\n","H_total_loss = math.sqrt(H_total_loss/H_den)\n","F_total_loss = math.sqrt(F_total_loss/F_den)\n","R_total_loss = math.sqrt(R_total_loss/R_den)\n","\n","\n","print('S_total_loss: ', S_total_loss)\n","print('E_total_loss: ', E_total_loss)\n","print('I_total_loss: ', I_total_loss)\n","print('H_total_loss: ', H_total_loss)\n","print('F_total_loss: ', F_total_loss)\n","print('R_total_loss: ', R_total_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5f6IXgoz6DL"},"source":["S_total_loss:  0.009322135497198349\n","E_total_loss:  0.012280559733445641\n","I_total_loss:  0.016357916536579947\n","H_total_loss:  0.07646396798420164\n","F_total_loss:  0.12599100282001896\n","R_total_loss:  0.01289130681993955"],"execution_count":null,"outputs":[]}]}
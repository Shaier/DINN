{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "sidarthe_tensor_norm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoPs1QTPZtrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "da9ec2e4-dd54-4556-a8b6-b8193a56c87d"
      },
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n",
        "os.getcwd() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/dinn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFhy95XbZqOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883dc4bc-4ad3-4e22-ac58-7b4144697944"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tSIDARTHE_data = genfromtxt('tSIDARTHE_data.csv', delimiter=',') #in the form of [t,S,I,D,A,R,T,H,E]\n",
        "\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd37ccb2ab0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoCZfHrmtgOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b65ce8-7efe-4187-8e5b-a71dbd9c460b"
      },
      "source": [
        "#[<4, <12, <22, <28, <38, <50, >50] #i.e 7 bins\n",
        "parameters_dict = {}\n",
        "parameters_dict['alpha'] = [0.570, 0.422,0.422,0.360,0.210,0.210,0.105]\n",
        "parameters_dict['beta'] = [0.011, 0.0057,0.0057, 0.005,0.005,0.005,0.005]\n",
        "parameters_dict['gamma'] = [0.456, 0.285, 0.285,0.2,0.110,0.110,0.110]\n",
        "parameters_dict['delta'] = [0.011, 0.0057, 0.0057, 0.005,0.005,0.005,0.005]\n",
        "parameters_dict['epsilon'] = [0.171, 0.171,0.143,0.143,0.143,0.200,0.200]\n",
        "parameters_dict['zeta'] = [0.125,0.125,0.125,0.034,0.034,0.025,0.025]\n",
        "parameters_dict['lambdda'] = [0.034,0.034,0.034,0.08,0.08,0.08,0.08]\n",
        "parameters_dict['eta'] = [0.125,0.125,0.125,0.034,0.034,0.025,0.025]\n",
        "parameters_dict['rho'] = [0.034,0.034,0.034,0.017,0.017,0.020,0.020]\n",
        "parameters_dict['mu'] = [0.017,0.017,0.017,0.008,0.008,0.008,0.008]\n",
        "parameters_dict['kappa'] = [0.017,0.017,0.017,0.017,0.017,0.020,0.020]\n",
        "parameters_dict['theta'] = [0.371,0.371,0.371, 0.371,0.371,0.371,0.371]\n",
        "parameters_dict['nu'] = [0.027,0.027,0.027,0.015,0.015,0.015,0.015]\n",
        "parameters_dict['xi'] = [0.017,0.017,0.017,0.017,0.017,0.020,0.020]\n",
        "parameters_dict['sigma'] = [0.017,0.017,0.017,0.017,0.017,0.010,0.010]\n",
        "parameters_dict['tao'] = [0.01,0.01,0.01,0.01,0.01,0.01,]\n",
        "parameters_dict"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': [0.57, 0.422, 0.422, 0.36, 0.21, 0.21, 0.105],\n",
              " 'beta': [0.011, 0.0057, 0.0057, 0.005, 0.005, 0.005, 0.005],\n",
              " 'delta': [0.011, 0.0057, 0.0057, 0.005, 0.005, 0.005, 0.005],\n",
              " 'epsilon': [0.171, 0.171, 0.143, 0.143, 0.143, 0.2, 0.2],\n",
              " 'eta': [0.125, 0.125, 0.125, 0.034, 0.034, 0.025, 0.025],\n",
              " 'gamma': [0.456, 0.285, 0.285, 0.2, 0.11, 0.11, 0.11],\n",
              " 'kappa': [0.017, 0.017, 0.017, 0.017, 0.017, 0.02, 0.02],\n",
              " 'lambdda': [0.034, 0.034, 0.034, 0.08, 0.08, 0.08, 0.08],\n",
              " 'mu': [0.017, 0.017, 0.017, 0.008, 0.008, 0.008, 0.008],\n",
              " 'nu': [0.027, 0.027, 0.027, 0.015, 0.015, 0.015, 0.015],\n",
              " 'rho': [0.034, 0.034, 0.034, 0.017, 0.017, 0.02, 0.02],\n",
              " 'sigma': [0.017, 0.017, 0.017, 0.017, 0.017, 0.01, 0.01],\n",
              " 'tao': [0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
              " 'theta': [0.371, 0.371, 0.371, 0.371, 0.371, 0.371, 0.371],\n",
              " 'xi': [0.017, 0.017, 0.017, 0.017, 0.017, 0.02, 0.02],\n",
              " 'zeta': [0.125, 0.125, 0.125, 0.034, 0.034, 0.025, 0.025]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "AD6iFgYfZqOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832194e1-0346-47a8-991c-1393e2645b52"
      },
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'sidarthe_tensor_norm' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data, D_data, A_data, R_data, T_data, H_data, E_data): #[t,S,I,D,A,R,T,H,E]\n",
        "        super(DINN, self).__init__()\n",
        "        self.t = torch.tensor(t).float()\n",
        "        self.t = torch.reshape(self.t, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data)\n",
        "        self.I = torch.tensor(I_data)\n",
        "        self.D = torch.tensor(D_data)\n",
        "        self.A = torch.tensor(A_data)\n",
        "        self.R = torch.tensor(R_data)\n",
        "        self.T = torch.tensor(T_data)\n",
        "        self.H = torch.tensor(H_data)\n",
        "        self.E = torch.tensor(E_data)\n",
        "\n",
        "        #Unnormalize (out of 60mil population)\n",
        "        # self.S = self.S * 60e6\n",
        "        # self.I = self.I * 60e6\n",
        "        # self.D = self.D * 60e6\n",
        "        # self.A = self.A * 60e6\n",
        "        # self.R = self.R * 60e6\n",
        "        # self.T = self.T * 60e6\n",
        "        # self.H = self.H * 60e6\n",
        "        # self.E = self.E * 60e6\n",
        "\n",
        "        #find values for normalization\n",
        "        self.t_max = max(self.t)\n",
        "        self.t_min = min(self.t)        \n",
        "        self.S_max = max(self.S)\n",
        "        self.I_max = max(self.I)\n",
        "        self.D_max = max(self.D)\n",
        "        self.A_max = max(self.A)\n",
        "        self.R_max = max(self.R)\n",
        "        self.T_max = max(self.T)\n",
        "        self.H_max = max(self.H)\n",
        "        self.E_max = max(self.E)\n",
        "        self.S_min = min(self.S)\n",
        "        self.I_min = min(self.I)\n",
        "        self.D_min = min(self.D)\n",
        "        self.A_min = min(self.A)\n",
        "        self.R_min = min(self.R)\n",
        "        self.T_min = min(self.T)\n",
        "        self.H_min = min(self.H)\n",
        "        self.E_min = min(self.E)\n",
        "\n",
        "        #normalize \n",
        "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
        "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
        "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
        "        self.A_hat = (self.A - self.A_min) / (self.A_max - self.A_min)\n",
        "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n",
        "        self.T_hat = (self.T - self.T_min) / (self.T_max - self.T_min)\n",
        "        self.H_hat = (self.H - self.H_min) / (self.H_max - self.H_min)\n",
        "        self.E_hat = (self.E - self.E_min) / (self.E_max - self.E_min)\n",
        "        self.t_hat = (self.t - self.t_min) / (self.t_max - self.t_min)\n",
        "\n",
        "        self.bin = 0 #a counter for which self.bin I'm on\n",
        "        self.losses = []\n",
        "        self.save = 2 #which file to save to\n",
        "        self.SI_vals = [] #keep the intermediate SI values\n",
        "\n",
        "        #learnable parameters (there are 7 self.bins (e.g <4 days, etc.))\n",
        "        self.alpha_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.gamma_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.delta_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.epsilon_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.zeta_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.lambdda_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.eta_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.rho_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.mu_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.kappa_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.theta_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.nu_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.xi_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.sigma_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        self.tao_tilda = torch.nn.Parameter(torch.rand(7, requires_grad=True))\n",
        "        \n",
        "        #NN\n",
        "        self.net_sidarthe = self.Net_sidarthe()\n",
        "        self.params = list(self.net_sidarthe.parameters())\n",
        "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda, self.delta_tilda, self.epsilon_tilda, self.zeta_tilda, self.lambdda_tilda, self.eta_tilda, self.rho_tilda, self.mu_tilda, self.kappa_tilda, self.theta_tilda, self.nu_tilda, self.xi_tilda, self.sigma_tilda, self.tao_tilda ]))\n",
        "\n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        val = self.alpha_tilda[0]*(self.t<4) + self.alpha_tilda[1]*((4<=self.t)&(self.t<12)) + self.alpha_tilda[2]*((12<=self.t)&(self.t<22)) + self.alpha_tilda[3]*((22<=self.t)&(self.t<28)) + self.alpha_tilda[4]*((28<=self.t)&(self.t<38)) + self.alpha_tilda[5]*((38<=self.t)&(self.t<50)) + self.alpha_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val)# * 0.8\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        val = self.beta_tilda[0]*(self.t<4) + self.beta_tilda[1]*((4<=self.t)&(self.t<12)) + self.beta_tilda[2]*((12<=self.t)&(self.t<22)) + self.beta_tilda[3]*((22<=self.t)&(self.t<28)) + self.beta_tilda[4]*((28<=self.t)&(self.t<38)) + self.beta_tilda[5]*((38<=self.t)&(self.t<50)) + self.beta_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.03\n",
        "    \n",
        "    @property\n",
        "    def gamma(self):\n",
        "        val = self.gamma_tilda[0]*(self.t<4) + self.gamma_tilda[1]*((4<=self.t)&(self.t<12)) + self.gamma_tilda[2]*((12<=self.t)&(self.t<22)) + self.gamma_tilda[3]*((22<=self.t)&(self.t<28)) + self.gamma_tilda[4]*((28<=self.t)&(self.t<38)) + self.gamma_tilda[5]*((38<=self.t)&(self.t<50)) + self.gamma_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.6\n",
        "\n",
        "    @property\n",
        "    def delta(self):\n",
        "        val = self.delta_tilda[0]*(self.t<4) + self.delta_tilda[1]*((4<=self.t)&(self.t<12)) + self.delta_tilda[2]*((12<=self.t)&(self.t<22)) + self.delta_tilda[3]*((22<=self.t)&(self.t<28)) + self.delta_tilda[4]*((28<=self.t)&(self.t<38)) + self.delta_tilda[5]*((38<=self.t)&(self.t<50)) + self.delta_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.03\n",
        "\n",
        "    @property\n",
        "    def epsilon(self):\n",
        "        val = self.epsilon_tilda[0]*(self.t<4) + self.epsilon_tilda[1]*((4<=self.t)&(self.t<12)) + self.epsilon_tilda[2]*((12<=self.t)&(self.t<22)) + self.epsilon_tilda[3]*((22<=self.t)&(self.t<28)) + self.epsilon_tilda[4]*((28<=self.t)&(self.t<38)) + self.epsilon_tilda[5]*((38<=self.t)&(self.t<50)) + self.epsilon_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) * 0.5\n",
        "\n",
        "    @property\n",
        "    def zeta(self):\n",
        "        val = self.zeta_tilda[0]*(self.t<4) + self.zeta_tilda[1]*((4<=self.t)&(self.t<12)) + self.zeta_tilda[2]*((12<=self.t)&(self.t<22)) + self.zeta_tilda[3]*((22<=self.t)&(self.t<28)) + self.zeta_tilda[4]*((28<=self.t)&(self.t<38)) + self.zeta_tilda[5]*((38<=self.t)&(self.t<50)) + self.zeta_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.4\n",
        "\n",
        "    @property\n",
        "    def lambdda(self):\n",
        "        val = self.lambdda_tilda[0]*(self.t<4) + self.lambdda_tilda[1]*((4<=self.t)&(self.t<12)) + self.lambdda_tilda[2]*((12<=self.t)&(self.t<22)) + self.lambdda_tilda[3]*((22<=self.t)&(self.t<28)) + self.lambdda_tilda[4]*((28<=self.t)&(self.t<38)) + self.lambdda_tilda[5]*((38<=self.t)&(self.t<50)) + self.lambdda_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val)# * 0.3\n",
        "\n",
        "    @property\n",
        "    def eta(self):\n",
        "        val = self.eta_tilda[0]*(self.t<4) + self.eta_tilda[1]*((4<=self.t)&(self.t<12)) + self.eta_tilda[2]*((12<=self.t)&(self.t<22)) + self.eta_tilda[3]*((22<=self.t)&(self.t<28)) + self.eta_tilda[4]*((28<=self.t)&(self.t<38)) + self.eta_tilda[5]*((38<=self.t)&(self.t<50)) + self.eta_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.3\n",
        "\n",
        "    @property\n",
        "    def rho(self):\n",
        "        val = self.rho_tilda[0]*(self.t<4) + self.rho_tilda[1]*((4<=self.t)&(self.t<12)) + self.rho_tilda[2]*((12<=self.t)&(self.t<22)) + self.rho_tilda[3]*((22<=self.t)&(self.t<28)) + self.rho_tilda[4]*((28<=self.t)&(self.t<38)) + self.rho_tilda[5]*((38<=self.t)&(self.t<50)) + self.rho_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.1\n",
        "\n",
        "    @property\n",
        "    def mu(self):\n",
        "        val = self.mu_tilda[0]*(self.t<4) + self.mu_tilda[1]*((4<=self.t)&(self.t<12)) + self.mu_tilda[2]*((12<=self.t)&(self.t<22)) + self.mu_tilda[3]*((22<=self.t)&(self.t<28)) + self.mu_tilda[4]*((28<=self.t)&(self.t<38)) + self.mu_tilda[5]*((38<=self.t)&(self.t<50)) + self.mu_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.05\n",
        "\n",
        "    @property\n",
        "    def kappa(self):\n",
        "        val = self.kappa_tilda[0]*(self.t<4) + self.kappa_tilda[1]*((4<=self.t)&(self.t<12)) + self.kappa_tilda[2]*((12<=self.t)&(self.t<22)) + self.kappa_tilda[3]*((22<=self.t)&(self.t<28)) + self.kappa_tilda[4]*((28<=self.t)&(self.t<38)) + self.kappa_tilda[5]*((38<=self.t)&(self.t<50)) + self.kappa_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val)# * 0.05\n",
        "\n",
        "    @property\n",
        "    def theta(self):\n",
        "        val = self.theta_tilda[0]*(self.t<4) + self.theta_tilda[1]*((4<=self.t)&(self.t<12)) + self.theta_tilda[2]*((12<=self.t)&(self.t<22)) + self.theta_tilda[3]*((22<=self.t)&(self.t<28)) + self.theta_tilda[4]*((28<=self.t)&(self.t<38)) + self.theta_tilda[5]*((38<=self.t)&(self.t<50)) + self.theta_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.8\n",
        "                    \n",
        "    @property\n",
        "    def nu(self):\n",
        "        val = self.nu_tilda[0]*(self.t<4) + self.nu_tilda[1]*((4<=self.t)&(self.t<12)) + self.nu_tilda[2]*((12<=self.t)&(self.t<22)) + self.nu_tilda[3]*((22<=self.t)&(self.t<28)) + self.nu_tilda[4]*((28<=self.t)&(self.t<38)) + self.nu_tilda[5]*((38<=self.t)&(self.t<50)) + self.nu_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.08\n",
        "\n",
        "    @property\n",
        "    def xi(self):\n",
        "        val = self.xi_tilda[0]*(self.t<4) + self.xi_tilda[1]*((4<=self.t)&(self.t<12)) + self.xi_tilda[2]*((12<=self.t)&(self.t<22)) + self.xi_tilda[3]*((22<=self.t)&(self.t<28)) + self.xi_tilda[4]*((28<=self.t)&(self.t<38)) + self.xi_tilda[5]*((38<=self.t)&(self.t<50)) + self.xi_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.05\n",
        "\n",
        "    @property\n",
        "    def sigma(self):\n",
        "        val = self.sigma_tilda[0]*(self.t<4) + self.sigma_tilda[1]*((4<=self.t)&(self.t<12)) + self.sigma_tilda[2]*((12<=self.t)&(self.t<22)) + self.sigma_tilda[3]*((22<=self.t)&(self.t<28)) + self.sigma_tilda[4]*((28<=self.t)&(self.t<38)) + self.sigma_tilda[5]*((38<=self.t)&(self.t<50)) + self.sigma_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.05\n",
        "\n",
        "    @property\n",
        "    def tao(self):\n",
        "        val = self.tao_tilda[0]*(self.t<4) + self.tao_tilda[1]*((4<=self.t)&(self.t<12)) + self.tao_tilda[2]*((12<=self.t)&(self.t<22)) + self.tao_tilda[3]*((22<=self.t)&(self.t<28)) + self.tao_tilda[4]*((28<=self.t)&(self.t<38)) + self.tao_tilda[5]*((38<=self.t)&(self.t<50)) + self.tao_tilda[6]*(self.t>=50)\n",
        "        return torch.tanh(val) #* 0.05\n",
        "\n",
        "    #nets\n",
        "    class Net_sidarthe(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_sidarthe, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 20) #takes t\n",
        "            self.fc2=nn.Linear(20, 20)\n",
        "            self.fc3=nn.Linear(20, 20)\n",
        "            self.fc4=nn.Linear(20, 20)\n",
        "            self.fc5=nn.Linear(20, 20)\n",
        "            self.fc6=nn.Linear(20, 20)\n",
        "            self.fc7=nn.Linear(20, 20)\n",
        "            self.fc8=nn.Linear(20, 20)\n",
        "            self.out=nn.Linear(20, 8) #outputs [S,I,D,A,R,T,H,E]\n",
        "\n",
        "        def forward(self, t):\n",
        "            sidarthe=F.relu(self.fc1(t))\n",
        "            sidarthe=F.relu(self.fc2(sidarthe))\n",
        "            sidarthe=F.relu(self.fc3(sidarthe))\n",
        "            sidarthe=F.relu(self.fc4(sidarthe))\n",
        "            sidarthe=F.relu(self.fc5(sidarthe))\n",
        "            sidarthe=F.relu(self.fc6(sidarthe))\n",
        "            sidarthe=F.relu(self.fc7(sidarthe))\n",
        "            sidarthe=F.relu(self.fc8(sidarthe))\n",
        "            sidarthe=self.out(sidarthe)\n",
        "            return sidarthe    \n",
        "\n",
        "    def get_SI(self, t_):\n",
        "      net_vals = self.net_sidarthe(t_)\n",
        "      self.SI_vals.append(net_vals)\n",
        "      return net_vals\n",
        "\n",
        "    def net_f(self, t_hat):\n",
        "        self.SI_vals = [] #reset values list\n",
        "        d_SI = torch.autograd.functional.jacobian(self.get_SI, t_hat) #calculate Jacobian\n",
        "\n",
        "        S_hat,I_hat,D_hat,A_hat,R_hat,T_hat,H_hat,E_hat = self.SI_vals[0][:,0], self.SI_vals[0][:,1], self.SI_vals[0][:,2], self.SI_vals[0][:,3], self.SI_vals[0][:,4], self.SI_vals[0][:,5], self.SI_vals[0][:,6], self.SI_vals[0][:,7] \n",
        "\n",
        "        S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
        "        I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
        "        D = self.D_min + (self.D_max - self.D_min) * D_hat\n",
        "        A = self.A_min + (self.A_max - self.A_min) * A_hat\n",
        "        R = self.R_min + (self.R_max - self.R_min) * R_hat\n",
        "        T = self.T_min + (self.T_max - self.T_min) * T_hat\n",
        "        H = self.H_min + (self.H_max - self.H_min) * H_hat\n",
        "        E = self.E_min + (self.E_max - self.E_min) * E_hat\n",
        "        t = self.t_min + (self.t_max - self.t_min) * t_hat\n",
        "\n",
        "        S_hat_t_hat, I_hat_t_hat, D_hat_t_hat, A_hat_t_hat, R_hat_t_hat, T_hat_t_hat, H_hat_t_hat, E_hat_t_hat = torch.diagonal(torch.diagonal(d_SI, 0, -1), 0)[0], torch.diagonal(torch.diagonal(d_SI, 1, -1), 0)[0], torch.diagonal(torch.diagonal(d_SI, 2, -1), 0)[0] , torch.diagonal(torch.diagonal(d_SI, 3, -1), 0)[0] , torch.diagonal(torch.diagonal(d_SI, 4, -1), 0)[0], torch.diagonal(torch.diagonal(d_SI, 5, -1), 0)[0] , torch.diagonal(torch.diagonal(d_SI, 6, -1), 0)[0] , torch.diagonal(torch.diagonal(d_SI, 7, -1), 0)[0]          \n",
        "\n",
        "        f1 = S_hat_t_hat + (S  * (self.alpha * I + self.beta * D + self.gamma * A + self.delta * R)) / (self.S_max - self.S_min)\n",
        "        f2 = I_hat_t_hat + (- S * (self.alpha * I + self.beta * D + self.gamma * A + self.delta * R) + (self.epsilon + self.eta + self.lambdda) * I ) / (self.I_max - self.I_min)\n",
        "        f3 = D_hat_t_hat + (- self.epsilon * I + (self.eta + self.rho) * D) / (self.D_max - self.D_min)\n",
        "        f4 = A_hat_t_hat + (- self.eta * I + (self.theta + self.mu + self.kappa) * A) / (self.A_max - self.A_min)\n",
        "        f5 = R_hat_t_hat + (- self.eta * D - self.theta * A + (self.nu + self.xi) * R) / (self.R_max - self.R_min)\n",
        "        f6 = T_hat_t_hat + (- self.mu * A - self.nu * R + (self.sigma + self.tao) * T) / (self.T_max - self.T_min)\n",
        "        f7 = H_hat_t_hat + (- self.lambdda * I - self.rho * D - self.kappa * A - self.xi * R - self.sigma * T) / (self.H_max - self.H_min)\n",
        "        f8 = E_hat_t_hat + (- self.tao * T) / (self.E_max - self.E_min)\n",
        "\n",
        "        # print('\\nf1: ', f1[0][0])\n",
        "        # print('f2: ', f2[0][0])\n",
        "        # print('f3: ', f3[0][0])\n",
        "        # print('f4: ', f4[0][0])\n",
        "        # print('f5: ', f5[0][0])\n",
        "        # print('f6: ', f6[0][0])\n",
        "        # print('f7: ', f7[0][0])\n",
        "        # print('f8: ', f8[0][0])\n",
        "        return f1, f2, f3, f4, f5, f6, f7, f8, S, I, D, A, R, T, H, E\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        self.losses = checkpoint['losses']\n",
        "        print('loaded previous loss: ', loss)\n",
        "        self.scheduler._last_lr = 1e-10\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list = []\n",
        "        I_pred_list = []\n",
        "        D_pred_list = []\n",
        "        A_pred_list = []\n",
        "        R_pred_list = []\n",
        "        T_pred_list = []\n",
        "        H_pred_list = []\n",
        "        E_pred_list = []\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        f1, f2, f3, f4, f5, f6, f7, f8, S_pred, I_pred, D_pred, A_pred, R_pred, T_pred, H_pred, E_pred = self.net_f(self.t_hat)\n",
        "\n",
        "        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred) #unnormalize for graphing\n",
        "        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
        "        D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
        "        A_pred_list.append(self.A_min + (self.A_max - self.A_min) * A_pred)\n",
        "        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
        "        T_pred_list.append(self.T_min + (self.T_max - self.T_min) * T_pred)\n",
        "        H_pred_list.append(self.H_min + (self.H_max - self.H_min) * H_pred)\n",
        "        E_pred_list.append(self.E_min + (self.E_max - self.E_min) * E_pred)\n",
        "        \n",
        "        loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
        "                torch.mean(torch.square(self.I_hat - I_pred))+\n",
        "                torch.mean(torch.square(self.D_hat - D_pred))+\n",
        "                torch.mean(torch.square(self.A_hat - A_pred))+\n",
        "                torch.mean(torch.square(self.R_hat - R_pred))+\n",
        "                torch.mean(torch.square(self.T_hat - T_pred))+\n",
        "                torch.mean(torch.square(self.H_hat - H_pred))+\n",
        "                torch.mean(torch.square(self.E_hat - E_pred))+\n",
        "                torch.mean(torch.square(f1))+\n",
        "                torch.mean(torch.square(f2))+\n",
        "                torch.mean(torch.square(f3))+\n",
        "                torch.mean(torch.square(f4))+\n",
        "                torch.mean(torch.square(f5))+\n",
        "                torch.mean(torch.square(f6))+\n",
        "                torch.mean(torch.square(f7))+\n",
        "                torch.mean(torch.square(f8))\n",
        "                ) \n",
        "\n",
        "        #loss.backward(retain_graph=True)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() #scheduler\n",
        "\n",
        "        self.losses.append(loss)\n",
        "        #print(self.zeta)\n",
        "        #loss + model parameters update\n",
        "        if epoch % 100 == 0:\n",
        "          #checkpoint save every 1000 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH + str(self.save)+'.pt')\n",
        "          if self.save % 2 > 0: #its on 3\n",
        "            self.save = 2 #change to 2\n",
        "          else: #its on 2\n",
        "            self.save = 3 #change to 3\n",
        "\n",
        "          print('epoch: ', epoch)\n",
        "          #print(f'alpha: (goal {parameters_dict[\"alpha\"]}', '\\noutput: ', self.alpha)\n",
        "          print(f'alpha: (goal {parameters_dict[\"alpha\"]}', '\\noutput: ', torch.tanh(self.alpha_tilda) * 0.8)\n",
        "          # print(f'beta: (goal {parameters_dict[\"beta\"]}', '\\noutput: ',self.beta)\n",
        "          # print(f'gamma: (goal {parameters_dict[\"gamma\"]}', '\\noutput: ',self.gamma)\n",
        "          # print(f'delta: (goal {parameters_dict[\"delta\"]}', '\\noutput: ',self.delta)\n",
        "          # print(f'epsilon: (goal {parameters_dict[\"epsilon\"]}', '\\noutput: ',self.epsilon)\n",
        "          # print(f'eta: (goal {parameters_dict[\"eta\"]}', '\\noutput: ',self.eta)\n",
        "          # print(f'lambdda: (goal {parameters_dict[\"lambdda\"]}', '\\noutput: ',self.lambdda)\n",
        "          # print(f'eta: (goal {parameters_dict[\"eta\"]}', '\\noutput: ',self.eta)\n",
        "          # print(f'rho: (goal {parameters_dict[\"rho\"]}', '\\noutput: ',self.rho)\n",
        "          # print(f'mu: (goal {parameters_dict[\"mu\"]}', '\\noutput: ',self.mu)\n",
        "          # print(f'kappa: (goal {parameters_dict[\"kappa\"]}', '\\noutput: ',self.kappa)\n",
        "          # print(f'theta: (goal {parameters_dict[\"theta\"]}', '\\noutput: ',self.theta)\n",
        "          # print(f'nu: (goal {parameters_dict[\"nu\"]}', '\\noutput: ',self.nu)\n",
        "          # print(f'xi: (goal {parameters_dict[\"xi\"]}', '\\noutput: ',self.xi)\n",
        "          # print(f'sigma: (goal {parameters_dict[\"sigma\"]}', '\\noutput: ',self.sigma)\n",
        "          # print(f'tao: (goal {parameters_dict[\"tao\"]}', '\\noutput: ',self.tao)\n",
        "          print('#################################')                \n",
        "\n",
        "        \n",
        "      #plot\n",
        "      plt.plot(self.losses, color = 'teal')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      return S_pred_list, I_pred_list, D_pred_list, A_pred_list, R_pred_list, T_pred_list, H_pred_list, E_pred_list"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 129 µs, sys: 0 ns, total: 129 µs\n",
            "Wall time: 140 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_P1obOwWZqOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba450208-9be8-47d5-d2c2-0558577add4c"
      },
      "source": [
        "%%time\n",
        "\n",
        "#this worked best\n",
        "dinn = DINN(tSIDARTHE_data[0], tSIDARTHE_data[1], tSIDARTHE_data[2], tSIDARTHE_data[3], \n",
        "            tSIDARTHE_data[4], tSIDARTHE_data[5], tSIDARTHE_data[6], tSIDARTHE_data[7], tSIDARTHE_data[8]) #in the form of [t,S,I,D,A,R,T,H,E]\n",
        "\n",
        "learning_rate = 0.02\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-9, max_lr=1e-3, step_size_up=4000, mode=\"triangular2\", cycle_momentum=False)\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-9, max_lr=1e-3, step_size_up=1000, mode=\"triangular2\", cycle_momentum=False)\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "S_pred_list, I_pred_list, D_pred_list, A_pred_list, R_pred_list, T_pred_list, H_pred_list, E_pred_list = dinn.train(20000) #train\n",
        "#S_pred_list, I_pred_list, D_pred_list, A_pred_list, R_pred_list, T_pred_list, H_pred_list, E_pred_list = dinn.test() #test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "loading pre-trained model...\n",
            "loaded previous loss:  tensor(11.7333, dtype=torch.float64, requires_grad=True)\n",
            "\n",
            "starting training...\n",
            "\n",
            "\n",
            "Saving model... Loss is:  tensor(11.7276, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwqBVtEM9FYG"
      },
      "source": [
        "plt.plot(dinn.losses[12000:], color = 'teal')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrvoRWQZqOd"
      },
      "source": [
        "#(tSIDARTHE_data[0], tSIDARTHE_data[1], tSIDARTHE_data[2], tSIDARTHE_data[3], \n",
        "            #tSIDARTHE_data[4], tSIDARTHE_data[5], tSIDARTHE_data[6], tSIDARTHE_data[7], tSIDARTHE_data[8]) #in the form of [t,S,I,D,A,R,T,H,E]\n",
        "\n",
        "fig = plt.figure(facecolor='w', figsize=(12,12))\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[1]* 60e6, 'pink', alpha=0.5, lw=2, label='Susceptible')\n",
        "# ax.plot(tSIDARTHE_data[0], S_pred_list[0].detach().numpy(), 'navy', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[2]* 60e6, 'violet', alpha=0.5, lw=2, label='Infected')\n",
        "# ax.plot(tSIDARTHE_data[0], I_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[3]* 60e6, 'darkgreen', alpha=0.5, lw=2, label='Diagnosed')\n",
        "# ax.plot(tSIDARTHE_data[0], D_pred_list[0].detach().numpy(), 'gold', alpha=0.9, lw=2, label='Diagnosed Prediction', linestyle='dashed')\n",
        "\n",
        "ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[4], 'red', alpha=0.5, lw=2, label='Ailling')\n",
        "ax.plot(tSIDARTHE_data[0], A_pred_list[0].detach().numpy(), 'salmon', alpha=0.9, lw=2, label='Ailling Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[5]* 60e6, 'blue', alpha=0.5, lw=2, label='Recognized')\n",
        "# ax.plot(tSIDARTHE_data[0], R_pred_list[0].detach().numpy(), 'wheat', alpha=0.9, lw=2, label='Recognized Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[6]* 60e6, 'purple', alpha=0.5, lw=2, label='Threatened')\n",
        "# ax.plot(tSIDARTHE_data[0], T_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='Threatened Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[7]* 60e6, 'yellow', alpha=0.5, lw=2, label='Healed')\n",
        "# ax.plot(tSIDARTHE_data[0], H_pred_list[0].detach().numpy(), 'slategrey', alpha=0.9, lw=2, label='Healed Prediction', linestyle='dashed')\n",
        "\n",
        "# ax.plot(tSIDARTHE_data[0], tSIDARTHE_data[8]* 60e6, 'black', alpha=0.5, lw=2, label='Extinct')\n",
        "# ax.plot(tSIDARTHE_data[0], E_pred_list[0].detach().numpy(), 'aqua', alpha=0.9, lw=2, label='Extinct Prediction', linestyle='dashed')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.set_ylabel('Number')\n",
        "#ax.set_ylim([-1,50])\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzZI6VMZqOe"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#initial conditions\n",
        "I0 = 200\n",
        "D0 = 20\n",
        "A0 = 1\n",
        "R0 = 2\n",
        "T0 = 0\n",
        "H0 = 0\n",
        "E0 = 0\n",
        "S0 = (1 - I0 - D0 - A0 - R0 - T0 - H0 - E0) * 60e6\n",
        "\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 350, 50) \n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t):\n",
        "    if t < 4:\n",
        "      idx = 0\n",
        "    elif 4 <= t < 12:\n",
        "      idx = 1\n",
        "    elif 12 <= t < 22:\n",
        "      idx = 2\n",
        "    elif 22 <= t < 28:\n",
        "      idx = 3\n",
        "    elif 28 <= t < 38:\n",
        "      idx = 4\n",
        "    elif 38 <= t < 50:\n",
        "      idx = 5\n",
        "    elif t >= 50:\n",
        "      idx = 6\n",
        "\n",
        "    alpha=dinn.alpha[idx]\n",
        "    beta=dinn.beta[idx]\n",
        "    gamma=dinn.gamma[idx]\n",
        "    delta=dinn.delta[idx]\n",
        "    epsilon=dinn.epsilon[idx]\n",
        "    zeta=dinn.zeta[idx]\n",
        "    lambdda=dinn.lambdda[idx]\n",
        "    eta=dinn.eta[idx]\n",
        "    rho=dinn.rho[idx]\n",
        "    mu=dinn.mu[idx]\n",
        "    kappa=dinn.kappa[idx]\n",
        "    theta=dinn.theta[idx]\n",
        "    nu=dinn.nu[idx]\n",
        "    xi=dinn.xi[idx]\n",
        "    sigma=dinn.sigma[idx]\n",
        "    tao=dinn.tao[idx]\n",
        "\n",
        "    I, D, A, R, T, H, E, S = y\n",
        "    dSdt = -S * (alpha * I + beta * D + gamma * A + delta * R)\n",
        "    dIdt = S * (alpha * I + beta * D + gamma * A + delta * R) - (epsilon + zeta + lambdda) * I\n",
        "    dDdt = epsilon * I - (eta + rho) * D\n",
        "    dAdt = zeta * I - (theta + mu + kappa) * A \n",
        "    dRdt = eta * D + theta * A - (nu + xi) * R\n",
        "    dTdt = mu * A + nu * R - (sigma + tao) * T\n",
        "    dHdt = lambdda * I + rho * D + kappa * A + xi * R + sigma * T\n",
        "    dEdt = tao * T\n",
        "\n",
        "    return dIdt, dDdt, dAdt, dRdt, dTdt, dHdt, dEdt, dSdt\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = I0, D0, A0, R0, T0, H0, E0, S0\n",
        "\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t)\n",
        "I, D, A, R, T, H, E, S = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "\n",
        "#ax.plot(t, I, 'violet', alpha=0.5, lw=2, label='Infected', linestyle='dashed')\n",
        "#ax.plot(t, D, 'darkgreen', alpha=0.5, lw=2, label='Diagnosed', linestyle='dashed')\n",
        "#ax.plot(t, A, 'red', alpha=0.5, lw=2, label='Ailling', linestyle='dashed')\n",
        "#ax.plot(t, R, 'blue', alpha=0.5, lw=2, label='Recognized', linestyle='dashed')\n",
        "#ax.plot(t, T, 'purple', alpha=0.5, lw=2, label='Threatened', linestyle='dashed')\n",
        "#ax.plot(t, H, 'yellow', alpha=0.5, lw=2, label='Healed', linestyle='dashed')\n",
        "#ax.plot(t, E, 'black', alpha=0.5, lw=2, label='Extinct', linestyle='dashed')\n",
        "ax.plot(t, S, 'pink', alpha=0.5, lw=2, label='Susceptible', linestyle='dashed')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-zofRIm2RNz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
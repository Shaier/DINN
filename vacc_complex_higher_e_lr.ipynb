{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python373jvsc74a57bd0f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "vacc_complex_higher_e_lr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JoPs1QTPZtrO",
        "outputId": "dccd85bb-bcbc-4a67-d0a6-95b534ba7592"
      },
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#Change working directory to make it easier to access the files\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/dinn\")\n",
        "os.getcwd() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/dinn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhy95XbZqOS",
        "outputId": "a6ff24db-881d-48b1-f79d-45632fdde8b6"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tSI_vaccination_data = genfromtxt('tSI_vaccination_data.csv', delimiter=',') #in the form of [t, S, I]\n",
        "\n",
        "torch.manual_seed(1234)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f27efdaccf0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6iFgYfZqOa",
        "outputId": "31415652-bbc0-47e5-a711-4a39a7794871"
      },
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'vacc_complex_higher_e_lr.pt' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data): #t, S_data, I_data\n",
        "        super(DINN, self).__init__()\n",
        "        self.t = torch.tensor(t).float()\n",
        "        self.S = torch.tensor(S_data)\n",
        "        self.I = torch.tensor(I_data)\n",
        "\n",
        "        self.losses = []\n",
        "\n",
        "        #learnable parameters\n",
        "        self.alpha1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.alpha2_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.mu_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.u_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "        self.tao_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "\n",
        "        #NN\n",
        "        self.net_si = self.Net_si()\n",
        "        self.params = list(self.net_si.parameters())\n",
        "        self.params.extend(list([self.mu_tilda, self.beta_tilda, self.alpha1_tilda, self.alpha2_tilda, self.u_tilda, self.tao_tilda]))\n",
        "\n",
        "        #get values for normalization\n",
        "        self.t_min = torch.min(self.t)\n",
        "        self.t_max = torch.max(self.t)\n",
        "        self.S_min = torch.min(self.S)\n",
        "        self.S_max = torch.max(self.S)\n",
        "        self.I_min = torch.min(self.I)\n",
        "        self.I_max = torch.max(self.I)\n",
        "\n",
        "        #normalize \n",
        "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
        "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
        "        self.t_hat = (self.t - self.t_min) / (self.t_max - self.t_min)\n",
        "\n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha1(self):\n",
        "        return torch.tanh(self.alpha1_tilda) * 2\n",
        "\n",
        "    @property\n",
        "    def alpha2(self):\n",
        "        return torch.tanh(self.alpha2_tilda)\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda)*0.01\n",
        "\n",
        "    @property\n",
        "    def mu(self):\n",
        "        return torch.tanh(self.mu_tilda)*6\n",
        "\n",
        "    @property\n",
        "    def u(self):\n",
        "        return torch.tanh(self.u_tilda)\n",
        "\n",
        "    @property\n",
        "    def tao(self):\n",
        "        return torch.tanh(self.tao_tilda)\n",
        "\n",
        "    #nets\n",
        "    class Net_si(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_si, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 32) #takes t\n",
        "            self.fc2=nn.Linear(32, 32)\n",
        "            self.fc3=nn.Linear(32, 64)\n",
        "            self.fc4=nn.Linear(64, 64)\n",
        "            self.fc5=nn.Linear(64, 128)\n",
        "            self.fc6=nn.Linear(128, 128)\n",
        "            self.fc7=nn.Linear(128, 64)\n",
        "            self.fc8=nn.Linear(64, 32)\n",
        "            self.out=nn.Linear(32, 2) #outputs S, I\n",
        "\n",
        "        def forward(self, t):\n",
        "            si=F.relu(self.fc1(t))\n",
        "            si=F.relu(self.fc2(si))\n",
        "            si=F.relu(self.fc3(si))\n",
        "            si=F.relu(self.fc4(si))\n",
        "            si=F.relu(self.fc5(si))\n",
        "            si=F.relu(self.fc6(si))\n",
        "            si=F.relu(self.fc7(si))\n",
        "            si=F.relu(self.fc8(si))\n",
        "            si=self.out(si)\n",
        "            return si    \n",
        "\n",
        "    def net_f(self, t_hat):  \n",
        "        # our NN take as input normalized data and outputs normalized data\n",
        "        si_hat = self.net_si(t_hat) \n",
        "\n",
        "        S_hat, I_hat = si_hat[:,0], si_hat[:,1]\n",
        "\n",
        "        S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
        "        I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
        "        t = self.t_min + (self.t_max - self.t_min) * t_hat\n",
        "\n",
        "        S_hat_t_hat = grad(S_hat, t_hat, retain_graph=True)[0][0] \n",
        "        I_hat_t_hat = grad(I_hat, t_hat, retain_graph=True)[0][0] \n",
        "        \n",
        "        f1_hat = S_hat_t_hat  - (- self.beta * S * I  + self.u * torch.nn.Sigmoid()(-1e3*(self.tao - t)) * (- self.alpha1) * S) * ((self.t_max - self.t_min)/(self.S_max - self.S_min))\n",
        "        f2_hat = I_hat_t_hat  - (self.beta * S * I  - self.mu * I + self.u * torch.nn.Sigmoid()(-1e3*(self.tao - t)) * (-self.alpha2) * I)* ((self.t_max - self.t_min)/(self.I_max - self.I_min))\n",
        "        return f1_hat, f2_hat, S_hat, I_hat\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        checkpoint = torch.load(PATH) \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        loss = checkpoint['loss']\n",
        "        self.losses = checkpoint['losses']\n",
        "        print('loaded previous loss: ', loss)\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list= []\n",
        "        I_pred_list= []\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        for time_step in range(len(self.t_hat)):\n",
        "            \n",
        "            t_value = self.t_hat[time_step]\n",
        "            t_value = torch.tensor(t_value, requires_grad=True).unsqueeze(0).unsqueeze(1)\n",
        "            \n",
        "            f1_hat, f2_hat, S_pred, I_pred = self.net_f(t_value)\n",
        "\n",
        "            S_pred_list.append(S_pred) #these are the normalized predictions. Don't forget to denorm. them before graphing\n",
        "            I_pred_list.append(I_pred)\n",
        "            \n",
        "            loss = (torch.mean(torch.square(self.S_hat[time_step]-S_pred))+torch.mean(torch.square(self.I_hat[time_step]-I_pred)) \\\n",
        "            +torch.mean(torch.square(f1_hat)) + torch.mean(torch.square(f2_hat))) #/100\n",
        "\n",
        "\n",
        "            loss.backward(retain_graph=True)\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() #scheduler\n",
        "\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 100 == 0:\n",
        "          #checkpoint save every 1000 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH)\n",
        "\n",
        "          #old_loss = loss #change old loss to current loss\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print('epoch: ', epoch)\n",
        "          print('loss: ' ,loss)\n",
        "          print('alpha1: (goal 1)', self.alpha1)\n",
        "          print('\\nalpha2: (goal 0)', self.alpha2)\n",
        "          print('\\nbeta: (goal 0.0075): ', self.beta)\n",
        "          print('\\nmu (goal 5): ', self.mu)\n",
        "          print('\\nu: (goal 0.515151515): ', self.u)\n",
        "          print('\\ntao (goal 0.58): ', self.tao)\n",
        "          print('#################################')                \n",
        "\n",
        "        \n",
        "      #plot\n",
        "      plt.plot(self.losses, color = 'teal')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      return S_pred_list, I_pred_list\n",
        "\n",
        "    def test(self):\n",
        "        # Load checkpoint\n",
        "        try:\n",
        "            print('\\nLoading trained model...')\n",
        "            checkpoint = torch.load(PATH)        \n",
        "            #self.net_si.load_state_dict(checkpoint['net_si_state_dict'])\n",
        "            self.load_state_dict(checkpoint['model'])\n",
        "            self.losses = checkpoint['losses']\n",
        "\n",
        "        except RuntimeError :\n",
        "            print('changed the architecture, ignore')\n",
        "            pass\n",
        "        except FileNotFoundError:\n",
        "            pass\n",
        "        \n",
        "        S_pred_list= []\n",
        "        I_pred_list= []\n",
        "\n",
        "        for time_step in range(len(self.t)):\n",
        "\n",
        "            t_value = self.t[time_step]\n",
        "            t_value = torch.tensor(t_value, requires_grad=True).unsqueeze(0).unsqueeze(1)\n",
        "            \n",
        "            f1, f2, S_pred, I_pred = self.net_f(t_value)\n",
        "            S_pred_list.append(S_pred)\n",
        "            I_pred_list.append(I_pred)\n",
        "\n",
        "        return S_pred_list, I_pred_list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 79 µs, sys: 0 ns, total: 79 µs\n",
            "Wall time: 82.7 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1obOwWZqOc",
        "outputId": "7755e681-ba90-4760-aed4-d73886f949c2"
      },
      "source": [
        "%%time\n",
        "dinn = DINN(tSI_vaccination_data[0], tSI_vaccination_data[1], tSI_vaccination_data[2]) #t, S_data, I_data\n",
        "\n",
        "learning_rate = 0.02\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=3000, mode=\"triangular2\", cycle_momentum=False)\n",
        "\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "S_pred_list, I_pred_list = dinn.train(70000) #train\n",
        "#S_pred_list, I_pred_list = dinn.test() #test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "loading pre-trained model...\n",
            "loaded previous loss:  tensor(0.0604, requires_grad=True)\n",
            "\n",
            "starting training...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saving model... Loss is:  tensor(0.0609, grad_fn=<AddBackward0>)\n",
            "epoch:  0\n",
            "loss:  tensor(0.0609, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3206], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7085], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9102], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6505], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6050], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0568, grad_fn=<AddBackward0>)\n",
            "epoch:  100\n",
            "loss:  tensor(0.0568, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3183], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7088], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9050], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6501], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6049], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0564, grad_fn=<AddBackward0>)\n",
            "epoch:  200\n",
            "loss:  tensor(0.0564, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3160], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7092], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8998], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6500], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6047], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0538, grad_fn=<AddBackward0>)\n",
            "epoch:  300\n",
            "loss:  tensor(0.0538, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3136], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7096], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8948], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6496], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6043], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0517, grad_fn=<AddBackward0>)\n",
            "epoch:  400\n",
            "loss:  tensor(0.0517, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3112], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7100], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8903], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6494], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6044], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0504, grad_fn=<AddBackward0>)\n",
            "epoch:  500\n",
            "loss:  tensor(0.0504, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3092], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7104], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8869], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6494], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6043], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0602, grad_fn=<AddBackward0>)\n",
            "epoch:  600\n",
            "loss:  tensor(0.0602, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3069], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7108], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8816], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6490], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6046], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0565, grad_fn=<AddBackward0>)\n",
            "epoch:  700\n",
            "loss:  tensor(0.0565, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3043], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7114], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8765], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6044], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0503, grad_fn=<AddBackward0>)\n",
            "epoch:  800\n",
            "loss:  tensor(0.0503, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3014], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7121], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8711], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6492], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6039], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0414, grad_fn=<AddBackward0>)\n",
            "epoch:  900\n",
            "loss:  tensor(0.0414, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2981], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7128], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8652], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6029], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1599, grad_fn=<AddBackward0>)\n",
            "epoch:  1000\n",
            "loss:  tensor(0.1599, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2951], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7135], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8605], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6024], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1505, grad_fn=<AddBackward0>)\n",
            "epoch:  1100\n",
            "loss:  tensor(0.1505, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2924], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7142], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8564], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6491], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6021], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2392, grad_fn=<AddBackward0>)\n",
            "epoch:  1200\n",
            "loss:  tensor(0.2392, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2897], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7148], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8529], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6492], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6017], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2334, grad_fn=<AddBackward0>)\n",
            "epoch:  1300\n",
            "loss:  tensor(0.2334, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2871], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7154], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8498], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6492], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6014], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2147, grad_fn=<AddBackward0>)\n",
            "epoch:  1400\n",
            "loss:  tensor(0.2147, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2847], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7159], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8469], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6012], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2086, grad_fn=<AddBackward0>)\n",
            "epoch:  1500\n",
            "loss:  tensor(0.2086, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2825], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7164], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8448], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6010], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1942, grad_fn=<AddBackward0>)\n",
            "epoch:  1600\n",
            "loss:  tensor(0.1942, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2804], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7169], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8433], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6008], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1869, grad_fn=<AddBackward0>)\n",
            "epoch:  1700\n",
            "loss:  tensor(0.1869, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2785], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7173], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8419], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6491], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6007], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1750, grad_fn=<AddBackward0>)\n",
            "epoch:  1800\n",
            "loss:  tensor(0.1750, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2767], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7178], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8408], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6495], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6006], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1706, grad_fn=<AddBackward0>)\n",
            "epoch:  1900\n",
            "loss:  tensor(0.1706, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2750], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7183], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8403], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6502], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6005], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1659, grad_fn=<AddBackward0>)\n",
            "epoch:  2000\n",
            "loss:  tensor(0.1659, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2735], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7188], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8399], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6509], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6004], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1614, grad_fn=<AddBackward0>)\n",
            "epoch:  2100\n",
            "loss:  tensor(0.1614, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2720], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7193], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8396], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6516], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1527, grad_fn=<AddBackward0>)\n",
            "epoch:  2200\n",
            "loss:  tensor(0.1527, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2706], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7198], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8396], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6525], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1529, grad_fn=<AddBackward0>)\n",
            "epoch:  2300\n",
            "loss:  tensor(0.1529, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2693], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7203], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8400], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6534], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1476, grad_fn=<AddBackward0>)\n",
            "epoch:  2400\n",
            "loss:  tensor(0.1476, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2682], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7208], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8407], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6544], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1439, grad_fn=<AddBackward0>)\n",
            "epoch:  2500\n",
            "loss:  tensor(0.1439, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2671], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7213], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8417], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6553], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1396, grad_fn=<AddBackward0>)\n",
            "epoch:  2600\n",
            "loss:  tensor(0.1396, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2663], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7218], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8432], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6562], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6003], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1350, grad_fn=<AddBackward0>)\n",
            "epoch:  2700\n",
            "loss:  tensor(0.1350, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2658], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7222], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8451], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6572], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6004], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1287, grad_fn=<AddBackward0>)\n",
            "epoch:  2800\n",
            "loss:  tensor(0.1287, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2657], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7227], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8474], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6582], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6004], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1250, grad_fn=<AddBackward0>)\n",
            "epoch:  2900\n",
            "loss:  tensor(0.1250, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2657], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7231], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8503], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6591], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6006], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1114, grad_fn=<AddBackward0>)\n",
            "epoch:  3000\n",
            "loss:  tensor(0.1114, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2666], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7235], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8547], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6600], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6008], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1208, grad_fn=<AddBackward0>)\n",
            "epoch:  3100\n",
            "loss:  tensor(0.1208, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2679], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7237], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8596], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6607], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6012], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1264, grad_fn=<AddBackward0>)\n",
            "epoch:  3200\n",
            "loss:  tensor(0.1264, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2700], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7238], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8659], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6612], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6022], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1323, grad_fn=<AddBackward0>)\n",
            "epoch:  3300\n",
            "loss:  tensor(0.1323, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2726], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7236], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8728], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6616], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6049], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1579, grad_fn=<AddBackward0>)\n",
            "epoch:  3400\n",
            "loss:  tensor(0.1579, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2752], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7233], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8784], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6617], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6051], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2081, grad_fn=<AddBackward0>)\n",
            "epoch:  3500\n",
            "loss:  tensor(0.2081, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2772], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7225], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8834], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6611], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6070], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2272, grad_fn=<AddBackward0>)\n",
            "epoch:  3600\n",
            "loss:  tensor(0.2272, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2788], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7219], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8893], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6605], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6075], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2402, grad_fn=<AddBackward0>)\n",
            "epoch:  3700\n",
            "loss:  tensor(0.2402, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2801], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7214], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8946], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6600], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6076], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2445, grad_fn=<AddBackward0>)\n",
            "epoch:  3800\n",
            "loss:  tensor(0.2445, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2813], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7210], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.8998], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6596], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6076], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2317, grad_fn=<AddBackward0>)\n",
            "epoch:  3900\n",
            "loss:  tensor(0.2317, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2820], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7207], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9042], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6593], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6075], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0667, grad_fn=<AddBackward0>)\n",
            "epoch:  4000\n",
            "loss:  tensor(0.0667, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2825], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7205], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9084], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6591], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6072], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0613, grad_fn=<AddBackward0>)\n",
            "epoch:  4100\n",
            "loss:  tensor(0.0613, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2831], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7204], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9135], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6591], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6070], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1257, grad_fn=<AddBackward0>)\n",
            "epoch:  4200\n",
            "loss:  tensor(0.1257, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2840], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7202], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9200], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6590], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6068], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1355, grad_fn=<AddBackward0>)\n",
            "epoch:  4300\n",
            "loss:  tensor(0.1355, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2862], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7197], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9289], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6587], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6074], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1521, grad_fn=<AddBackward0>)\n",
            "epoch:  4400\n",
            "loss:  tensor(0.1521, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2882], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7193], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9364], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6585], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6076], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1638, grad_fn=<AddBackward0>)\n",
            "epoch:  4500\n",
            "loss:  tensor(0.1638, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2903], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7188], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9439], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6583], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6076], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1717, grad_fn=<AddBackward0>)\n",
            "epoch:  4600\n",
            "loss:  tensor(0.1717, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2924], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7183], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9511], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6579], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6076], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1896, grad_fn=<AddBackward0>)\n",
            "epoch:  4700\n",
            "loss:  tensor(0.1896, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2946], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7175], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9583], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6571], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6079], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0559, grad_fn=<AddBackward0>)\n",
            "epoch:  4800\n",
            "loss:  tensor(0.0559, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2971], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7168], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9655], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6564], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6081], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0624, grad_fn=<AddBackward0>)\n",
            "epoch:  4900\n",
            "loss:  tensor(0.0624, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2994], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7161], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9720], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6557], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6083], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0611, grad_fn=<AddBackward0>)\n",
            "epoch:  5000\n",
            "loss:  tensor(0.0611, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3020], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7154], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9787], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6550], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6087], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2532, grad_fn=<AddBackward0>)\n",
            "epoch:  5100\n",
            "loss:  tensor(0.2532, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3043], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7147], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9848], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6542], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6085], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0625, grad_fn=<AddBackward0>)\n",
            "epoch:  5200\n",
            "loss:  tensor(0.0625, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3064], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7139], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9906], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6533], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6070], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0624, grad_fn=<AddBackward0>)\n",
            "epoch:  5300\n",
            "loss:  tensor(0.0624, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3076], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7134], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9947], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6526], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6058], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0608, grad_fn=<AddBackward0>)\n",
            "epoch:  5400\n",
            "loss:  tensor(0.0608, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3085], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7129], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([2.9983], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6520], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6057], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0560, grad_fn=<AddBackward0>)\n",
            "epoch:  5500\n",
            "loss:  tensor(0.0560, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3082], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7127], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0005], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6515], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6068], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0515, grad_fn=<AddBackward0>)\n",
            "epoch:  5600\n",
            "loss:  tensor(0.0515, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3071], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7126], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0016], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6511], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6068], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0514, grad_fn=<AddBackward0>)\n",
            "epoch:  5700\n",
            "loss:  tensor(0.0514, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3056], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7127], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0026], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6509], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0495, grad_fn=<AddBackward0>)\n",
            "epoch:  5800\n",
            "loss:  tensor(0.0495, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3034], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7128], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6507], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6058], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0212, grad_fn=<AddBackward0>)\n",
            "epoch:  5900\n",
            "loss:  tensor(0.0212, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3010], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7132], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0033], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6508], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0141, grad_fn=<AddBackward0>)\n",
            "epoch:  6000\n",
            "loss:  tensor(0.0141, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2980], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7135], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0032], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6507], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6047], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0138, grad_fn=<AddBackward0>)\n",
            "epoch:  6100\n",
            "loss:  tensor(0.0138, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2954], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7140], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0039], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6508], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6043], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0174, grad_fn=<AddBackward0>)\n",
            "epoch:  6200\n",
            "loss:  tensor(0.0174, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2934], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7143], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0057], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6507], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6040], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0209, grad_fn=<AddBackward0>)\n",
            "epoch:  6300\n",
            "loss:  tensor(0.0209, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2917], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7145], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0085], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6508], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6038], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0215, grad_fn=<AddBackward0>)\n",
            "epoch:  6400\n",
            "loss:  tensor(0.0215, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2908], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7148], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0123], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6039], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0204, grad_fn=<AddBackward0>)\n",
            "epoch:  6500\n",
            "loss:  tensor(0.0204, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2899], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7149], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0161], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6040], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0222, grad_fn=<AddBackward0>)\n",
            "epoch:  6600\n",
            "loss:  tensor(0.0222, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2889], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7151], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0200], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6041], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0217, grad_fn=<AddBackward0>)\n",
            "epoch:  6700\n",
            "loss:  tensor(0.0217, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2885], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7152], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0242], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6512], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6049], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0188, grad_fn=<AddBackward0>)\n",
            "epoch:  6800\n",
            "loss:  tensor(0.0188, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2878], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7155], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0278], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6514], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0110, grad_fn=<AddBackward0>)\n",
            "epoch:  6900\n",
            "loss:  tensor(0.0110, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2863], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7159], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0298], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6518], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6051], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0134, grad_fn=<AddBackward0>)\n",
            "epoch:  7000\n",
            "loss:  tensor(0.0134, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2849], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7162], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0325], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6520], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6047], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0202, grad_fn=<AddBackward0>)\n",
            "epoch:  7100\n",
            "loss:  tensor(0.0202, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2848], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7163], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0376], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6521], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6049], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0237, grad_fn=<AddBackward0>)\n",
            "epoch:  7200\n",
            "loss:  tensor(0.0237, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2865], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7159], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0439], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6519], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0133, grad_fn=<AddBackward0>)\n",
            "epoch:  7300\n",
            "loss:  tensor(0.0133, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2893], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7152], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0514], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6513], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6065], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0738, grad_fn=<AddBackward0>)\n",
            "epoch:  7400\n",
            "loss:  tensor(0.0738, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2923], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7145], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0583], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6508], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0804, grad_fn=<AddBackward0>)\n",
            "epoch:  7500\n",
            "loss:  tensor(0.0804, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2954], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7137], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0651], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6501], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6060], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0789, grad_fn=<AddBackward0>)\n",
            "epoch:  7600\n",
            "loss:  tensor(0.0789, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.2986], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7130], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0713], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6497], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0849, grad_fn=<AddBackward0>)\n",
            "epoch:  7700\n",
            "loss:  tensor(0.0849, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3016], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7124], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0771], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6493], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6066], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0918, grad_fn=<AddBackward0>)\n",
            "epoch:  7800\n",
            "loss:  tensor(0.0918, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3047], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7117], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0828], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6068], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0999, grad_fn=<AddBackward0>)\n",
            "epoch:  7900\n",
            "loss:  tensor(0.0999, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3072], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7110], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0876], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6484], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6068], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1050, grad_fn=<AddBackward0>)\n",
            "epoch:  8000\n",
            "loss:  tensor(0.1050, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3097], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7104], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0922], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6479], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6067], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1064, grad_fn=<AddBackward0>)\n",
            "epoch:  8100\n",
            "loss:  tensor(0.1064, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3123], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7098], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.0968], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6476], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1129, grad_fn=<AddBackward0>)\n",
            "epoch:  8200\n",
            "loss:  tensor(0.1129, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3144], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7092], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1008], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6472], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6065], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1171, grad_fn=<AddBackward0>)\n",
            "epoch:  8300\n",
            "loss:  tensor(0.1171, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3167], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7087], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1049], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6469], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6059], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1244, grad_fn=<AddBackward0>)\n",
            "epoch:  8400\n",
            "loss:  tensor(0.1244, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3186], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7082], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1083], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6465], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6057], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0253, grad_fn=<AddBackward0>)\n",
            "epoch:  8500\n",
            "loss:  tensor(0.0253, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3203], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7078], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1115], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6462], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6062], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0230, grad_fn=<AddBackward0>)\n",
            "epoch:  8600\n",
            "loss:  tensor(0.0230, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3215], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7074], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1141], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6458], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0173, grad_fn=<AddBackward0>)\n",
            "epoch:  8700\n",
            "loss:  tensor(0.0173, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3226], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7070], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1164], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6453], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6059], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0131, grad_fn=<AddBackward0>)\n",
            "epoch:  8800\n",
            "loss:  tensor(0.0131, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3233], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7066], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1185], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6448], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6057], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0143, grad_fn=<AddBackward0>)\n",
            "epoch:  8900\n",
            "loss:  tensor(0.0143, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3237], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7063], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1201], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6443], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6058], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0105, grad_fn=<AddBackward0>)\n",
            "epoch:  9000\n",
            "loss:  tensor(0.0105, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3235], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7062], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1212], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6439], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0097, grad_fn=<AddBackward0>)\n",
            "epoch:  9100\n",
            "loss:  tensor(0.0097, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3235], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7061], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1227], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6437], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6066], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0093, grad_fn=<AddBackward0>)\n",
            "epoch:  9200\n",
            "loss:  tensor(0.0093, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3236], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7059], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1245], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6434], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0092, grad_fn=<AddBackward0>)\n",
            "epoch:  9300\n",
            "loss:  tensor(0.0092, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3241], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7057], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1266], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6431], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0090, grad_fn=<AddBackward0>)\n",
            "epoch:  9400\n",
            "loss:  tensor(0.0090, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3249], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7054], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1292], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6428], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0099, grad_fn=<AddBackward0>)\n",
            "epoch:  9500\n",
            "loss:  tensor(0.0099, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3266], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7050], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1326], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6425], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6058], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0084, grad_fn=<AddBackward0>)\n",
            "epoch:  9600\n",
            "loss:  tensor(0.0084, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3297], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7043], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1375], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6421], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6060], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0081, grad_fn=<AddBackward0>)\n",
            "epoch:  9700\n",
            "loss:  tensor(0.0081, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3326], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7036], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1418], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6419], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0094, grad_fn=<AddBackward0>)\n",
            "epoch:  9800\n",
            "loss:  tensor(0.0094, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3353], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7030], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1460], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6417], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6060], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0115, grad_fn=<AddBackward0>)\n",
            "epoch:  9900\n",
            "loss:  tensor(0.0115, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3383], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7024], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1507], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6416], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0123, grad_fn=<AddBackward0>)\n",
            "epoch:  10000\n",
            "loss:  tensor(0.0123, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3415], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7016], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1560], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6414], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6057], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0130, grad_fn=<AddBackward0>)\n",
            "epoch:  10100\n",
            "loss:  tensor(0.0130, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3445], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7010], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1611], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6413], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0116, grad_fn=<AddBackward0>)\n",
            "epoch:  10200\n",
            "loss:  tensor(0.0116, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3471], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.7003], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1653], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6411], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6056], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0172, grad_fn=<AddBackward0>)\n",
            "epoch:  10300\n",
            "loss:  tensor(0.0172, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3504], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6997], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1706], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6414], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6046], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0120, grad_fn=<AddBackward0>)\n",
            "epoch:  10400\n",
            "loss:  tensor(0.0120, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3528], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6990], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1746], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6413], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6045], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0162, grad_fn=<AddBackward0>)\n",
            "epoch:  10500\n",
            "loss:  tensor(0.0162, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3562], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6984], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1802], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6419], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6041], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0133, grad_fn=<AddBackward0>)\n",
            "epoch:  10600\n",
            "loss:  tensor(0.0133, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3589], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6978], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1842], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6423], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6037], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0126, grad_fn=<AddBackward0>)\n",
            "epoch:  10700\n",
            "loss:  tensor(0.0126, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3621], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6972], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1894], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6434], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6035], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0112, grad_fn=<AddBackward0>)\n",
            "epoch:  10800\n",
            "loss:  tensor(0.0112, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3646], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6967], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1929], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6440], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6033], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0118, grad_fn=<AddBackward0>)\n",
            "epoch:  10900\n",
            "loss:  tensor(0.0118, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3674], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6962], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1974], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6449], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6030], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0135, grad_fn=<AddBackward0>)\n",
            "epoch:  11000\n",
            "loss:  tensor(0.0135, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3700], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6957], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2011], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6457], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6029], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0086, grad_fn=<AddBackward0>)\n",
            "epoch:  11100\n",
            "loss:  tensor(0.0086, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3723], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6952], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2046], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6464], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6028], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0082, grad_fn=<AddBackward0>)\n",
            "epoch:  11200\n",
            "loss:  tensor(0.0082, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3749], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6947], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2087], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6472], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6026], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0074, grad_fn=<AddBackward0>)\n",
            "epoch:  11300\n",
            "loss:  tensor(0.0074, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3772], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6944], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2119], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6483], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6024], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0085, grad_fn=<AddBackward0>)\n",
            "epoch:  11400\n",
            "loss:  tensor(0.0085, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3795], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6940], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2152], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6492], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6021], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "epoch:  11500\n",
            "loss:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3820], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6936], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2192], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6501], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6020], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0084, grad_fn=<AddBackward0>)\n",
            "epoch:  11600\n",
            "loss:  tensor(0.0084, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3843], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6934], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2225], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6018], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0076, grad_fn=<AddBackward0>)\n",
            "epoch:  11700\n",
            "loss:  tensor(0.0076, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3866], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6931], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2259], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6519], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6018], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "epoch:  11800\n",
            "loss:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3886], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6929], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2288], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6527], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6018], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0085, grad_fn=<AddBackward0>)\n",
            "epoch:  11900\n",
            "loss:  tensor(0.0085, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3902], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6928], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2307], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6533], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6019], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0069, grad_fn=<AddBackward0>)\n",
            "epoch:  12000\n",
            "loss:  tensor(0.0069, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3918], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6927], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2326], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6540], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6020], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "epoch:  12100\n",
            "loss:  tensor(0.0071, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3930], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6926], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2337], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6544], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6022], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0059, grad_fn=<AddBackward0>)\n",
            "epoch:  12200\n",
            "loss:  tensor(0.0059, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3939], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6925], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2342], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6548], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6025], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0065, grad_fn=<AddBackward0>)\n",
            "epoch:  12300\n",
            "loss:  tensor(0.0065, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3943], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6926], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2335], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6550], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6028], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.0062, grad_fn=<AddBackward0>)\n",
            "epoch:  12400\n",
            "loss:  tensor(0.0062, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3943], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6929], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2318], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6552], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6035], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2671, grad_fn=<AddBackward0>)\n",
            "epoch:  12500\n",
            "loss:  tensor(0.2671, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3937], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6933], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0029], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2290], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6553], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6050], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2499, grad_fn=<AddBackward0>)\n",
            "epoch:  12600\n",
            "loss:  tensor(0.2499, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3926], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6939], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2248], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6553], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2395, grad_fn=<AddBackward0>)\n",
            "epoch:  12700\n",
            "loss:  tensor(0.2395, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3910], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6945], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2197], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6551], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6070], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2249, grad_fn=<AddBackward0>)\n",
            "epoch:  12800\n",
            "loss:  tensor(0.2249, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3889], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6952], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2138], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6548], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6073], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2162, grad_fn=<AddBackward0>)\n",
            "epoch:  12900\n",
            "loss:  tensor(0.2162, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3865], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6959], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2075], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6543], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6075], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2230, grad_fn=<AddBackward0>)\n",
            "epoch:  13000\n",
            "loss:  tensor(0.2230, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3837], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6966], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2004], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6538], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6074], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2184, grad_fn=<AddBackward0>)\n",
            "epoch:  13100\n",
            "loss:  tensor(0.2184, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3805], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6974], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1923], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6531], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6073], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2516, grad_fn=<AddBackward0>)\n",
            "epoch:  13200\n",
            "loss:  tensor(0.2516, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3774], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6983], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1842], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6525], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6069], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2543, grad_fn=<AddBackward0>)\n",
            "epoch:  13300\n",
            "loss:  tensor(0.2543, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3750], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6988], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0030], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1781], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6518], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.5944, grad_fn=<AddBackward0>)\n",
            "epoch:  13400\n",
            "loss:  tensor(0.5944, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3731], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6989], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1734], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6059], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.6662, grad_fn=<AddBackward0>)\n",
            "epoch:  13500\n",
            "loss:  tensor(0.6662, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3720], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6989], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1702], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6504], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3070, grad_fn=<AddBackward0>)\n",
            "epoch:  13600\n",
            "loss:  tensor(0.3070, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3722], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6992], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1702], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6508], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6050], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3059, grad_fn=<AddBackward0>)\n",
            "epoch:  13700\n",
            "loss:  tensor(0.3059, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3725], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6993], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1720], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6510], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6045], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3344, grad_fn=<AddBackward0>)\n",
            "epoch:  13800\n",
            "loss:  tensor(0.3344, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3731], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6993], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1745], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6513], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6047], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3343, grad_fn=<AddBackward0>)\n",
            "epoch:  13900\n",
            "loss:  tensor(0.3343, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3737], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6991], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1775], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6514], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6042], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.7188, grad_fn=<AddBackward0>)\n",
            "epoch:  14000\n",
            "loss:  tensor(0.7188, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3742], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6987], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1808], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6512], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3363, grad_fn=<AddBackward0>)\n",
            "epoch:  14100\n",
            "loss:  tensor(0.3363, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3745], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6985], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1842], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6511], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.8272, grad_fn=<AddBackward0>)\n",
            "epoch:  14200\n",
            "loss:  tensor(0.8272, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3749], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6981], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1883], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6509], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6065], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.4133, grad_fn=<AddBackward0>)\n",
            "epoch:  14300\n",
            "loss:  tensor(0.4133, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3754], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6977], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1931], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6506], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6069], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.4425, grad_fn=<AddBackward0>)\n",
            "epoch:  14400\n",
            "loss:  tensor(0.4425, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3756], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6974], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.1977], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6504], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6067], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.2737, grad_fn=<AddBackward0>)\n",
            "epoch:  14500\n",
            "loss:  tensor(0.2737, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3756], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6975], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2027], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6505], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6064], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.5094, grad_fn=<AddBackward0>)\n",
            "epoch:  14600\n",
            "loss:  tensor(0.5094, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3754], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6974], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2079], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6504], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6061], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3042, grad_fn=<AddBackward0>)\n",
            "epoch:  14700\n",
            "loss:  tensor(0.3042, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3754], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6972], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2133], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6501], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3269, grad_fn=<AddBackward0>)\n",
            "epoch:  14800\n",
            "loss:  tensor(0.3269, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3754], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6970], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2187], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6499], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6065], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.5867, grad_fn=<AddBackward0>)\n",
            "epoch:  14900\n",
            "loss:  tensor(0.5867, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3757], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6965], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2241], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6495], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6069], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3405, grad_fn=<AddBackward0>)\n",
            "epoch:  15000\n",
            "loss:  tensor(0.3405, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3759], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6963], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2288], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6492], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6067], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3495, grad_fn=<AddBackward0>)\n",
            "epoch:  15100\n",
            "loss:  tensor(0.3495, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3762], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6959], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2329], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6489], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6063], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3601, grad_fn=<AddBackward0>)\n",
            "epoch:  15200\n",
            "loss:  tensor(0.3601, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3771], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6950], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2372], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6482], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6059], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3620, grad_fn=<AddBackward0>)\n",
            "epoch:  15300\n",
            "loss:  tensor(0.3620, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3785], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6942], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2417], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6477], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6060], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.1385, grad_fn=<AddBackward0>)\n",
            "epoch:  15400\n",
            "loss:  tensor(0.1385, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3805], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6934], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2464], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6472], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6053], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3002, grad_fn=<AddBackward0>)\n",
            "epoch:  15500\n",
            "loss:  tensor(0.3002, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3830], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6924], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2512], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6466], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6052], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.6241, grad_fn=<AddBackward0>)\n",
            "epoch:  15600\n",
            "loss:  tensor(0.6241, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3860], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6915], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2563], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6460], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6056], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3009, grad_fn=<AddBackward0>)\n",
            "epoch:  15700\n",
            "loss:  tensor(0.3009, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3889], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6906], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2612], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6456], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6057], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.6327, grad_fn=<AddBackward0>)\n",
            "epoch:  15800\n",
            "loss:  tensor(0.6327, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3921], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6898], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2662], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6452], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6048], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(1.0437, grad_fn=<AddBackward0>)\n",
            "epoch:  15900\n",
            "loss:  tensor(1.0437, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3953], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6890], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2712], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6450], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6039], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3225, grad_fn=<AddBackward0>)\n",
            "epoch:  16000\n",
            "loss:  tensor(0.3225, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.3987], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6883], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2761], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6451], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6032], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3765, grad_fn=<AddBackward0>)\n",
            "epoch:  16100\n",
            "loss:  tensor(0.3765, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4018], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6879], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2804], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6460], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6028], grad_fn=<TanhBackward>)\n",
            "#################################\n",
            "\n",
            "Saving model... Loss is:  tensor(0.3173, grad_fn=<AddBackward0>)\n",
            "epoch:  16200\n",
            "loss:  tensor(0.3173, grad_fn=<AddBackward0>)\n",
            "alpha1: (goal 1) tensor([0.4040], grad_fn=<MulBackward0>)\n",
            "\n",
            "alpha2: (goal 0) tensor([-0.6876], grad_fn=<TanhBackward>)\n",
            "\n",
            "beta: (goal 0.0075):  tensor([0.0031], grad_fn=<MulBackward0>)\n",
            "\n",
            "mu (goal 5):  tensor([3.2836], grad_fn=<MulBackward0>)\n",
            "\n",
            "u: (goal 0.515151515):  tensor([0.6467], grad_fn=<TanhBackward>)\n",
            "\n",
            "tao (goal 0.58):  tensor([0.6029], grad_fn=<TanhBackward>)\n",
            "#################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJrvoRWQZqOd"
      },
      "source": [
        "#normalize the predictions\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Susceptible')\n",
        "ax.plot(tSI_vaccination_data[0], S_pred_list, 'violet', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Infected')\n",
        "ax.plot(tSI_vaccination_data[0], I_pred_list, 'darkgreen', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "ax.set_xlabel('Time /days')\n",
        "ax.set_ylabel('Number')\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcowlQFZqOe"
      },
      "source": [
        "print('alpha1: (goal 1)', round(dinn.alpha1.item(),2))\n",
        "print('\\nalpha2: (goal 0)', round(dinn.alpha2.item(),2))\n",
        "print('\\nbeta: (goal 0.0075): ', round(dinn.beta.item(),4))\n",
        "print('\\nmu (goal 5): ', round(dinn.mu.item(),2))\n",
        "print('\\nu: (goal 0.515151515): ', round(dinn.u.item(),2))\n",
        "print('\\ntao (goal 0.58): ', round(dinn.tao.item(),2))\n",
        "\n",
        "\n",
        "print('\\nerror:')\n",
        "print('alpha1: ', round((1-round(dinn.alpha1.item(),2))/1,2)*100,'%')\n",
        "print('alpha2: ', round((0-round(dinn.alpha2.item(),2))/1e-20,2)*100,'%')\n",
        "print('beta: ', round((0.0075-round(dinn.beta.item(),4))/0.0075,2)*100,'%')\n",
        "print('mu: ', round((5-round(dinn.mu.item(),2))/5,2)*100,'%')\n",
        "print('u: ', round((0.515151515-round(dinn.u.item(),2))/0.515151515,2)*100,'%')\n",
        "print('tao: ', round((0.58-round(dinn.tao.item(),2))/0.58,2)*100,'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUzZI6VMZqOe"
      },
      "source": [
        "#vaccination! \n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initial number of infected individuals, I0\n",
        "I0 = 1\n",
        "# Everyone else, S0, is susceptible to infection initially.\n",
        "S0 = 2000\n",
        "# Contact rate, beta, and mean recovery rate, mu.\n",
        "beta, mu = dinn.beta, dinn.mu\n",
        "# A grid of time points (in days)\n",
        "t = np.linspace(0, 3, 100) \n",
        "#parameters\n",
        "u = dinn.u\n",
        "tao = dinn.tao\n",
        "alpha1 = dinn.alpha1\n",
        "alpha2 = dinn.alpha2\n",
        "\n",
        "# The SIR model differential equations.\n",
        "def deriv(y, t, beta, mu, u, tao, alpha1, alpha2):\n",
        "    S, I = y\n",
        "    dSdt = -beta * S * I + u * (t > tao) * alpha1 * (-S)\n",
        "    dIdt = beta * S * I - mu * I + u * (t > tao) * alpha2 * (-I)\n",
        "    return dSdt, dIdt\n",
        "\n",
        "#add u = 0.5, get the corresponding tao, generate the SI data\n",
        "# learn u (self.u), the corresponding tao (self.tao)\n",
        "\n",
        "# Initial conditions vector\n",
        "y0 = S0, I0\n",
        "# Integrate the SIR equations over the time grid, t.\n",
        "ret = odeint(deriv, y0, t, args=(beta, mu, u, tao, alpha1, alpha2))\n",
        "S, I = ret.T\n",
        "\n",
        "# Plot the data on two separate curves for S(t), I(t)\n",
        "fig = plt.figure(facecolor='w')\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[1], 'navy', alpha=0.9, lw=2, label='Actual Susceptible')\n",
        "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Learnable Param Susceptible', linestyle='dashed')\n",
        "ax.plot(tSI_vaccination_data[0], tSI_vaccination_data[2], 'dodgerblue', alpha=0.9, lw=2, label='Actual Infected')\n",
        "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Learnable Param Infected', linestyle='dashed')\n",
        "ax.set_xlabel('Time /days')\n",
        "#ax.set_ylabel('Number (1000s)')\n",
        "#ax.set_ylim(0,1.2)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.xaxis.set_tick_params(length=0)\n",
        "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICWNogFjn27j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}